<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>枫叶冢</title>
    <link>http://zihang.fun/</link>
    
    <atom:link href="http://zihang.fun/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>只有努力不会辜负你</description>
    <pubDate>Mon, 12 Dec 2022 05:41:14 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Sealos</title>
      <link>http://zihang.fun/2022/12/12/k8s%E7%9A%84%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Sealos/</link>
      <guid>http://zihang.fun/2022/12/12/k8s%E7%9A%84%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Sealos/</guid>
      <pubDate>Mon, 12 Dec 2022 04:35:07 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;Sealos&quot;&gt;&lt;a href=&quot;#Sealos&quot; class=&quot;headerlink&quot; title=&quot;Sealos&quot;&gt;&lt;/a&gt;Sealos&lt;/h1&gt;&lt;p&gt;是部署工具 ， 用go语言开发的干净且清凉的k8s的部署工具&lt;/p&gt;
&lt;h1 id=&quot;Sealos的优势&quot;&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="Sealos"><a href="#Sealos" class="headerlink" title="Sealos"></a>Sealos</h1><p>是部署工具 ， 用go语言开发的干净且清凉的k8s的部署工具</p><h1 id="Sealos的优势"><a href="#Sealos的优势" class="headerlink" title="Sealos的优势"></a>Sealos的优势</h1><p>他的证书有效时间是100年</p><p>不依赖ansible haproxy keepalived 是零依赖</p><p>离线安装</p><p>kubelet其默认通过ipvs实现localLB，占用资源少稳定可靠</p><p>更容易在集群节点上增加&#x2F;删除管理</p><p>上千用户使用，在阿里云oss上有，不用担心网速的问题</p><p>dashboard ingress prometheus 等 APP 同样支持离线打包安装</p><p>当不超过三个独立集群，都是免费的，超过则要订阅服务了</p><h1 id="rancher是目前企业中认知度最好的-：-周六周日补上"><a href="#rancher是目前企业中认知度最好的-：-周六周日补上" class="headerlink" title="rancher是目前企业中认知度最好的 ： 周六周日补上"></a>rancher是目前企业中认知度最好的 ： 周六周日补上</h1><h1 id="Sealos常用的参数"><a href="#Sealos常用的参数" class="headerlink" title="Sealos常用的参数"></a>Sealos常用的参数</h1><p>–master master的节点服务器地址</p><p>–node node节点服务器地址列表</p><p>–user 服务器 SSH 用户名</p><p>–password 服务器 SSH 用户的密码</p><p>–pkg-url 离线包所在的位置，可以是本地，也可以是http</p><p>–version 指定要部署的k8s的版本</p><p> –pk 指定 SSH 私钥所在的位置 默认是在&#x2F;root&#x2F;.ssh&#x2F;id_rsa</p><p>–podcidr 自定义 pod网段</p><p>–svccidr 参数指定clusterip网段</p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>需要纯净的linux ： centos7 对于centos8 需要调试很多的</p><p>或者是ubantu</p><p>尽量用新版本的Sealos</p><p>注意 ： 服务器时间必须同步</p><p>主机名字不可以重复</p><p>master的cpu要2个以上</p><p>cni组件选择cilium 时的内核版本不低于5.4</p><p>k8s一般用回退两个版本</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>47.25</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E4%BA%91%E5%8E%9F%E7%94%9F%EF%BC%88%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%EF%BC%89/">云原生（哔哩哔哩）</category>
      
      
      
      <comments>http://zihang.fun/2022/12/12/k8s%E7%9A%84%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Sealos/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>flume</title>
      <link>http://zihang.fun/2022/12/12/12-12/</link>
      <guid>http://zihang.fun/2022/12/12/12-12/</guid>
      <pubDate>Mon, 12 Dec 2022 00:49:24 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;xxl：任务调度的时候&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置一个xxl job 完成任务 ，解耦不好，就是代码中常规定义的高内聚 ，低偶合&lt;/li&gt;
&lt;li&gt;设置多个xxl job，可以解决上述的问题 ， 但是时间不好把握 ， 就是第一个任务和第二个任务的交界处，就是如何判断第一</description>
        
      
      
      
      <content:encoded><![CDATA[<p>xxl：任务调度的时候</p><ul><li>设置一个xxl job 完成任务 ，解耦不好，就是代码中常规定义的高内聚 ，低偶合</li><li>设置多个xxl job，可以解决上述的问题 ， 但是时间不好把握 ， 就是第一个任务和第二个任务的交界处，就是如何判断第一个任务执行完了，如何开启第二个，xxl中有可以控制这个的功能</li><li>在任务编辑页面中，点击添加子任务id，就可以了</li></ul><p>然后只用执行父任务就好</p><p>但是不太方便</p><p>任务调度框架 ： 推荐dolphinscheduler  官网  ：<code>dolphinscheduler.apache.org</code></p><p>周六周日学会</p><p>首选dolphinscheduler</p><p>airflow 也是比较擅长制作dag（有向无关图）的一个框架官网 ： <code>airflow.apache.org</code></p><p>他的dag能力非常好用，但是是要求用python使用的，同样周六周日学会</p><p>或者自己开发&#x3D;》java团队</p><p>sqoop是要在yarn上申请资源，然后进行map阶段，它不走reduce阶段，它在yarn上申请资源，就是消耗时间的最大问题</p><h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><p>主要是收集我们的日志数据的</p><p>数据采集&#x2F;数据收集</p><p>数据采集：把数据采集到服务器上</p><p>数据收集：把数据移动到指定位置</p><p>上述是老师之前公司的定义</p><p>flume的架构地位 ： 一般采集日志数据，并不用我们做，是java团队要做的</p><p>日志数据 -》flume-》hdfs</p><p>业务数据 通过sqoop存到hdfs上</p><p>数据处理的两种方式 ： 离线 ，实时</p><p>上述所处的数据处理方式是离线处理，</p><p>实时处理是来一个数据，就处理一个</p><p>离线处理是把一定时间内的数据放到一起来进行处理也叫p处理</p><p>实时处理的架构线和离线处理的差不多，因为flume采集数据就是实时的</p><p>实时 ： 日志数据 -》 flume -》 kafka -》 实时处理框架</p><p>离线 ： 日志数据 -》 flume -》 hdfs -》 hive</p><p>但是现在有一种框架如下 ：</p><p>日志数据 -》 flume -》 kafka</p><ul><li>-》实时</li><li>-》flume -》hdfs -》离线</li></ul><p>并不意味着下面的架构比上面两种好，架构没有好与坏，只有合适不合适</p><p>因为下面意味着要多加一层维护，消耗人力以及物资</p><p>官网 ： <code>flume.apache.org</code></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>官方介绍 ：</p><p>收集，聚合，移动日志文件 <code>Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.</code></p><p>flume ：采集数据是实时采集的而且支持恢复机制 <code> It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms.</code></p><p>flume组件</p><ul><li>source ：采集数据</li><li>channel ： 管道，存储采集过来的数据</li><li>sink ： 移动数据</li></ul><p>flume ： 使用场景</p><p>采集数据日志-》 hdfs上</p><h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><p>以后操作flume，就是编写agent里面的配置</p><p>agent ： 包括上面的那三个组件</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>我们部署的化用1.9版本</p><p>第一步 ： 先解压 到app下</p><p>第二步 ： 软连接 + 环境变量</p><p>第三步 ： 配置flume，修改flume的env.sh文件，把java_home加上</p><p>第四步 ： 使用flume ： 配置agent 配置文件</p><p>flume user guide ：基本使用</p><p>flume develop guide ：二次开发</p><p>常用的 source</p><ul><li>avro 序列化框架的source ****</li><li>exec 日志文件</li><li>spooling dir 日志文件</li><li>kafka Source</li><li>Netcat Source 通过端口采集数据</li><li>taildir Source 日志文件 ****</li><li>等 ，可以自己开发</li><li>其余都是两个星</li></ul><p>常用的channel</p><ul><li>Memory ****</li><li>File  ****</li><li>JDBC *</li><li>kafka *</li><li>Custom ： 用户开发 *</li><li>等</li></ul><p>常用的sink</p><ul><li>hdfs ****</li><li>hive ****</li><li>avro ****</li><li>logger 控制台，打印 **</li><li>HBase *</li><li>kafka *</li><li>http *</li><li>custom *</li><li>等</li></ul><p>如何配置agent</p><p>用什么查什么 ： 不用记</p><p>需求  ：从指定端口的地方获取数据并输出到控制套</p><p>分析  ：</p><p>source ：Netcat</p><p>channel ： memory</p><p>sink ： logger</p><p>然后编写一个flume的文件，文件内容如下</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = netcat<br><span class="hljs-attr">a1.sources.r1.bind</span> = localhost<br><span class="hljs-attr">a1.sources.r1.port</span> = <span class="hljs-number">44444</span><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>event  ：就是我们的flume的一条数据，代表数据是通过这三个阶段的一条数据</p><p>关于source的参数，下列以netcat为例</p><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs vhdl"><br><span class="hljs-keyword">Property</span> Name<span class="hljs-keyword">Default</span>Description<br>channels– <br><span class="hljs-keyword">type</span>–The <span class="hljs-keyword">component</span> <span class="hljs-keyword">type</span> name, needs <span class="hljs-keyword">to</span> be netcat<br>bind–Host name <span class="hljs-keyword">or</span> IP address <span class="hljs-keyword">to</span> bind <span class="hljs-keyword">to</span><br><span class="hljs-keyword">port</span>–<span class="hljs-keyword">Port</span> # <span class="hljs-keyword">to</span> bind <span class="hljs-keyword">to</span><br>max-<span class="hljs-literal">line</span>-length<span class="hljs-number">512</span>Max <span class="hljs-literal">line</span> length per event <span class="hljs-keyword">body</span> (<span class="hljs-keyword">in</span> bytes)<br>ack-every-event<span class="hljs-literal">true</span>Respond <span class="hljs-keyword">with</span> an “OK” <span class="hljs-keyword">for</span> every event received<br>selector.<span class="hljs-keyword">type</span>replicatingreplicating <span class="hljs-keyword">or</span> multiplexing<br>selector.* Depends <span class="hljs-keyword">on</span> the selector.<span class="hljs-keyword">type</span> value<br>interceptors–Space-separated list <span class="hljs-keyword">of</span> interceptors<br>interceptors.*  <br></code></pre></td></tr></table></figure><p>关于channel参数</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><br>Property <span class="hljs-type">Name</span><span class="hljs-keyword">Default</span>Description<br><span class="hljs-keyword">type</span>–The component <span class="hljs-keyword">type</span> <span class="hljs-type">name</span>, needs <span class="hljs-keyword">to</span> be memory<br>capacity<span class="hljs-number">100</span>The maximum number <span class="hljs-keyword">of</span> events stored <span class="hljs-keyword">in</span> the channel<br>transactionCapacity<span class="hljs-number">100</span>The maximum number <span class="hljs-keyword">of</span> events the channel will take <span class="hljs-keyword">from</span> a source <span class="hljs-keyword">or</span> give <span class="hljs-keyword">to</span> a sink per <span class="hljs-keyword">transaction</span><br>keep-alive<span class="hljs-number">3</span>Timeout <span class="hljs-keyword">in</span> seconds <span class="hljs-keyword">for</span> adding <span class="hljs-keyword">or</span> removing an event<br>byteCapacityBufferPercentage<span class="hljs-number">20</span>Defines the percent <span class="hljs-keyword">of</span> buffer <span class="hljs-keyword">between</span> byteCapacity <span class="hljs-keyword">and</span> the estimated total size <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> events <span class="hljs-keyword">in</span> the channel, <span class="hljs-keyword">to</span> account <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> headers. See below.<br>byteCapacitysee descriptionMaximum total bytes <span class="hljs-keyword">of</span> memory allowed <span class="hljs-keyword">as</span> a sum <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> events <span class="hljs-keyword">in</span> this channel. The implementation <span class="hljs-keyword">only</span> counts the Event body, which <span class="hljs-keyword">is</span> the reason <span class="hljs-keyword">for</span> providing the byteCapacityBufferPercentage <span class="hljs-keyword">configuration</span> parameter <span class="hljs-keyword">as</span> well. Defaults <span class="hljs-keyword">to</span> a computed <span class="hljs-keyword">value</span> equal <span class="hljs-keyword">to</span> <span class="hljs-number">80</span>% <span class="hljs-keyword">of</span> the maximum memory available <span class="hljs-keyword">to</span> the JVM (i.e. <span class="hljs-number">80</span>% <span class="hljs-keyword">of</span> the -Xmx <span class="hljs-keyword">value</span> passed <span class="hljs-keyword">on</span> the command <span class="hljs-type">line</span>). Note that <span class="hljs-keyword">if</span> you have multiple memory channels <span class="hljs-keyword">on</span> a single JVM, <span class="hljs-keyword">and</span> they happen <span class="hljs-keyword">to</span> hold the same physical events (i.e. <span class="hljs-keyword">if</span> you are <span class="hljs-keyword">using</span> a replicating channel selector <span class="hljs-keyword">from</span> a single source) <span class="hljs-keyword">then</span> those event sizes may be <span class="hljs-type">double</span>-counted <span class="hljs-keyword">for</span> channel byteCapacity purposes. Setting this <span class="hljs-keyword">value</span> <span class="hljs-keyword">to</span> <span class="hljs-number">0</span> will cause this <span class="hljs-keyword">value</span> <span class="hljs-keyword">to</span> fall back <span class="hljs-keyword">to</span> a hard <span class="hljs-type">internal</span> <span class="hljs-keyword">limit</span> <span class="hljs-keyword">of</span> about <span class="hljs-number">200</span> GB.<br></code></pre></td></tr></table></figure><p>关于sink</p><figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs delphi"><br><span class="hljs-keyword">Property</span> <span class="hljs-keyword">Name</span><span class="hljs-keyword">Default</span>Description<br>channel– <br><span class="hljs-keyword">type</span>–The component <span class="hljs-keyword">type</span> <span class="hljs-keyword">name</span>, needs <span class="hljs-keyword">to</span> be logger<br>maxBytesToLog<span class="hljs-number">16</span>Maximum number <span class="hljs-keyword">of</span> bytes <span class="hljs-keyword">of</span> the Event body <span class="hljs-keyword">to</span> log<br></code></pre></td></tr></table></figure><p>然后启动我们的flume</p><p>执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p><p>然后执行talent localhost 44444</p><p>往里面发送内容，在我们启动flume的session就会发现内容</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">53</span>,<span class="hljs-number">172</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">31</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">1</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">54</span>,<span class="hljs-number">427</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">32</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">2</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">54</span>,<span class="hljs-number">877</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">33</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">3</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">55</span>,<span class="hljs-number">237</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">34</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">4</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">55</span>,<span class="hljs-number">565</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">35</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">5</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">55</span>,<span class="hljs-number">891</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">36</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">6</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">56</span>,<span class="hljs-number">238</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">37</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">7</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">56</span>,<span class="hljs-number">609</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">38</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">8</span>. &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">11</span>:<span class="hljs-number">57</span>,<span class="hljs-number">272</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">39</span> <span class="hljs-number">0</span>D                                           <span class="hljs-number">9</span>. &#125;<br></code></pre></td></tr></table></figure><p>如上 ：</p><p>生产上常见的</p><ul><li>采集log文件到hdfs上</li><li>采集log文件到hive</li><li>待机log文件到kafka里</li><li>采集kafka数据到hdfs</li><li>采集kafka数据到hive</li><li>采集数据到下一个agent里</li></ul><p>source ：</p><ul><li>netcat ： 采集端口数据 ： 学习测试</li><li>日志文件</li><li>kafka</li><li>agent</li></ul><p>采集日志文件</p><ul><li>exec</li><li>spooldir</li><li>taildir</li></ul><p>采集数据文件到控制台</p><ul><li>source ： exec</li><li>channel  ： memory</li><li>sink ： logger</li></ul><h1 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h1><p>编写agent</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = exec<br><span class="hljs-attr">a1.sources.r1.command</span> = tail -F /home/hadoop/data/loger.txt<br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>然后执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p><p>结果如下 ：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">39</span>:<span class="hljs-number">25</span>,<span class="hljs-number">755</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">31</span>                                              <span class="hljs-number">1</span> &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">39</span>:<span class="hljs-number">55</span>,<span class="hljs-number">761</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span>                                     aaaa &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">40</span>:<span class="hljs-number">01</span>,<span class="hljs-number">909</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span>                                     aaaa &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">40</span>:<span class="hljs-number">10</span>,<span class="hljs-number">910</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">73</span> <span class="hljs-number">73</span>                               aaaass &#125;<br><span class="hljs-number">2022</span>-<span class="hljs-number">12</span>-<span class="hljs-number">12</span> <span class="hljs-number">14</span>:<span class="hljs-number">44</span>:<span class="hljs-number">40</span>,<span class="hljs-number">961</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="hljs-built_in">process</span>(LoggerSink.java:<span class="hljs-number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="hljs-selector-tag">body</span>: <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">73</span> <span class="hljs-number">73</span> <span class="hljs-number">64</span> <span class="hljs-number">73</span> <span class="hljs-number">61</span> <span class="hljs-number">61</span> <span class="hljs-number">64</span> <span class="hljs-number">73</span>             aaaassdsaads &#125;<br></code></pre></td></tr></table></figure><p>上面的body里的东西是ascII码值的16进制</p><p>exec 的方式采集数据的时候，如果停掉flume，然后重新启动的时候，还会再次把文件里的数据再采集一次，造成数据双倍，能用，但是不建议</p><h1 id="spoolingdir"><a href="#spoolingdir" class="headerlink" title="spoolingdir"></a>spoolingdir</h1><p>接下来spooldir的采集文件夹下的文件</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = spooldir<br><span class="hljs-attr">a1.sources.r1.spoolDir</span> = 数据文件夹<br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>然后执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p><p>被采集过的文件会被打上标记，会重命名文件命名为xxx.completed</p><p>然后就不会再次采集到这个文件，哪怕是关闭之后重新启动</p><p>而且往已经采集的文件下再次加入文件内容的时候，flume会被重新启动，且不能采集到新加的内容，而且文件名字不可以重复，如果重复，flume会挂掉，生产上不怎么使用</p><h1 id="taildir"><a href="#taildir" class="headerlink" title="taildir"></a>taildir</h1><p>接下来是taildir ：既可以采集文件夹，也可以采集单个文件，且有断点续传的作用</p><p>但是它并不能运行在windows上</p><p>编写agent</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = TAILDIR<br><span class="hljs-attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json<br><span class="hljs-attr">a1.sources.r1.filegroups</span> = f1 f2<br><span class="hljs-attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt<br><span class="hljs-attr">a1.sources.r1.headers.f1.headerKey1</span> = value1<br><span class="hljs-attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey1</span> = value2<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="hljs-number">2</span><br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><span class="hljs-attr">a1.sources.ri.maxBatchCount</span> = <span class="hljs-number">1000</span><br><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = logger<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>然后运行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p><p>它可以实时性的采集数据，是生产上重点，一般都用它，在flume里模糊匹配的语法要加个点在可以</p><p>断点续传的文件，a1.sources.r1.positionFile &#x3D; &#x2F;var&#x2F;log&#x2F;flume&#x2F;taildir_position.json</p><p>可以自己定义，或者是默认，默认是在~&#x2F;.flume&#x2F;taildir_position.json</p><h1 id="sink-：-hdfs"><a href="#sink-：-hdfs" class="headerlink" title="sink ： hdfs"></a>sink ： hdfs</h1><p>指定到hdfs上</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = TAILDIR<br><span class="hljs-attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json<br><span class="hljs-attr">a1.sources.r1.filegroups</span> = f1 f2<br><span class="hljs-attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt<br><span class="hljs-attr">a1.sources.r1.headers.f1.headerKey1</span> = value1<br><span class="hljs-attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey1</span> = value2<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="hljs-number">2</span><br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><span class="hljs-attr">a1.sources.ri.maxBatchCount</span> = <span class="hljs-number">1000</span><br><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hdfs<br><span class="hljs-attr">a1.sinks.k1.hdfs.path</span> = hdfs://bigdata3:<span class="hljs-number">9000</span>/data<br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>flume存储的数据才hdfs山观察看不了，因为其默认的数据格式不对</p><p>更改</p><ul><li>hdfs.filetype DataStream</li><li>hdfs.writeFormat : Text</li></ul><p>如下</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = TAILDIR<br><span class="hljs-attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json<br><span class="hljs-attr">a1.sources.r1.filegroups</span> = f1 f2<br><span class="hljs-attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt<br><span class="hljs-attr">a1.sources.r1.headers.f1.headerKey1</span> = value1<br><span class="hljs-attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey1</span> = value2<br><span class="hljs-attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="hljs-number">2</span><br><span class="hljs-attr">a1.sources.r1.fileHeader</span> = <span class="hljs-literal">true</span><br><span class="hljs-attr">a1.sources.ri.maxBatchCount</span> = <span class="hljs-number">1000</span><br><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hdfs<br><span class="hljs-attr">a1.sinks.k1.hdfs.path</span> = hdfs://bigdata3:<span class="hljs-number">9000</span>/data<br><span class="hljs-attr">a1.sinks.k1.hdfs.fileType</span> = DataStream<br><span class="hljs-attr">a1.sinks.k1.hdfs.writeFormat</span> = Text<br><span class="hljs-attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="hljs-number">134217728</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="hljs-number">21</span>,<span class="hljs-number">600</span><br><span class="hljs-attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="hljs-number">1000</span><br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure><p>执行 ：<code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p><p>采集的时候要注意：</p><p>因为采集数据会造成小文件问题就是当flume在采集的时候，如果文件一直发生变化的时候，flume可能会造成有多个小文件</p><p>可以通过增加参数进行设置</p><ul><li>按照条数进行滚动：就是生成下一个文件</li><li>按照时间进行滚动：就是生成下一个文件</li><li>hdfs.round &#x3D;&gt; 文件滚动的开关</li><li>hdfs.batchSize &#x3D;&gt; 按照条目数滚动，一般不会用</li><li>hdfs.roundUnit &#x3D;&gt; 按照时间滚动</li><li>hdfs.roundValue &#x3D;&gt; 时间滚动的具体值</li></ul><h3 id="上面有的时候不好用，下面是一定好用的"><a href="#上面有的时候不好用，下面是一定好用的" class="headerlink" title="上面有的时候不好用，下面是一定好用的"></a>上面有的时候不好用，下面是一定好用的</h3><ul><li>hdfs.rollSize &#x3D;&gt; 按照大小进行滚动 默认是字节</li><li>hdfs.rollInterval &#x3D;&gt;按照时间进行滚动，秒为单位</li><li>hdfs.rollCount &#x3D;&gt; 文件里存的数据条数进行滚动</li></ul><h1 id="Sink-hive"><a href="#Sink-hive" class="headerlink" title="Sink:hive"></a>Sink:hive</h1><p>以下是官方提供的hive的flume参数</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">a1.channels</span> = c1<br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.sinks.k1.type</span> = hive // 类型<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1 <br><span class="hljs-attr">a1.sinks.k1.hive.metastore</span> = thrift://bigdata3:<span class="hljs-number">9083</span> //元数据库<br><span class="hljs-attr">a1.sinks.k1.hive.database</span> = logsdb 数据库<br><span class="hljs-attr">a1.sinks.k1.hive.table</span> = weblogs 表<br><span class="hljs-attr">a1.sinks.k1.hive.partition</span> = asia,%&#123;country&#125;,%Y-%m-%d-%H-%M 分区字段<br><span class="hljs-attr">a1.sinks.k1.useLocalTimeStamp</span> = <span class="hljs-literal">false</span> 是不是使用本地时间戳<br><span class="hljs-attr">a1.sinks.k1.round</span> = <span class="hljs-literal">true</span> <br><span class="hljs-attr">a1.sinks.k1.roundValue</span> = <span class="hljs-number">10</span><br><span class="hljs-attr">a1.sinks.k1.roundUnit</span> = minute <br><span class="hljs-attr">a1.sinks.k1.serializer</span> = DELIMITED   负责解析事件中的字段并将它们映射到hive表中的列 <br><span class="hljs-attr">a1.sinks.k1.serializer.delimiter</span> = <span class="hljs-string">&quot;\t&quot;</span> 传入数据的分隔符（每个字段之间的）<br><span class="hljs-attr">a1.sinks.k1.serializer.serdeSeparator</span> = <span class="hljs-string">&#x27;\t&#x27;</span> 输出字段分隔符,单引号括起来，例如<span class="hljs-string">&#x27;\t&#x27;</span><br><span class="hljs-attr">a1.sinks.k1.serializer.fieldnames</span> =id,,msg 参数名字（表的）<br></code></pre></td></tr></table></figure><p>然后我们自己写一个</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># example.conf: A single-node Flume configuration</span><br><br><span class="hljs-comment"># Name the components on this agent</span><br><span class="hljs-attr">a1.sources</span> = r1<br><span class="hljs-attr">a1.sinks</span> = k1<br><span class="hljs-attr">a1.channels</span> = c1<br><br><span class="hljs-comment"># Describe/configure the source</span><br><span class="hljs-attr">a1.sources.r1.type</span> = TAILDIR<br><span class="hljs-attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json<br><span class="hljs-attr">a1.sources.r1.filegroups</span> = f1<br><span class="hljs-attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/emp_202211301118.csv<br><span class="hljs-attr">a1.sources.r1.headers.f1.headerKey1</span> = value1<br><br><br><span class="hljs-comment"># Describe the sink</span><br><span class="hljs-attr">a1.sinks.k1.type</span> = hive<br><span class="hljs-attr">a1.sinks.k1.hive.metastore</span> = thrift://bigdata2:<span class="hljs-number">9083</span><br><span class="hljs-attr">a1.sinks.k1.hive.database</span> = bigdata_hive3<br><span class="hljs-attr">a1.sinks.k1.hive.table</span> = emp22<br><span class="hljs-attr">a1.sinks.k1.serializer</span> = DELIMITED<br><span class="hljs-attr">a1.sinks.k1.serializer.delimiter</span> = <span class="hljs-string">&quot;,&quot;</span><br><span class="hljs-attr">a1.sinks.k1.serializer.serdeSeparator</span> = <span class="hljs-string">&#x27;,&#x27;</span><br><span class="hljs-attr">a1.sinks.k1.serializer.fieldnames</span> =emp<span class="hljs-literal">no</span>,ename,job,mgr,hiredate,sal,comm,dept<span class="hljs-literal">no</span><br><br><br><span class="hljs-comment"># Use a channel which buffers events in memory</span><br><span class="hljs-attr">a1.channels.c1.type</span> = memory<br><span class="hljs-attr">a1.channels.c1.capacity</span> = <span class="hljs-number">1000</span><br><span class="hljs-attr">a1.channels.c1.transactionCapacity</span> = <span class="hljs-number">100</span><br><br><span class="hljs-comment"># Bind the source and sink to the channel</span><br><span class="hljs-attr">a1.sources.r1.channels</span> = c1<br><span class="hljs-attr">a1.sinks.k1.channel</span> = c1<br></code></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/12/12-12/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>云原生教学视频</title>
      <link>http://zihang.fun/2022/12/10/12-08/</link>
      <guid>http://zihang.fun/2022/12/10/12-08/</guid>
      <pubDate>Sat, 10 Dec 2022 03:38:03 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;云原生&quot;&gt;&lt;a href=&quot;#云原生&quot; class=&quot;headerlink&quot; title=&quot;云原生&quot;&gt;&lt;/a&gt;云原生&lt;/h1&gt;&lt;p&gt;理解 ： 理解上要把他们拆开理解会更好&lt;/p&gt;
&lt;p&gt;云 ：云基础设施（cloud）&lt;/p&gt;
&lt;p&gt;原生：native ：在云计算平</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="云原生"><a href="#云原生" class="headerlink" title="云原生"></a>云原生</h1><p>理解 ： 理解上要把他们拆开理解会更好</p><p>云 ：云基础设施（cloud）</p><p>原生：native ：在云计算平台里可以原生的计算和运行的</p><p>云原生的概念由来：<br>2013年被prvoyal公司的Ms提出</p><p>2015年谷歌带头成立了云原生的计算基金会</p><p>云原生的定义 ：</p><p>基于微服务原理而开发的应用，用容器的方式打包，在运行时，容器由运行于云基础设施之上的平台进行调度，应用开发采用持续交付和devOps实践</p><p>2015年：容器化封装+自动化管理+面向微服务</p><p>2018年：容器化封装+面向微服务+服务网格+声明格式API</p><p>云原生有利于各种组织在共有云，私有云和混合云等新动态环境中，构建和运行可扩展性的应用</p><p>微服务 ：把原有的单体应用拆分为多个独立自治的组件，每个组件都可以独立开发，设计，测试，运维，部署，这个组件可以单独的对外进行服务，我们称其为微服务</p><p>容器化：docker容器，容器属于it基础设施层概念，是比虚拟机更轻量化的隔离工具，是微服务的最佳载体</p><p>使用k8s的资源调度与容器编排，可以实现docker容器更优管理，进一步实现其PaaS能力</p><p>服务网格</p><p>服务网格存在的目的，就是中心化的服务治理框架</p><p>以往需要对微服务或者对api接口区做治理和管理请求</p><p>不可以改变基础设施指的是镜像：日后如果想再次改变他的部署，可以用镜像进行改变</p><p>应用部署：命令行：声明式</p><p>DevOps</p><p>借助云原生的相关技术，DevOps的时代才到来</p><p>云原生的最佳实现的实现三个层面</p><p>服务编排要实现计算资源弹性化</p><p>服务构建和部署要实现高可用</p><p>实践驱动基础设施标准初始化</p><p>云原生应用的领域</p><p>云原生的生态也已经覆盖到了，大数据，人工智能，边缘计算，区域局等领域</p><p>云原生的编排以及管理</p><p>编排与调度k8s</p><p>原生调用grpc</p><p>服务代理envoy</p><p>api网关apisix</p><p>服务网格istio</p><p>服务发现coreDns</p><p>消息和流式处理kafka</p><p>Severless ：只是对服务器的关心比较少，并不是完全无服务器</p><p>自动化配置：ansible</p><p>数据库：不赘述了</p><p>容器镜像仓库：harbor</p><p>定义及镜像制作：helm</p><p>密钥管理：spiffe</p><p>存储技术：ceph</p><p>网络技术：calico</p><p>监控分析：prometheus</p><p>等</p><h1 id="4步制作超级精简的大厂docker镜像"><a href="#4步制作超级精简的大厂docker镜像" class="headerlink" title="4步制作超级精简的大厂docker镜像"></a>4步制作超级精简的大厂docker镜像</h1><h2 id="什么是镜像"><a href="#什么是镜像" class="headerlink" title="什么是镜像"></a>什么是镜像</h2><p>镜像是：分层联合文件系统</p><p>一种轻量级，可执行的独立软件包</p><p>镜像大小：有大有小</p><p>曾经网易蜂巢logo镜像只有585B</p><p><code>docker pull hub.c.163.com/public/logo</code></p><p>精简docker镜像的优势</p><p>减少构建时间</p><p>减少磁盘使用量</p><p>减少下载时间</p><p>提高安全性</p><h2 id="镜像的分层原理"><a href="#镜像的分层原理" class="headerlink" title="镜像的分层原理"></a>镜像的分层原理</h2><p>doccker镜像的分层</p><p>第一层：本机的系统</p><p>第二层：镜像上安装的虚拟环境比如：python</p><p>第三层：打的补丁文件</p><p><code>docker pull busybox:latest</code></p><p>拉下来之后我们对它进行多层的镜像,进行演示一遍</p><p>拉下来之后随便找个地方创建个文件叫dockerfile</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><br><span class="hljs-keyword">FROM</span> busybox<br><span class="hljs-built_in">RUN</span> mkdir /tmp/foo<br><span class="hljs-built_in">RUN</span> dd <span class="hljs-attribute">if</span>=/dev/zero <span class="hljs-attribute">of</span>=/tmp/foo/bar <span class="hljs-attribute">bs</span>=1048576 <span class="hljs-attribute">count</span>=100<br><span class="hljs-built_in">RUN</span> rm /tmp/foo/bar<br>EOF<br></code></pre></td></tr></table></figure><p>上面这个是设置swap的交换分区的代码，count后面跟着的是字节数，bs是每秒的吞吐量</p><p>然后同步到docker容器上并执行这个文件 <code>docker build -t busybox:text . </code>这个语句的意思是根据本地镜像，加上我们的文本语句，进行创建我们的一个新的docker镜像，后面的.代表这个文件夹里所有的文本文件，也可以单独指明是哪一个文本文件</p><p>运行之前</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@VM-8-16-centos dockerfile]# docker images | grep busybox<br>busybox                     latest    334e4a014c81   4 days ago      4.86MB<br><br></code></pre></td></tr></table></figure><p>运行之后</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">[root@VM-8-16-centos dockerfile]# docker images | grep busybox<br>busybox                     text      efa9b412f2f7   4 minutes ago   110MB<br>busybox                     latest    334e4a014c81   4 days ago      4.86MB<br></code></pre></td></tr></table></figure><p>这个新的镜像是基于我们之前的busybox进行创建的，而且执行了上面的分区文件</p><p>我们通过代码查看一下我们的容器代码情况 通过 <code>docker inspect busybox:容器的标识</code></p><p>容器的标识就是 TAG</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">REPOSITORY                  TAG       IMAGE ID       CREATED             SIZE<br>busybox                     text      efa9b412f2f7   About an hour ago   110MB<br>busybox                     latest    334e4a014c81   4 days ago          4.86MB<br>gitlab/gitlab-ce            latest    08f00af277b7   5 days ago          2.79GB<br>hub.c.163.com/public/logo   latest    6fbdd13cd204   6 years ago         585B<br></code></pre></td></tr></table></figure><p>然后我们分别查看一下text和latest的代码情况，我们查看最后的layter有几层</p><p><code>docker inspect busybox:text</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">&quot;Layers&quot;: [<br>                &quot;sha256:98004ed6104b2f4cc21559ea6e4a742ebf6731e37b5d1b04013ca68862749ba3&quot;,<br>                &quot;sha256:c7a7aa6d1d87d0af266545bb8a56bdedfc79a14be948c092900ffb841c919c87&quot;,<br>                &quot;sha256:88d1f859f65e27bca2996107976f04ed974c062b507b33b2388b2228b5d80122&quot;,<br>                &quot;sha256:8e9b239d68ef8acc6fe2b2a82c7c803a79f0bdc5bf200b6d35fc2b062de24963&quot;<br>            ]<br></code></pre></td></tr></table></figure><p><code>docker inspect busybox:latest</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">&quot;Layers&quot;: [<br>               &quot;sha256:98004ed6104b2f4cc21559ea6e4a742ebf6731e37b5d1b04013ca68862749ba3&quot;<br>           ]<br>       &#125;,<br><br></code></pre></td></tr></table></figure><p>简单来说，一个run就是一层</p><h2 id="制作精简镜像"><a href="#制作精简镜像" class="headerlink" title="制作精简镜像"></a>制作精简镜像</h2><p>但是我们如何精简镜像呢，就像上述所说，仅仅用了三个命令，就多了100m</p><p>而且docker最多只有127个run</p><p>接下来我们来制作一个精简的redis的docker镜像</p><p>先创建一个dockerfile2文件在文件中输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs shell">FROM 192.168.5.160/library/ubantu:trusty<br>ENV VER    3.0.0<br>ENV TARBALL http://download.redis.io/releases/redis-$VER.tar.gz<br>RUN apt-get update<br>RUN apt-get install -y curl make gcc<br>RUN curl -L $TARBALL | tar zxv<br>WORKDIR redis-$$VER<br>RUN make<br>RUN make install<br>WORKDIR /<br>RUN apt-get remove -y --auto-remove curl make gcc<br>RUN apt-get clean<br>RUN rm -rf /var/lib/apt/lists/* /redis-$$VER<br><br></code></pre></td></tr></table></figure><p>save 和 export</p><p>导出的区别 ：</p><p>export 导出的包括的东西更多一点，它有压缩功能，保留历史层，有历史层的可以进行回滚操作 ;算是导出容器，</p><p>容器相当于镜像加个读写层</p><p>save 导出的仅仅是镜像，不保留历史层</p><p>但是下完之后是300多M有点大</p><p>我们对他进行缩小</p><p>缩小的方式</p><p>用更小的基础镜像 <code>debain</code></p><p>如下</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> <span class="hljs-number">192.168</span>.<span class="hljs-number">5.160</span>/library/debain:jessie<br><span class="hljs-keyword">ENV</span> VER    <span class="hljs-number">3.0</span>.<span class="hljs-number">0</span><br><span class="hljs-keyword">ENV</span> TARBALL http://download.redis.io/releases/redis-$VER.tar.gz<br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get update</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get install -y curl make gcc</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> curl -L <span class="hljs-variable">$TARBALL</span> | tar zxv</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> redis-$<span class="hljs-variable">$VER</span></span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> make</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> make install</span><br><span class="hljs-keyword">WORKDIR</span><span class="language-bash"> /</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get remove -y --auto-remove curl make gcc</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> apt-get clean</span><br><span class="hljs-keyword">RUN</span><span class="language-bash"> <span class="hljs-built_in">rm</span> -rf /var/lib/apt/lists/* /redis-$<span class="hljs-variable">$VER</span></span><br></code></pre></td></tr></table></figure><p>成功之后会发现少了很多的空间</p><p>然后再进一步瘦身<br>把dockerfile里的命令串联起来</p><p>如下</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs awk"><br>FROM <span class="hljs-number">192.168</span>.<span class="hljs-number">5.160</span><span class="hljs-regexp">/library/</span>debain:jessie<br>ENV VER    <span class="hljs-number">3.0</span>.<span class="hljs-number">0</span><br>ENV TARBALL http:<span class="hljs-regexp">//</span>download.redis.io<span class="hljs-regexp">/releases/</span>redis-<span class="hljs-variable">$VER</span>.tar.gz<br>RUN apt-get update &amp;&amp; \<br>apt-get install -y curl make gcc &amp;&amp; \<br>curl -L <span class="hljs-variable">$TARBALL</span> | tar zxv &amp;&amp; \<br>WORKDIR redis-$<span class="hljs-variable">$VER</span> &amp;&amp; \<br>make &amp;&amp; \<br>make install &amp;&amp; \<br>WORKDIR / &amp;&amp; \<br>apt-get remove -y --auto-remove curl make gcc &amp;&amp; \<br>apt-get clean &amp;&amp; \<br>rm -rf <span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/apt/</span>lists<span class="hljs-regexp">/* /</span>redis-$<span class="hljs-variable">$VER</span><br></code></pre></td></tr></table></figure><p>通过串联命令编排之后的镜像体积比不编排的能小上一半左右</p><p>压缩镜像 ： 但是有时候并不会好使，但是能压缩多少就压缩多少吧，对一个外来镜像进行压缩的时候，可能会比较明显</p><p><code>docker save 镜像的名字 | docker-squash -verbose -t 生成的镜像的名字 | docker load 这个对mac不好使，再linux可以</code></p><p>使用容器专用的基础镜像 —— scratch 或者busybox作为基础镜像</p><p>上面两个是空镜像，所以我们可以把docker里的程序文件拿出来，打包成gz的压缩包</p><p>然后再用空镜像再次生成一个容器，进行极致的压缩</p><p>这种方式进行的docker容器对于redis而言，会被压缩到个位数的空间，而且可以正常运行</p><p>dockerfile</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> scratch<br><span class="hljs-keyword">ADD</span><span class="language-bash"> 压缩的文件及其依赖 /</span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> redis.conf /etc/redis/redis.conf</span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">6379</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;usr/local/bin/redis-server&quot;</span>]</span><br> <span class="hljs-keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="hljs-string">&quot;docker-entrypoint.sh&quot;</span>]</span><br></code></pre></td></tr></table></figure><p>其中压缩的文件是从debain上搞来的依赖，以及redis的包一起打的压缩</p><p>EXPOSE ：设置的是端口</p><p>查询依赖的方式，通过 ldd 查出所需要的.so文件</p><p>然后把所以依赖都打包成tar或者gz文件，用scratch</p><p>至于如何获取空镜像，我们可以通过官网命令 <code>tar cv --files-from /dev/null | docker import - scratch</code></p><p>就会自动获取了</p><p>实操</p><p>首先拉去空镜像</p><p>对于已经拉去过空镜像的同学就不用了</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">tar cv --files-<span class="hljs-keyword">from</span> <span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span> | docker <span class="hljs-keyword">import</span> - scratch<br></code></pre></td></tr></table></figure><p>拉去之后找到我们的模板机</p><p>然后进入我们的模板机里 <code>docker exec -it 名字 /bin/bash</code></p><p>然后找到我们的程序比如我找的是redis-server</p><p>然后我们找到之后通过ldd命令查看他的依赖 <code>ldd redis-srever</code></p><p>查看到依赖之后把文件夹结构以及文件都弄出来，通过cp命令 <code> docker cp 模板机的名字:文件路径 宿主机的路径</code></p><p>然后我们把所有的文件，都打包成一个tar.gz <code>tar -zxcf 生成的文件名（带tar.gz的） 打包的内容的路径</code></p><p>然后我们编辑dockerfile文件如下</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dockerfile"><span class="hljs-keyword">FROM</span> scratch <span class="hljs-comment">#从什么镜像中创建</span><br><span class="hljs-keyword">ADD</span><span class="language-bash"> 压缩的文件及其依赖 / <span class="hljs-comment"># 通过ADD可以把文件自动解压</span></span><br><span class="hljs-keyword">COPY</span><span class="language-bash"> redis.conf /etc/redis/redis.conf <span class="hljs-comment">#redis 的配置文件</span></span><br><span class="hljs-keyword">EXPOSE</span> <span class="hljs-number">6379</span> <span class="hljs-comment">#端口号</span><br><span class="hljs-keyword">CMD</span><span class="language-bash"> [<span class="hljs-string">&quot;usr/local/bin/redis-server&quot;</span>] <span class="hljs-comment">#这个相当于解释器，要用的</span></span><br></code></pre></td></tr></table></figure><p>然后执行 <code>docker build -t 生成的容器的内容 -f dockerfile</code></p><p>构建容器，最后成功之后，通过 <code>docker run -d --name 你的image的名字 你自己起的名字 </code></p><p>然后就运行成功了</p><p>我们通过docker images</p><p>查看一下存储大小如下 ：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">redis</span>-<span class="hljs-number">01</span>           latest    c654e9a88af9   <span class="hljs-number">13</span> minutes ago   <span class="hljs-number">22</span>.<span class="hljs-number">3</span>MB<br><span class="hljs-attribute">scratch</span>            latest    <span class="hljs-number">89</span>a161411e52   <span class="hljs-number">2</span> hours ago      <span class="hljs-number">0</span>B<br><span class="hljs-attribute">busybox</span>            latest    <span class="hljs-number">334</span>e4a014c81   <span class="hljs-number">4</span> days ago       <span class="hljs-number">4</span>.<span class="hljs-number">86</span>MB<br><span class="hljs-attribute">redis</span>              latest    <span class="hljs-number">3</span>e12e2ceb68f   <span class="hljs-number">5</span> days ago       <span class="hljs-number">117</span>MB<br><span class="hljs-attribute">gitlab</span>/gitlab-ce   latest    <span class="hljs-number">08</span>f00af277b7   <span class="hljs-number">5</span> days ago       <span class="hljs-number">2</span>.<span class="hljs-number">79</span>GB<br></code></pre></td></tr></table></figure><p>如上所属，redis-01 是我们自己创建的，redis是官方提供的</p><p>差距显而易见</p><h2 id="构建企业debian-10-基础测试镜像"><a href="#构建企业debian-10-基础测试镜像" class="headerlink" title="构建企业debian 10 基础测试镜像"></a>构建企业debian 10 基础测试镜像</h2>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E4%BA%91%E5%8E%9F%E7%94%9F%EF%BC%88%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%EF%BC%89/">云原生（哔哩哔哩）</category>
      
      
      
      <comments>http://zihang.fun/2022/12/10/12-08/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>数据可视化</title>
      <link>http://zihang.fun/2022/12/07/12-07/</link>
      <guid>http://zihang.fun/2022/12/07/12-07/</guid>
      <pubDate>Wed, 07 Dec 2022 00:53:05 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;数据可视化的数据库选择&quot;&gt;&lt;a href=&quot;#数据可视化的数据库选择&quot; class=&quot;headerlink&quot; title=&quot;数据可视化的数据库选择&quot;&gt;&lt;/a&gt;数据可视化的数据库选择&lt;/h1&gt;&lt;p&gt;一般选择响应数据库比较快的一般是 秒级，或者毫秒级 ： 不要选择hi</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="数据可视化的数据库选择"><a href="#数据可视化的数据库选择" class="headerlink" title="数据可视化的数据库选择"></a>数据可视化的数据库选择</h1><p>一般选择响应数据库比较快的一般是 秒级，或者毫秒级 ： 不要选择hive</p><p>因为hive太慢</p><p>我们一般都把数据最后导入到mysql里</p><p>作业：</p><p>自己做一个dashboard</p><h1 id="xxl"><a href="#xxl" class="headerlink" title="xxl"></a>xxl</h1><p>定时任务调度</p><p>就是按照每天都要做的任务</p><ul><li>crontab 进行 用的比较少 而因为不方便</li><li>定时任务的调度的框架<ul><li>ozio , azkaban,airflow,xxl,dolphinscheduler</li><li>现在ozio 和 azkaban 因为操作比较反人类，所以不太推荐</li><li>airflow ： 通过python进行任务调度的</li><li>公司首选 dolphinscheduler ，其次 xxl</li></ul></li><li>针对 xxl 或者 dolphinscheduler 可以串联的方式进行执行调度，就是a任务完成，直接执行b任务等等</li><li>但是crontab它要设置时间间隔，不可以串联的方式进行执行</li><li>多任务之间的依赖关系 ：<ul><li>DAG 有向无环图</li></ul></li><li>xxl 官网 ： 国人开发的 <code>https://github.com/xuxueli/xxl-job</code><ul><li>架构：主从架构，分布式架构</li><li>老大：调度中心</li><li>小弟：调度器</li></ul></li><li>其他的都是apache的</li></ul><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>下载源码 ；</p><p>导入idea 进行编译</p><p>初始化“调度数据库”xxl源数据库 -》 mysql中</p><p>首先在mysql中执行语句</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><code class="hljs n1ql">#<br># XXL-JOB v2.4.0-SNAPSHOT<br># Copyright (c) 2015-present, xuxueli.<br><br><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">database</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span> <span class="hljs-symbol">`xxl_job`</span> default character <span class="hljs-keyword">set</span> utf8mb4 <span class="hljs-keyword">collate</span> utf8mb4_unicode_ci;<br>use `xxl_job`;<br><br>SET NAMES utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_info`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`job_group`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器主键ID&#x27;</span>,<br>  <span class="hljs-symbol">`job_desc`</span> varchar(<span class="hljs-number">255</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`add_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`update_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`author`</span> varchar(<span class="hljs-number">64</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;作者&#x27;</span>,<br>  <span class="hljs-symbol">`alarm_email`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;报警邮件&#x27;</span>,<br>  <span class="hljs-symbol">`schedule_type`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;NONE&#x27;</span> COMMENT <span class="hljs-string">&#x27;调度类型&#x27;</span>,<br>  <span class="hljs-symbol">`schedule_conf`</span> varchar(<span class="hljs-number">128</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;调度配置，值含义取决于调度类型&#x27;</span>,<br>  <span class="hljs-symbol">`misfire_strategy`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;DO_NOTHING&#x27;</span> COMMENT <span class="hljs-string">&#x27;调度过期策略&#x27;</span>,<br>  <span class="hljs-symbol">`executor_route_strategy`</span> varchar(<span class="hljs-number">50</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器路由策略&#x27;</span>,<br>  <span class="hljs-symbol">`executor_handler`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器任务handler&#x27;</span>,<br>  <span class="hljs-symbol">`executor_param`</span> varchar(<span class="hljs-number">512</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器任务参数&#x27;</span>,<br>  <span class="hljs-symbol">`executor_block_strategy`</span> varchar(<span class="hljs-number">50</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;阻塞处理策略&#x27;</span>,<br>  <span class="hljs-symbol">`executor_timeout`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;任务执行超时时间，单位秒&#x27;</span>,<br>  <span class="hljs-symbol">`executor_fail_retry_count`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;失败重试次数&#x27;</span>,<br>  <span class="hljs-symbol">`glue_type`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;GLUE类型&#x27;</span>,<br>  <span class="hljs-symbol">`glue_source`</span> mediumtext COMMENT <span class="hljs-string">&#x27;GLUE源代码&#x27;</span>,<br>  <span class="hljs-symbol">`glue_remark`</span> varchar(<span class="hljs-number">128</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;GLUE备注&#x27;</span>,<br>  <span class="hljs-symbol">`glue_updatetime`</span> datetime DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;GLUE更新时间&#x27;</span>,<br>  <span class="hljs-symbol">`child_jobid`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;子任务ID，多个逗号分隔&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_status`</span> tinyint(<span class="hljs-number">4</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;调度状态：0-停止，1-运行&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_last_time`</span> bigint(<span class="hljs-number">13</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;上次调度时间&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_next_time`</span> bigint(<span class="hljs-number">13</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;下次调度时间&#x27;</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_log`</span> (<br>  <span class="hljs-symbol">`id`</span> bigint(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`job_group`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器主键ID&#x27;</span>,<br>  <span class="hljs-symbol">`job_id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;任务，主键ID&#x27;</span>,<br>  <span class="hljs-symbol">`executor_address`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器地址，本次执行的地址&#x27;</span>,<br>  <span class="hljs-symbol">`executor_handler`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器任务handler&#x27;</span>,<br>  <span class="hljs-symbol">`executor_param`</span> varchar(<span class="hljs-number">512</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器任务参数&#x27;</span>,<br>  <span class="hljs-symbol">`executor_sharding_param`</span> varchar(<span class="hljs-number">20</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器任务分片参数，格式如 1/2&#x27;</span>,<br>  <span class="hljs-symbol">`executor_fail_retry_count`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;失败重试次数&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;调度-时间&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_code`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;调度-结果&#x27;</span>,<br>  <span class="hljs-symbol">`trigger_msg`</span> text COMMENT <span class="hljs-string">&#x27;调度-日志&#x27;</span>,<br>  <span class="hljs-symbol">`handle_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行-时间&#x27;</span>,<br>  <span class="hljs-symbol">`handle_code`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行-状态&#x27;</span>,<br>  <span class="hljs-symbol">`handle_msg`</span> text COMMENT <span class="hljs-string">&#x27;执行-日志&#x27;</span>,<br>  <span class="hljs-symbol">`alarm_status`</span> tinyint(<span class="hljs-number">4</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;告警状态：0-默认、1-无需告警、2-告警成功、3-告警失败&#x27;</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>),<br>  <span class="hljs-keyword">KEY</span> <span class="hljs-symbol">`I_trigger_time`</span> (<span class="hljs-symbol">`trigger_time`</span>),<br>  <span class="hljs-keyword">KEY</span> <span class="hljs-symbol">`I_handle_code`</span> (<span class="hljs-symbol">`handle_code`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_log_report`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`trigger_day`</span> datetime DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;调度-时间&#x27;</span>,<br>  <span class="hljs-symbol">`running_count`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;运行中-日志数量&#x27;</span>,<br>  <span class="hljs-symbol">`suc_count`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;执行成功-日志数量&#x27;</span>,<br>  <span class="hljs-symbol">`fail_count`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;执行失败-日志数量&#x27;</span>,<br>  <span class="hljs-symbol">`update_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>),<br>  <span class="hljs-keyword">UNIQUE</span> <span class="hljs-keyword">KEY</span> <span class="hljs-symbol">`i_trigger_day`</span> (<span class="hljs-symbol">`trigger_day`</span>) <span class="hljs-keyword">USING</span> BTREE<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_logglue`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`job_id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;任务，主键ID&#x27;</span>,<br>  <span class="hljs-symbol">`glue_type`</span> varchar(<span class="hljs-number">50</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;GLUE类型&#x27;</span>,<br>  <span class="hljs-symbol">`glue_source`</span> mediumtext COMMENT <span class="hljs-string">&#x27;GLUE源代码&#x27;</span>,<br>  <span class="hljs-symbol">`glue_remark`</span> varchar(<span class="hljs-number">128</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;GLUE备注&#x27;</span>,<br>  <span class="hljs-symbol">`add_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`update_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_registry`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`registry_group`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`registry_key`</span> varchar(<span class="hljs-number">255</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`registry_value`</span> varchar(<span class="hljs-number">255</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-symbol">`update_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>),<br>  <span class="hljs-keyword">KEY</span> <span class="hljs-symbol">`i_g_k_v`</span> (<span class="hljs-symbol">`registry_group`</span>,<span class="hljs-symbol">`registry_key`</span>,<span class="hljs-symbol">`registry_value`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_group`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`app_name`</span> varchar(<span class="hljs-number">64</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器AppName&#x27;</span>,<br>  <span class="hljs-symbol">`title`</span> varchar(<span class="hljs-number">12</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;执行器名称&#x27;</span>,<br>  <span class="hljs-symbol">`address_type`</span> tinyint(<span class="hljs-number">4</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> DEFAULT <span class="hljs-string">&#x27;0&#x27;</span> COMMENT <span class="hljs-string">&#x27;执行器地址类型：0=自动注册、1=手动录入&#x27;</span>,<br>  <span class="hljs-symbol">`address_list`</span> text COMMENT <span class="hljs-string">&#x27;执行器地址列表，多地址逗号分隔&#x27;</span>,<br>  <span class="hljs-symbol">`update_time`</span> datetime DEFAULT <span class="hljs-literal">NULL</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_user`</span> (<br>  <span class="hljs-symbol">`id`</span> int(<span class="hljs-number">11</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> AUTO_INCREMENT,<br>  <span class="hljs-symbol">`username`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;账号&#x27;</span>,<br>  <span class="hljs-symbol">`password`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;密码&#x27;</span>,<br>  <span class="hljs-symbol">`role`</span> tinyint(<span class="hljs-number">4</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;角色：0-普通用户、1-管理员&#x27;</span>,<br>  <span class="hljs-symbol">`permission`</span> varchar(<span class="hljs-number">255</span>) DEFAULT <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;权限：执行器ID列表，多个逗号分割&#x27;</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`id`</span>),<br>  <span class="hljs-keyword">UNIQUE</span> <span class="hljs-keyword">KEY</span> <span class="hljs-symbol">`i_username`</span> (<span class="hljs-symbol">`username`</span>) <span class="hljs-keyword">USING</span> BTREE<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">CREATE</span> TABLE <span class="hljs-symbol">`xxl_job_lock`</span> (<br>  <span class="hljs-symbol">`lock_name`</span> varchar(<span class="hljs-number">50</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span> COMMENT <span class="hljs-string">&#x27;锁名称&#x27;</span>,<br>  <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> (<span class="hljs-symbol">`lock_name`</span>)<br>) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;<br><br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-symbol">`xxl_job_group`</span>(<span class="hljs-symbol">`id`</span>, <span class="hljs-symbol">`app_name`</span>, <span class="hljs-symbol">`title`</span>, <span class="hljs-symbol">`address_type`</span>, <span class="hljs-symbol">`address_list`</span>, <span class="hljs-symbol">`update_time`</span>) <span class="hljs-keyword">VALUES</span> (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;xxl-job-executor-sample&#x27;</span>, <span class="hljs-string">&#x27;示例执行器&#x27;</span>, <span class="hljs-number">0</span>, <span class="hljs-literal">NULL</span>, <span class="hljs-string">&#x27;2018-11-03 22:21:31&#x27;</span> );<br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-symbol">`xxl_job_info`</span>(<span class="hljs-symbol">`id`</span>, <span class="hljs-symbol">`job_group`</span>, <span class="hljs-symbol">`job_desc`</span>, <span class="hljs-symbol">`add_time`</span>, <span class="hljs-symbol">`update_time`</span>, <span class="hljs-symbol">`author`</span>, <span class="hljs-symbol">`alarm_email`</span>, <span class="hljs-symbol">`schedule_type`</span>, <span class="hljs-symbol">`schedule_conf`</span>, <span class="hljs-symbol">`misfire_strategy`</span>, <span class="hljs-symbol">`executor_route_strategy`</span>, <span class="hljs-symbol">`executor_handler`</span>, <span class="hljs-symbol">`executor_param`</span>, <span class="hljs-symbol">`executor_block_strategy`</span>, <span class="hljs-symbol">`executor_timeout`</span>, <span class="hljs-symbol">`executor_fail_retry_count`</span>, <span class="hljs-symbol">`glue_type`</span>, <span class="hljs-symbol">`glue_source`</span>, <span class="hljs-symbol">`glue_remark`</span>, <span class="hljs-symbol">`glue_updatetime`</span>, <span class="hljs-symbol">`child_jobid`</span>) <span class="hljs-keyword">VALUES</span> (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;测试任务1&#x27;</span>, <span class="hljs-string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="hljs-string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="hljs-string">&#x27;XXL&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;CRON&#x27;</span>, <span class="hljs-string">&#x27;0 0 0 * * ? *&#x27;</span>, <span class="hljs-string">&#x27;DO_NOTHING&#x27;</span>, <span class="hljs-string">&#x27;FIRST&#x27;</span>, <span class="hljs-string">&#x27;demoJobHandler&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;SERIAL_EXECUTION&#x27;</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;BEAN&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-string">&#x27;GLUE代码初始化&#x27;</span>, <span class="hljs-string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>);<br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-symbol">`xxl_job_user`</span>(<span class="hljs-symbol">`id`</span>, <span class="hljs-symbol">`username`</span>, <span class="hljs-symbol">`password`</span>, <span class="hljs-symbol">`role`</span>, <span class="hljs-symbol">`permission`</span>) <span class="hljs-keyword">VALUES</span> (<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;admin&#x27;</span>, <span class="hljs-string">&#x27;e10adc3949ba59abbe56e057f20f883e&#x27;</span>, <span class="hljs-number">1</span>, <span class="hljs-literal">NULL</span>);<br><span class="hljs-keyword">INSERT</span> <span class="hljs-keyword">INTO</span> <span class="hljs-symbol">`xxl_job_lock`</span> ( <span class="hljs-symbol">`lock_name`</span>) <span class="hljs-keyword">VALUES</span> ( <span class="hljs-string">&#x27;schedule_lock&#x27;</span>);<br><br>commit;<br><br><br></code></pre></td></tr></table></figure><p>然后再把从GitHub上下载的文件夹用idea打开进行编译</p><p>进行配置我们的web端口以及数据库：在application.properties文件中，然后配置一下</p><p>配置好之后maven，之间打成jar包，然后上传到linux服务器上</p><p>运行java -jar 上传的文件的路径</p><p>然后会报错，就创建个文件夹就好了 <code>mkdir -p /data/applogs/xxl-job</code></p><p>使用su 进行用户切换</p><p>然后通过chown 进行修改组以及用户 <code>chown -R hadoop:hadoop /data</code></p><p>然后再次运行就可以了</p><p>然后在调度器管理页面添加调度器，然后分配任务就可以了</p><h1 id="钉钉报警"><a href="#钉钉报警" class="headerlink" title="钉钉报警"></a>钉钉报警</h1><p>钉钉机器人可发送的类型</p><ul><li>文本</li><li>链接</li><li>markdown</li><li>actioncard</li><li>feedcard</li></ul><p>weget  ： 从互联网上下载的时候用的 ： 下载安装包 ，但是占用网络资源较大，且会一直重复下载直到结果成功，所以占用的资源较大</p><p>curl ： 发送请求的，发送网页请求访问的，也可以进行下载</p><ul><li>-o ： 把访问的一个页面存储到文件里</li></ul><p>机器人发送消息</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ada">curl &#x27;机器人的token&#x27;<br>-H <span class="hljs-symbol">&#x27;Content</span>-<span class="hljs-keyword">type</span>:application/json&#x27;<br>-d &#x27;&#123;<span class="hljs-string">&quot;msgtype&quot;</span> : <span class="hljs-type">text</span>&#125;&#x27;<br></code></pre></td></tr></table></figure><p>需求 ： </p><ul><li>日志数据 ： hdfs 上 linux user_click.log</li><li>例子： u01,鼠标,ios</li></ul><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey"><span class="hljs-built_in">u01,</span>鼠标,ios<br><span class="hljs-built_in">u01,</span>鼠标,ios<br><span class="hljs-built_in">u01,</span>鼠标,ios<br><span class="hljs-built_in">u01,</span>鼠标,ios<br><span class="hljs-built_in">u01,</span>鼠标,ios<br><span class="hljs-built_in">u02,</span>键盘,android<br><span class="hljs-built_in">u02,</span>键盘,android<br><span class="hljs-built_in">u02,</span>键盘,android<br><span class="hljs-built_in">u02,</span>键盘,android<br><span class="hljs-built_in">u03,</span>显示器,ios<br><span class="hljs-built_in">u04,</span>托特包,ios<br></code></pre></td></tr></table></figure><ul><li>业务数据 ：mysql user_info</li></ul><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey"><span class="hljs-built_in">u01,</span>子航<br><span class="hljs-built_in">u02,</span>祖安<br><span class="hljs-built_in">u03,</span>海哥<br><span class="hljs-built_in">u04,</span>轩轩<br></code></pre></td></tr></table></figure><p>统计：</p><p>uid ， name ，sku ， os 每个用户点击商品的次数</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-keyword">select</span> bianhao,shop_name,caozuoxit,<span class="hljs-keyword">count</span>(*) <span class="hljs-keyword">as</span> cishu <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> bianhao,shop_name,caozuoxit;<br></code></pre></td></tr></table></figure><p>取出表中重复数据，的次数做个排序</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">select</span> shop_name,caozuoxit,<span class="hljs-type">name</span>,row_number() <span class="hljs-keyword">over</span> (<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> <span class="hljs-type">name</span>) <span class="hljs-keyword">as</span> rm <span class="hljs-keyword">from</span> (<br><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">left join</span> user_info <span class="hljs-keyword">on</span> user_click1.bianhao=user_info.bianhao<br>) <span class="hljs-keyword">as</span> king<br></code></pre></td></tr></table></figure><p>不重复字段标识为1</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">u01</span>,子航,鼠标,ios <span class="hljs-number">1</span><br><span class="hljs-attribute">u01</span>,子航,鼠标,ios <span class="hljs-number">2</span><br><span class="hljs-attribute">u01</span>,子航,鼠标,ios <span class="hljs-number">3</span><br><span class="hljs-attribute">u04</span>,托特包,ios <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>统计表中不重复的数据，一起做排序，但是对于重复数据它还是对自己排序</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">select</span> <span class="hljs-type">name</span>,caozuoxit,shop_name,row_number() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> cishu) <span class="hljs-keyword">from</span> (<br><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">left join</span> (<br><span class="hljs-keyword">select</span> bianhao,count(*) <span class="hljs-keyword">as</span> cishu <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> bianhao,shop_name,caozuoxit<br>) <span class="hljs-keyword">as</span> count_click <span class="hljs-keyword">on</span> count_click.bianhao=user_click1.bianhao<br><span class="hljs-keyword">left join</span> user_info <span class="hljs-keyword">on</span> count_click.bianhao=user_info.bianhao  <br>) <span class="hljs-keyword">as</span> ds;<br>上述是取巧的方法<br>下面是正经的方法<br><span class="hljs-keyword">select</span> count_clickbianhao,<span class="hljs-type">name</span>,caozuoxit,shop_name,row_number() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> cishu) <span class="hljs-keyword">as</span> rm <span class="hljs-keyword">from</span> (<br><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">left join</span> (<br><span class="hljs-keyword">select</span> bianhao <span class="hljs-keyword">as</span> count_clickbianhao,count(*) <span class="hljs-keyword">as</span> cishu <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> bianhao,shop_name,caozuoxit<br>) <span class="hljs-keyword">as</span> count_click <span class="hljs-keyword">on</span> count_click.count_clickbianhao=user_click1.bianhao <br><span class="hljs-keyword">left join</span> user_info <span class="hljs-keyword">on</span> count_click.count_clickbianhao=user_info.bianhao  <br>) <span class="hljs-keyword">as</span> jj <span class="hljs-keyword">where</span> cishu = <span class="hljs-number">1</span> <br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> count_clickbianhao,<span class="hljs-type">name</span>,caozuoxit,shop_name,row_number() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> (<span class="hljs-type">name</span>,caozuoxit,shop_name,cishu)) <span class="hljs-keyword">from</span> (<br><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">left join</span> (<br><span class="hljs-keyword">select</span> bianhao <span class="hljs-keyword">as</span> count_clickbianhao,count(*) <span class="hljs-keyword">as</span> cishu <span class="hljs-keyword">from</span> user_click1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> bianhao,shop_name,caozuoxit<br>) <span class="hljs-keyword">as</span> count_click <span class="hljs-keyword">on</span> count_click.count_clickbianhao=user_click1.bianhao <br><span class="hljs-keyword">left join</span> user_info <span class="hljs-keyword">on</span> count_click.count_clickbianhao=user_info.bianhao  <br>) <span class="hljs-keyword">as</span> j <span class="hljs-keyword">where</span> cishu != <span class="hljs-number">1</span>;<br></code></pre></td></tr></table></figure><p>整个流程使用xxl进行调度</p><p>最后结果导入到mysql</p><p>数据导入mysql保证幂等性</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/07/12-07/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>docker</title>
      <link>http://zihang.fun/2022/12/07/docker/</link>
      <guid>http://zihang.fun/2022/12/07/docker/</guid>
      <pubDate>Wed, 07 Dec 2022 00:23:07 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;这个是关于docker的简单介绍以及使用&lt;/p&gt;
&lt;p&gt;本来这个我其实不打算写的因为网上关于docker的教程很多，而且都比较全，我目前所学</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这个是关于docker的简单介绍以及使用</p><p>本来这个我其实不打算写的因为网上关于docker的教程很多，而且都比较全，我目前所学的全部都是基于菜鸟教程的</p><h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>首先我们要明白，什么是docker</p><p>docker就是相当于一个箱子，其里面有它自己的生态圈</p><p>各种环境依赖是直接现成的那样，和之前java打包成exe文件后面绑定依赖是一样的</p><h1 id="为什么现在docker会会很火"><a href="#为什么现在docker会会很火" class="headerlink" title="为什么现在docker会会很火"></a>为什么现在docker会会很火</h1><p>因为docker不需要我们配置复杂的环境变量，只要我们通过网络下载一个包含这个功能的linux或者unbanto镜像就行</p><p>特别方便，不过方便的同时也会带来隐患，比如，不知道原生安装的话，我们如何详细的知道这个组件的功能？</p><h2 id="docker的安装"><a href="#docker的安装" class="headerlink" title="docker的安装"></a>docker的安装</h2><p>docker支持多种操作系统的安装，以下我只简单介绍关于linux和云服务器的安装方法</p><h3 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h3><p>使用官方命令安装</p><p><code>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</code></p><p>也可以用国内的daocloud安装</p><p><code>curl -sSL https://get.daocloud.io/docker | sh</code></p><p>当执行安装命令出现以下情况报错的时候</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs subunit"># Executing docker install script, commit: 4f282167c425347a931ccfd95cc91fab041d414f<br>+ sh -c &#x27;yum install -y -q yum-utils&#x27;<br><span class="hljs-keyword">error: </span>rpmdb: BDB0113 Thread/process 16675/139942115395648 failed: BDB1507 Thread died in Berkeley DB library<br><span class="hljs-keyword">error: </span>db5 error(<span class="hljs-string">-30973</span>) from dbenv-&gt;failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery<br><span class="hljs-keyword">error: </span>cannot open Packages index using db5 -  (<span class="hljs-string">-30973</span>)<br><span class="hljs-keyword">error: </span>cannot open Packages database in /var/lib/rpm<br>CRITICAL:yum.main:<br><br><span class="hljs-keyword">Error: </span>rpmdb open failed<br><br></code></pre></td></tr></table></figure><p>执行 <code>mv /var/lib/rpm/__db.00* /tmp/&amp;&amp;yum clean all</code></p><p>再执行安装命令就可以了</p><p>这样在有网的机器上就安装完成了，是不是很简单 ，</p><p>接下来我们要说手动安装的情况</p><p>首先要卸载旧版本</p><p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs livescript">$ sudo yum remove docker <span class="hljs-string">\</span><br>                  docker-client <span class="hljs-string">\</span><br>                  docker-client-latest <span class="hljs-string">\</span><br>                  docker-common <span class="hljs-string">\</span><br>                  docker-latest <span class="hljs-string">\</span><br>                  docker-latest-logrotate <span class="hljs-string">\</span><br>                  docker-logrotate <span class="hljs-string">\</span><br>                  docker-engine<br><br></code></pre></td></tr></table></figure><p>在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。</p><p>安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。</p><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs haskell">$ sudo yum install -y yum-utils \<br>  device-mapper-persistent-<span class="hljs-class"><span class="hljs-keyword">data</span> \</span><br>  lvm2<br></code></pre></td></tr></table></figure><p>使用以下命令来设置稳定的仓库。</p><p>官方地址源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ sudo yum-config-manager \<br>    --add-repo \<br>    https:<span class="hljs-regexp">//</span>download.docker.com<span class="hljs-regexp">/linux/</span>centos/docker-ce.repo<br></code></pre></td></tr></table></figure><p>阿里云地址源</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ sudo yum-config-manager \<br>    --add-repo \<br>    http:<span class="hljs-regexp">//mi</span>rrors.aliyun.com<span class="hljs-regexp">/docker-ce/</span>linux<span class="hljs-regexp">/centos/</span>docker-ce.repo<br></code></pre></td></tr></table></figure><p>清华大学的</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ sudo yum-config-manager \<br>    --add-repo \<br>    https:<span class="hljs-regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="hljs-regexp">/docker-ce/</span>linux<span class="hljs-regexp">/centos/</span>docker-ce.repo<br></code></pre></td></tr></table></figure><p>在国内还是建议阿里和清华大学的</p><p>安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p><p><code>$ sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin</code></p><p>如果提示您接受 GPG 密钥，请选是。</p><p>Docker 安装完默认未启动。并且已经创建好 docker 用户组，但该用户组下没有用户。</p><p><strong>要安装特定版本的 Docker Engine-Community，请在存储库中列出可用版本，然后选择并安装：</strong></p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs vim">$ yum <span class="hljs-keyword">list</span> docker-<span class="hljs-keyword">ce</span> --showduplicates | <span class="hljs-keyword">sort</span> -r<br><br>docker-<span class="hljs-keyword">ce</span>.x86_64  <span class="hljs-number">3</span>:<span class="hljs-number">18.09</span>.<span class="hljs-number">1</span>-<span class="hljs-number">3</span>.el7                     docker-<span class="hljs-keyword">ce</span>-stable<br>docker-<span class="hljs-keyword">ce</span>.x86_64  <span class="hljs-number">3</span>:<span class="hljs-number">18.09</span>.<span class="hljs-number">0</span>-<span class="hljs-number">3</span>.el7                     docker-<span class="hljs-keyword">ce</span>-stable<br>docker-<span class="hljs-keyword">ce</span>.x86_64  <span class="hljs-number">18.06</span>.<span class="hljs-number">1</span>.<span class="hljs-keyword">ce</span>-<span class="hljs-number">3</span>.el7                    docker-<span class="hljs-keyword">ce</span>-stable<br>docker-<span class="hljs-keyword">ce</span>.x86_64  <span class="hljs-number">18.06</span>.<span class="hljs-number">0</span>.<span class="hljs-keyword">ce</span>-<span class="hljs-number">3</span>.el7                    docker-<span class="hljs-keyword">ce</span>-stable<br></code></pre></td></tr></table></figure><p>通过其完整的软件包名称安装特定版本，该软件包名称是软件包名称（docker-ce）加上版本字符串（第二列），从第一个冒号（:）一直到第一个连字符，并用连字符（-）分隔。例如：docker-ce-18.09.1。</p><p><code>$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io</code></p><p>然后启动docker</p><p><code>$ sudo systemctl start docker</code></p><p>然后运行hello world镜像查看是不是我们成功安装了这个docker</p><p><code>$ sudo docker run hello-world</code></p><h3 id="卸载docker"><a href="#卸载docker" class="headerlink" title="卸载docker"></a>卸载docker</h3><p>先删除安装包</p><p><code>yum remove docker-ce </code></p><p>然后删除镜像文件等</p><p><code>rm -rf /var/lib/docker</code></p><p>云服务器和上面一样</p><h1 id="docker-命令"><a href="#docker-命令" class="headerlink" title="docker 命令"></a>docker 命令</h1><p>docker命令的种类不多但是其中的分支较多</p><p>docker run : 原本的意义是创建一个docker容器，并运行它</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs stylus">-<span class="hljs-selector-tag">a</span> stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；<br><br>-d: 后台运行容器，并返回容器ID；<br><br>-<span class="hljs-selector-tag">i</span>: 以交互模式运行容器，通常与 -t 同时使用；<br><br>-P: 随机端口映射，容器内部端口随机映射到主机的端口<br><br>-<span class="hljs-selector-tag">p</span>: 指定端口映射，格式为：主机(宿主)端口:容器端口<br><br>-t: 为容器重新分配一个伪输入终端，通常与 -<span class="hljs-selector-tag">i</span> 同时使用；<br><br><span class="hljs-attr">--name</span>=<span class="hljs-string">&quot;nginx-lb&quot;</span>: 为容器指定一个名称；<br><br><span class="hljs-attr">--dns</span> <span class="hljs-number">8.8</span>.<span class="hljs-number">8.8</span>: 指定容器使用的DNS服务器，默认和宿主一致；<br><br><span class="hljs-attr">--dns-search</span> example<span class="hljs-selector-class">.com</span>: 指定容器DNS搜索域名，默认和宿主一致；<br><br>-h <span class="hljs-string">&quot;mars&quot;</span>: 指定容器的hostname；<br><br>-e username=<span class="hljs-string">&quot;ritchie&quot;</span>: 设置环境变量；<br><br><span class="hljs-attr">--env-file</span>=<span class="hljs-selector-attr">[]</span>: 从指定文件读入环境变量；<br><br><span class="hljs-attr">--cpuset</span>=<span class="hljs-string">&quot;0-2&quot;</span> or <span class="hljs-attr">--cpuset</span>=<span class="hljs-string">&quot;0,1,2&quot;</span>: 绑定容器到指定CPU运行；<br><br>-m :设置容器使用内存最大值；<br><br><span class="hljs-attr">--net</span>=<span class="hljs-string">&quot;bridge&quot;</span>: 指定容器的网络连接类型，支持 bridge/host/<span class="hljs-attribute">none</span>/container: 四种类型；<br><br><span class="hljs-attr">--link</span>=<span class="hljs-selector-attr">[]</span>: 添加链接到另一个容器；<br><br><span class="hljs-attr">--expose</span>=<span class="hljs-selector-attr">[]</span>: 开放一个端口或一组端口；<br><br><span class="hljs-attr">--volume</span> , -v: 绑定一个卷<br></code></pre></td></tr></table></figure><p><strong>docker start</strong> :启动一个或多个已经被停止的容器</p><p><strong>docker stop</strong> :停止一个运行中的容器</p><p><strong>docker restart</strong> :重启容器</p><p><strong>docker kill</strong> :杀掉一个运行中的容器。</p><ul><li><strong>-s :</strong> 向容器发送一个信号</li></ul><p><strong>docker rm ：</strong> 删除一个或多个容器。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-f :通过 SIGKILL 信号强制删除一个运行中的容器。</span><br><br><span class="hljs-deletion">-l :移除容器间的网络连接，而非容器本身。</span><br><br><span class="hljs-deletion">-v :删除与容器关联的卷。</span><br></code></pre></td></tr></table></figure><ul><li>命令可以嵌套使用如下 ：<ul><li><code>删除所有已经停止的容器：docker rm $(docker ps -a -q)</code></li></ul></li></ul><p><strong>docker pause</strong> :暂停容器中所有的进程。</p><p><strong>docker unpause</strong> :恢复容器中所有的进程。</p><p><strong>docker create ：</strong> 创建一个新的容器但不启动它 ：其语法和run一样</p><p><strong>docker exec ：</strong> 在运行的容器中执行命令</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-d :分离模式: 在后台运行</span><br><br><span class="hljs-deletion">-i :即使没有附加也保持STDIN 打开</span><br><br><span class="hljs-deletion">-t :分配一个伪终端</span><br></code></pre></td></tr></table></figure><p>docker ps : 列出容器</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-a :显示所有的容器，包括未运行的。</span><br><br><span class="hljs-deletion">-f :根据条件过滤显示的内容。</span><br><br><span class="hljs-deletion">--format :指定返回值的模板文件。</span><br><br><span class="hljs-deletion">-l :显示最近创建的容器。</span><br><br><span class="hljs-deletion">-n :列出最近创建的n个容器。</span><br><br><span class="hljs-deletion">--no-trunc :不截断输出。</span><br><br><span class="hljs-deletion">-q :静默模式，只显示容器编号。</span><br><br><span class="hljs-deletion">-s :显示总的文件大小。</span><br></code></pre></td></tr></table></figure><p>输出介绍</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">输出详情介绍：</span><br><span class="hljs-attribute"></span><br><span class="hljs-attribute">CONTAINER ID</span><span class="hljs-punctuation">:</span> <span class="hljs-string">容器 ID。</span><br><br><span class="hljs-attribute">IMAGE</span><span class="hljs-punctuation">:</span> <span class="hljs-string">使用的镜像。</span><br><br><span class="hljs-attribute">COMMAND</span><span class="hljs-punctuation">:</span> <span class="hljs-string">启动容器时运行的命令。</span><br><br><span class="hljs-attribute">CREATED</span><span class="hljs-punctuation">:</span> <span class="hljs-string">容器的创建时间。</span><br><br><span class="hljs-attribute">STATUS</span><span class="hljs-punctuation">:</span> <span class="hljs-string">容器状态。</span><br><br><span class="hljs-attribute">状态有7种：</span><br><span class="hljs-attribute"></span><br><span class="hljs-attribute">created（已创建）</span><br><span class="hljs-attribute">restarting（重启中）</span><br><span class="hljs-attribute">running（运行中）</span><br><span class="hljs-attribute">removing（迁移中）</span><br><span class="hljs-attribute">paused（暂停）</span><br><span class="hljs-attribute">exited（停止）</span><br><span class="hljs-attribute">dead（死亡）</span><br><span class="hljs-attribute">PORTS</span><span class="hljs-punctuation">:</span> <span class="hljs-string">容器的端口信息和使用的连接类型（tcp\udp）。</span><br><br><span class="hljs-attribute">NAMES</span><span class="hljs-punctuation">:</span> <span class="hljs-string">自动分配的容器名称。</span><br></code></pre></td></tr></table></figure><p><strong>docker inspect :</strong> 获取容器&#x2F;镜像的元数据。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-f :指定返回值的模板文件。</span><br><br><span class="hljs-deletion">-s :显示总的文件大小。</span><br><br><span class="hljs-deletion">--type :为指定类型返回JSON。</span><br></code></pre></td></tr></table></figure><p><strong>docker top :</strong> 查看容器中运行的进程信息，支持 ps 命令参数。</p><p><code>docker top [OPTIONS] CONTAINER [ps OPTIONS]</code></p><ul><li>查看所有运行容器的进程信息。</li><li><code>for i in  </code>docker ps |grep Up|awk ‘{print $1}’<code>;do echo \ &amp;&amp;docker top $i; done</code></li></ul><p><strong>docker attach :</strong> 连接到正在运行中的容器。</p><p>要attach上去的容器必须正在运行，可以同时连接上同一个container来共享屏幕（与screen命令的attach类似）。</p><p>docker events : 从服务器获取实时事件</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">-f ：根据条件过滤事件；<br><br><span class="hljs-params">--since</span> ：从指定的时间戳后显示所有事件;<br><br><span class="hljs-params">--until</span> ：流水时间显示到指定的时间为止；<br><br>如果指定的时间是到秒级的，需要将时间转成时间戳。如果时间为日期的话，可以直接使用，如<span class="hljs-params">--since=</span><span class="hljs-string">&quot;2016-07-01&quot;</span>。<br></code></pre></td></tr></table></figure><p>docker logs : 获取容器的日志</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs ada">-f : 跟踪日志输出<br><br><span class="hljs-comment">--since :显示某个开始时间的所有日志</span><br><br>-t : 显示时间戳<br><br><span class="hljs-comment">--tail :仅列出最新N条容器日志</span><br></code></pre></td></tr></table></figure><p><strong>docker wait :</strong> 阻塞运行直到容器停止，然后打印出它的退出代码</p><p><strong>docker export :</strong> 将文件系统作为一个tar归档文件导出到STDOUT。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-o :将输入内容写到文件。</span><br></code></pre></td></tr></table></figure><p>docker port 用于列出指定的容器的端口映射，或者查找将 PRIVATE_PORT NAT 到面向公众的端口。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">docker port <span class="hljs-comment">[OPTIONS]</span> <span class="hljs-keyword">CONTAINER</span> <span class="hljs-comment">[PRIVATE_PORT<span class="hljs-comment">[/PROTO]</span>]</span><br></code></pre></td></tr></table></figure><p>docker stats : 显示容器资源的使用情况，包括：CPU、内存、网络 I&#x2F;O 等。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-attr">--all</span> , -<span class="hljs-selector-tag">a</span> :显示所有的容器，包括未运行的。<br><br><span class="hljs-attr">--format</span> :指定返回值的模板文件。<br><br><span class="hljs-attr">--no-stream</span> :展示当前状态就直接退出了，不再实时更新。<br><br><span class="hljs-attr">--no-trunc</span> :不截断输出。<br></code></pre></td></tr></table></figure><p><strong>docker commit :</strong> 从容器创建一个新的镜像。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-a :提交的镜像作者；</span><br><br><span class="hljs-deletion">-c :使用Dockerfile指令来创建镜像；</span><br><br><span class="hljs-deletion">-m :提交时的说明文字；</span><br><br><span class="hljs-deletion">-p :在commit时，将容器暂停。</span><br></code></pre></td></tr></table></figure><p><strong>docker cp :</strong> 用于容器与主机之间的数据拷贝。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">-L :保持源目标中的链接<br>docker <span class="hljs-built_in">cp</span> [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-<br>docker <span class="hljs-built_in">cp</span> [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH<br>例子 ：<br>实例<br>将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。<br><br>docker <span class="hljs-built_in">cp</span> /www/runoob 96f7f14e99ab:/www/<br>将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。<br><br>docker <span class="hljs-built_in">cp</span> /www/runoob 96f7f14e99ab:/www<br>将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。<br><br>docker <span class="hljs-built_in">cp</span>  96f7f14e99ab:/www /tmp/<br></code></pre></td></tr></table></figure><p>docker diff : 检查容器里文件结构的更改。</p><figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs inform7">docker diff <span class="hljs-comment">[OPTIONS]</span> <span class="hljs-keyword">CONTAINER</span><br></code></pre></td></tr></table></figure><p><strong>docker login :</strong> 登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub</p><p><strong>docker logout :</strong> 登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">docker <span class="hljs-keyword">login</span> [<span class="hljs-keyword">OPTIONS</span>] [<span class="hljs-keyword">SERVER</span>]<br>docker logout [<span class="hljs-keyword">OPTIONS</span>] [<span class="hljs-keyword">SERVER</span>]<br>-u :登陆的用户名<br><br>-p :登陆的密码<br></code></pre></td></tr></table></figure><p>docker pull : 从镜像仓库中拉取或者更新指定镜像</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">-<span class="hljs-selector-tag">a</span> :拉取所有 tagged 镜像<br>docker pull <span class="hljs-selector-attr">[OPTIONS]</span> NAME<span class="hljs-selector-attr">[:TAG|@DIGEST]</span><br><span class="hljs-attr">--disable-content-trust</span> :忽略镜像的校验,默认开启<br></code></pre></td></tr></table></figure><p>docker push : 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-comment">--disable-content-trust :忽略镜像的校验,默认开启</span><br>docker push [<span class="hljs-keyword">OPTIONS</span>] <span class="hljs-type">NAME</span>[:TAG]<br></code></pre></td></tr></table></figure><p><strong>docker search :</strong> 从Docker Hub查找镜像</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">docker <span class="hljs-keyword">search</span> [<span class="hljs-keyword">OPTIONS</span>] TERM<br><span class="hljs-comment">--automated :只列出 automated build类型的镜像；</span><br><br><span class="hljs-comment">--no-trunc :显示完整的镜像描述；</span><br><br>-f &lt;过滤条件&gt;:列出收藏数不小于指定值的镜像。<br></code></pre></td></tr></table></figure><p>docker images : 列出本地镜像。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus">docker images <span class="hljs-selector-attr">[OPTIONS]</span> <span class="hljs-selector-attr">[REPOSITORY[:TAG]</span>]<br>-<span class="hljs-selector-tag">a</span> :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）；<br><br><span class="hljs-attr">--digests</span> :显示镜像的摘要信息；<br><br>-f :显示满足条件的镜像；<br><br><span class="hljs-attr">--format</span> :指定返回值的模板文件；<br><br><span class="hljs-attr">--no-trunc</span> :显示完整的镜像信息；<br><br>-<span class="hljs-selector-tag">q</span> :只显示镜像ID。<br></code></pre></td></tr></table></figure><p>docker rmi : 删除本地一个或多个镜像。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">docker rmi <span class="hljs-selector-attr">[OPTIONS]</span> IMAGE <span class="hljs-selector-attr">[IMAGE...]</span><br>-f :强制删除；<br><br><span class="hljs-attr">--no-prune</span> :不移除该镜像的过程镜像，默认移除；<br></code></pre></td></tr></table></figure><p>docker tag : 标记本地镜像，将其归入某一仓库。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">docker <span class="hljs-keyword">tag</span> <span class="hljs-title">[OPTIONS</span>] IMAGE[:<span class="hljs-keyword">TAG</span>] [REGISTRYHOST/][USERNAME/]NAME[:<span class="hljs-keyword">TAG</span>]<br></code></pre></td></tr></table></figure><p>docker build 命令用于使用 Dockerfile 创建镜像</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs diff">docker build [OPTIONS] PATH | URL | -<br><span class="hljs-deletion">--build-arg=[] :设置镜像创建时的变量；</span><br><br><span class="hljs-deletion">--cpu-shares :设置 cpu 使用权重；</span><br><br><span class="hljs-deletion">--cpu-period :限制 CPU CFS周期；</span><br><br><span class="hljs-deletion">--cpu-quota :限制 CPU CFS配额；</span><br><br><span class="hljs-deletion">--cpuset-cpus :指定使用的CPU id；</span><br><br><span class="hljs-deletion">--cpuset-mems :指定使用的内存 id；</span><br><br><span class="hljs-deletion">--disable-content-trust :忽略校验，默认开启；</span><br><br><span class="hljs-deletion">-f :指定要使用的Dockerfile路径；</span><br><br><span class="hljs-deletion">--force-rm :设置镜像过程中删除中间容器；</span><br><br><span class="hljs-deletion">--isolation :使用容器隔离技术；</span><br><br><span class="hljs-deletion">--label=[] :设置镜像使用的元数据；</span><br><br><span class="hljs-deletion">-m :设置内存最大值；</span><br><br><span class="hljs-deletion">--memory-swap :设置Swap的最大值为内存+swap，&quot;-1&quot;表示不限swap；</span><br><br><span class="hljs-deletion">--no-cache :创建镜像的过程不使用缓存；</span><br><br><span class="hljs-deletion">--pull :尝试去更新镜像的新版本；</span><br><br><span class="hljs-deletion">--quiet, -q :安静模式，成功后只输出镜像 ID；</span><br><br><span class="hljs-deletion">--rm :设置镜像成功后删除中间容器；</span><br><br><span class="hljs-deletion">--shm-size :设置/dev/shm的大小，默认值是64M；</span><br><br><span class="hljs-deletion">--ulimit :Ulimit配置。</span><br><br><span class="hljs-deletion">--squash :将 Dockerfile 中所有的操作压缩为一层。</span><br><br><span class="hljs-deletion">--tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。</span><br><br><span class="hljs-deletion">--network: 默认 default。在构建期间设置RUN指令的网络模式</span><br></code></pre></td></tr></table></figure><p>docker history : 查看指定镜像的创建历史。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs diff">docker history [OPTIONS] IMAGE<br><span class="hljs-deletion">-H :以可读的格式打印镜像大小和日期，默认为true；</span><br><br><span class="hljs-deletion">--no-trunc :显示完整的提交记录；</span><br><br><span class="hljs-deletion">-q :仅列出提交记录ID。</span><br></code></pre></td></tr></table></figure><p>docker save : 将指定镜像保存成 tar 归档文件</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs css">docker save <span class="hljs-selector-attr">[OPTIONS]</span> IMAGE <span class="hljs-selector-attr">[IMAGE...]</span><br>-o :输出到的文件。<br></code></pre></td></tr></table></figure><p>docker load : 导入使用 docker save 命令导出的镜像。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus">docker load <span class="hljs-selector-attr">[OPTIONS]</span><br><span class="hljs-attr">--input</span> , -<span class="hljs-selector-tag">i</span> : 指定导入的文件，代替 STDIN。<br><br><span class="hljs-attr">--quiet</span> , -<span class="hljs-selector-tag">q</span> : 精简输出信息。<br></code></pre></td></tr></table></figure><p><strong>docker import :</strong> 从归档文件中创建镜像。</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gradle">docker <span class="hljs-keyword">import</span> [<span class="hljs-keyword">OPTIONS</span>] <span class="hljs-keyword">file</span>|URL|- [REPOSITORY[:TAG]]<br>-c :应用docker 指令创建镜像；<br><br>-m :提交时的说明文字；<br></code></pre></td></tr></table></figure><p>docker info : 显示 Docker 系统信息，包括镜像和容器数。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">docker</span> <span class="hljs-literal">info</span> [OPTIONS]<br></code></pre></td></tr></table></figure><p>docker version :显示 Docker 版本信息。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-f :指定返回值的模板文件。</span><br></code></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%9D%82%E8%B4%A7%E6%8A%80%E6%9C%AF%E6%A0%88/">杂货技术栈</category>
      
      
      
      <comments>http://zihang.fun/2022/12/07/docker/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>项目可视化框架</title>
      <link>http://zihang.fun/2022/12/06/12-06/</link>
      <guid>http://zihang.fun/2022/12/06/12-06/</guid>
      <pubDate>Tue, 06 Dec 2022 00:48:06 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;superset&quot;&gt;&lt;a href=&quot;#superset&quot; class=&quot;headerlink&quot; title=&quot;superset&quot;&gt;&lt;/a&gt;superset&lt;/h1&gt;&lt;p&gt;官网 ： superset ： &lt;a href=&quot;https://superset.apac</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="superset"><a href="#superset" class="headerlink" title="superset"></a>superset</h1><p>官网 ： superset ： <a href="https://superset.apache.org/">https://superset.apache.org/</a></p><p>类似于otb ： 开箱即用</p><p>把图弄到一个dashboard中 ，显示出来</p><p>底层源码  ： python编译的 ： 建议先安装python 然后再安装它 ，不要把superset和mysql在一起</p><p>因为原生的superset，需要一个和mysql冲突的包</p><p>但是docker还是可以的</p><p>先安装python环境</p><p>anconda -》 python</p><p>python原生 ： 建议</p><h2 id="docker安装"><a href="#docker安装" class="headerlink" title="docker安装"></a>docker安装</h2><p>毫无疑问docker安装是最快速的而且，不用担心依赖等</p><p>docker安装的步骤如下  ：</p><p>先安装yarn工具集</p><p><code>yum -y install yum-utils</code></p><p>然后把docker源添加到镜像里</p><p><code>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</code></p><p>我这里添加的是阿里的镜像源</p><p>然后更新软件包索引</p><p><code>yum makecache fast</code></p><p>接下来我们就要开始安装docker了</p><p><code>yum -y install docker-ce docker-ce-cli containerd.io</code></p><p>设置一下docker开机自启</p><p><code>systemctl enable docker</code></p><p>然后我们启动docker</p><p><code>systemctl start docker</code></p><p>我们搜索superset镜像</p><p><code>docker search superset</code></p><p>直接拉去自己想要的版本 ，我这里拉去的是0.37.2的</p><p><code>docker pull amancevice/superset:0.37.2</code></p><p>接下来我们要创建存储superset配置文件及数据文件的文件夹</p><p><code>mkdir -p /opt/module/docker/superset/conf </code></p><p><code>mkdir -p /opt/module/docker/superset/data</code></p><p>接下来我们要创建superset的容器，并把端口映射出来</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker run --name superset -u <span class="hljs-number">0</span> -d -p <span class="hljs-number">8088</span>:<span class="hljs-number">8088</span> -v <span class="hljs-regexp">/opt/m</span>odule<span class="hljs-regexp">/docker/</span>superset<span class="hljs-regexp">/conf:/</span>etc<span class="hljs-regexp">/superset -v /</span>opt<span class="hljs-regexp">/module/</span>docker<span class="hljs-regexp">/superset/</span>data:<span class="hljs-regexp">/var/</span>lib<span class="hljs-regexp">/superset amancevice/</span>superset:<span class="hljs-number">0.37</span>.<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>然后初始化我们的superset数据库</p><p><code>docker exec -it superset superset db upgrade</code></p><p>创建superset的管理员账号</p><p><code>docker exec -it superset superset fab create-admin</code></p><p>创建成功之后可以对其进行初始化了</p><p><code>docker exec -it superset superset init </code></p><p>最后执行开启服务</p><p><code>docker exec -it superset superset run --with-threads --reload --debugger</code></p><p>就可以啦 ，我们可以通过web页面 ip:8088访问 因为我们映射的端口是8088嘛</p><p>但是要注意一点，就是我们在我们的superset添加数据库的时候不能用修改了host里的别名进行IP替代</p><p>因为我们的superset是安装在我们的docker里的哪里的host并没有进行修改，识别不了别名，我们可以对其进行修改，但是嫌麻烦可以直接弄个ip</p><p>接下来我们简单弄个启动脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">check_log_dir</span></span>()<br>&#123;<br>    SUPERSET_LOG_DIR=/usr/local/src/superset/logs<br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-variable">$SUPERSET_LOG_DIR</span> ]<br>    <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$SUPERSET_LOG_DIR</span><br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">superset_start</span></span>()<br>&#123;<br>    cmd=<span class="hljs-string">&quot;docker start superset;nohup docker exec -it superset superset run --with-threads --reload --debugger &gt;<span class="hljs-variable">$SUPERSET_LOG_DIR</span>/superset.log 2&gt;&amp;1 &amp;&quot;</span><br>    <span class="hljs-built_in">eval</span> <span class="hljs-variable">$cmd</span> || <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;superset服务已启动&quot;</span><br>&#125;<br><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">superset_stop</span></span>()<br>&#123;<br>   docker stop superset<br>&#125;<br><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">superset_status</span></span>()<br>&#123;<br>  docker ps<br>&#125;<br><br><br><span class="hljs-keyword">case</span> <span class="hljs-variable">$1</span> <span class="hljs-keyword">in</span><br><span class="hljs-string">&quot;start&quot;</span>)<br>     check_log_dir<br>     superset_start<br>    ;;<br><span class="hljs-string">&quot;stop&quot;</span>)<br>     superset_stop<br>    ;;<br><span class="hljs-string">&quot;status&quot;</span>)<br>      superset_status<br>    ;;<br>*)<br>    <span class="hljs-built_in">echo</span> Invalid Args!<br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;Usage: &#x27;</span>$(<span class="hljs-built_in">basename</span> <span class="hljs-variable">$0</span>)<span class="hljs-string">&#x27; start|stop|status&#x27;</span><br>    ;;<br><span class="hljs-keyword">esac</span><br></code></pre></td></tr></table></figure><h2 id="原生安装"><a href="#原生安装" class="headerlink" title="原生安装"></a>原生安装</h2><p>superset的原生安装是有坑的 ，以下操作只能是root用</p><p>在安装superset的时候容易出现gcc的问题，解决方法就是一直重新安装那一步</p><p>下面我们一起来进行原生安装</p><p>首先我们要安装python3的一些依赖 <code>yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel</code></p><p>然后我们要进行安装EPEL源并安装superset必备的包</p><p><code>yum install epel-release #安装epel源</code></p><p><code>yum install mysql-devel #安装MySQL开发包，属于pymysqlclient依赖</code></p><p><code>yum install gcc gcc-c++ libffi-devel python-devel python-pip python-wheel openssl-devel cyrus-sasl-devel openldap-devel</code></p><p>接下来我们要上传自己的python安装包到linuxx服务器上</p><p> <code>cd /root/公共</code></p><p><code>tar -xf ./Python-3.6.6.tgz</code></p><p>然后进入到解压出来的文件夹中进行编译</p><p><code>./configure</code></p><p><code>make &amp;&amp; make install</code></p><p>安装python3的virtualenv并建⽴superset的env</p><p><code>pip3 install --upgrade pip -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</code></p><p><code>virtualenv -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</code></p><p><code>pip3 install --upgrade setuptools -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</code></p><p>建⽴superset的env&amp;激活</p><p><code>python3 -m venv superset-py3</code></p><p><code>source superset-py3/bin/activate #激活superset的venv</code></p><p>安装superset需要的安装包</p><p>这个包的数量很多建议大家创建一个txt文件然后安装</p><p>requirement.txt文件添加</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">alembic</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">2</span>            # via flask-migrate<br><span class="hljs-attribute">amqp</span>==<span class="hljs-number">2</span>.<span class="hljs-number">5</span>.<span class="hljs-number">2</span>               # via kombu<br><span class="hljs-attribute">apispec</span>[yaml]==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">3</span>      # via flask-appbuilder<br><span class="hljs-attribute">attrs</span>==<span class="hljs-number">19</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>             # via jsonschema<br><span class="hljs-attribute">babel</span>==<span class="hljs-number">2</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span>              # via flask-babel<br><span class="hljs-attribute">backoff</span>==<span class="hljs-number">1</span>.<span class="hljs-number">10</span>.<span class="hljs-number">0</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">billiard</span>==<span class="hljs-number">3.6.3.0</span>         # via celery<br><span class="hljs-attribute">bleach</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>             # via apache-superset (setup.py)     ---<br><span class="hljs-attribute">celery</span>==<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span>             # via apache-superset (setup.py)<br><span class="hljs-attribute">cffi</span>==<span class="hljs-number">1</span>.<span class="hljs-number">13</span>.<span class="hljs-number">2</span>              # via cryptography<br><span class="hljs-attribute">click</span>==<span class="hljs-number">7</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>              # via apache-superset (setup.py), flask, flask-appbuilder<br><span class="hljs-attribute">colorama</span>==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">3</span>           # via apache-superset (setup.py), flask-appbuilder<br><span class="hljs-attribute">contextlib2</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span>.post1  # via apache-superset (setup.py)<br><span class="hljs-attribute">croniter</span>==<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">31</span>          # via apache-superset (setup.py)<br><span class="hljs-attribute">cryptography</span>==<span class="hljs-number">2</span>.<span class="hljs-number">8</span>         # via apache-superset (setup.py)<br><span class="hljs-attribute">decorator</span>==<span class="hljs-number">4</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span>          # via retry<br><span class="hljs-attribute">defusedxml</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span>         # via python3-openid<br><span class="hljs-attribute">flask</span>-appbuilder==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">4</span>   # via apache-superset (setup.py)<br><span class="hljs-attribute">flask</span>-babel==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>        # via flask-appbuilder<br><span class="hljs-attribute">flask</span>-caching==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">0</span>      # via apache-superset (setup.py)<br><span class="hljs-attribute">flask</span>-compress==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span>     # via apache-superset (setup.py)<br><span class="hljs-attribute">flask</span>-jwt-extended==<span class="hljs-number">3</span>.<span class="hljs-number">24</span>.<span class="hljs-number">1</span>  # via flask-appbuilder<br><span class="hljs-attribute">flask</span>-login==<span class="hljs-number">0</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span>        # via flask-appbuilder<br><span class="hljs-attribute">flask</span>-migrate==<span class="hljs-number">2</span>.<span class="hljs-number">5</span>.<span class="hljs-number">2</span>      # via apache-superset (setup.py)<br><span class="hljs-attribute">flask</span>-openid==<span class="hljs-number">1</span>.<span class="hljs-number">2</span>.<span class="hljs-number">5</span>       # via flask-appbuilder<br><span class="hljs-attribute">flask</span>-sqlalchemy==<span class="hljs-number">2</span>.<span class="hljs-number">4</span>.<span class="hljs-number">1</span>   # via flask-appbuilder, flask-migrate<br><span class="hljs-attribute">flask</span>-talisman==<span class="hljs-number">0</span>.<span class="hljs-number">7</span>.<span class="hljs-number">0</span>     # via apache-superset (setup.py)<br><span class="hljs-attribute">flask</span>-wtf==<span class="hljs-number">0</span>.<span class="hljs-number">14</span>.<span class="hljs-number">2</span>         # via apache-superset (setup.py), flask-appbuilder<br><span class="hljs-attribute">flask</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>              # via apache-superset (setup.py), flask-appbuilder, flask-babel, flask-caching, flask-compress, flask-jwt-extended, flask-login, flask-migrate, flask-openid, flask-sqlalchemy, flask-wtf<br><span class="hljs-attribute">geographiclib</span>==<span class="hljs-number">1</span>.<span class="hljs-number">50</span>       # via geopy<br><span class="hljs-attribute">geopy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">20</span>.<span class="hljs-number">0</span>             # via apache-superset (setup.py)<br><span class="hljs-attribute">gunicorn</span>==<span class="hljs-number">20</span>.<span class="hljs-number">0</span>.<span class="hljs-number">4</span>          # via apache-superset (setup.py)<br><span class="hljs-attribute">humanize</span>==<span class="hljs-number">0</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">importlib</span>-metadata==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span>  # via jsonschema, kombu<br><span class="hljs-attribute">isodate</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">0</span>            # via apache-superset (setup.py)<br><span class="hljs-attribute">itsdangerous</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>       # via flask<br><span class="hljs-attribute">jinja2</span>==<span class="hljs-number">2</span>.<span class="hljs-number">10</span>.<span class="hljs-number">3</span>            # via flask, flask-babel<br><span class="hljs-attribute">jsonschema</span>==<span class="hljs-number">3</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span>         # via flask-appbuilder<br><span class="hljs-attribute">kombu</span>==<span class="hljs-number">4</span>.<span class="hljs-number">6</span>.<span class="hljs-number">8</span>              # via celery<br><span class="hljs-attribute">mako</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>               # via alembic<br><span class="hljs-attribute">markdown</span>==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">markupsafe</span>==<span class="hljs-number">1</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span>         # via jinja2, mako<br><span class="hljs-attribute">marshmallow</span>-enum==<span class="hljs-number">1</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span>   # via flask-appbuilder<br><span class="hljs-attribute">marshmallow</span>-sqlalchemy==<span class="hljs-number">0</span>.<span class="hljs-number">21</span>.<span class="hljs-number">0</span>  # via flask-appbuilder<br><span class="hljs-attribute">marshmallow</span>==<span class="hljs-number">2</span>.<span class="hljs-number">19</span>.<span class="hljs-number">5</span>       # via flask-appbuilder, marshmallow-enum, marshmallow-sqlalchemy<br><span class="hljs-attribute">more</span>-itertools==<span class="hljs-number">8</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>     # via zipp<br><span class="hljs-attribute">msgpack</span>==<span class="hljs-number">0</span>.<span class="hljs-number">6</span>.<span class="hljs-number">2</span>            # via apache-superset (setup.py)<br><span class="hljs-attribute">numpy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">18</span>.<span class="hljs-number">1</span>             # via pandas, pyarrow<br><span class="hljs-attribute">pandas</span>==<span class="hljs-number">0</span>.<span class="hljs-number">25</span>.<span class="hljs-number">3</span>            # via apache-superset (setup.py)<br><span class="hljs-attribute">parsedatetime</span>==<span class="hljs-number">2</span>.<span class="hljs-number">5</span>        # via apache-superset (setup.py)<br><span class="hljs-attribute">pathlib2</span>==<span class="hljs-number">2</span>.<span class="hljs-number">3</span>.<span class="hljs-number">5</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">polyline</span>==<span class="hljs-number">1</span>.<span class="hljs-number">4</span>.<span class="hljs-number">0</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">prison</span>==<span class="hljs-number">0</span>.<span class="hljs-number">1</span>.<span class="hljs-number">2</span>             # via flask-appbuilder<br><span class="hljs-attribute">py</span>==<span class="hljs-number">1</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span>                 # via retry<br><span class="hljs-attribute">pyarrow</span>==<span class="hljs-number">0</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">pycparser</span>==<span class="hljs-number">2</span>.<span class="hljs-number">19</span>           # via cffi<br><span class="hljs-attribute">pyjwt</span>==<span class="hljs-number">1</span>.<span class="hljs-number">7</span>.<span class="hljs-number">1</span>              # via flask-appbuilder, flask-jwt-extended<br><span class="hljs-attribute">python</span>-dateutil==<span class="hljs-number">2</span>.<span class="hljs-number">8</span>.<span class="hljs-number">1</span>    # via alembic, apache-superset (setup.py), croniter, flask-appbuilder, pandas<br><span class="hljs-attribute">python</span>-dotenv==<span class="hljs-number">0</span>.<span class="hljs-number">10</span>.<span class="hljs-number">5</span>     # via apache-superset (setup.py)<br><span class="hljs-attribute">python</span>-editor==<span class="hljs-number">1</span>.<span class="hljs-number">0</span>.<span class="hljs-number">4</span>      # via alembic<br><span class="hljs-attribute">python</span>-geohash==<span class="hljs-number">0</span>.<span class="hljs-number">8</span>.<span class="hljs-number">5</span>     # via apache-superset (setup.py)<br><span class="hljs-attribute">python3</span>-openid==<span class="hljs-number">3</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span>     # via flask-openid<br><span class="hljs-attribute">pytz</span>==<span class="hljs-number">2019</span>.<span class="hljs-number">3</span>              # via babel, celery, flask-babel, pandas<br><span class="hljs-attribute">pyyaml</span>==<span class="hljs-number">5</span>.<span class="hljs-number">3</span>               # via apache-superset (setup.py), apispec<br><span class="hljs-attribute">retry</span>==<span class="hljs-number">0</span>.<span class="hljs-number">9</span>.<span class="hljs-number">2</span>              # via apache-superset (setup.py)<br><span class="hljs-attribute">selenium</span>==<span class="hljs-number">3</span>.<span class="hljs-number">141</span>.<span class="hljs-number">0</span>         # via apache-superset (setup.py)<br><span class="hljs-attribute">simplejson</span>==<span class="hljs-number">3</span>.<span class="hljs-number">17</span>.<span class="hljs-number">0</span>        # via apache-superset (setup.py)<br><span class="hljs-attribute">six</span>==<span class="hljs-number">1</span>.<span class="hljs-number">14</span>.<span class="hljs-number">0</span>               # via bleach, cryptography, flask-jwt-extended, flask-talisman, isodate, jsonschema, pathlib2, polyline, prison, pyarrow, pyrsistent, python-dateutil, sqlalchemy-utils, wtforms-json<br><span class="hljs-attribute">sqlalchemy</span>-utils==<span class="hljs-number">0</span>.<span class="hljs-number">36</span>.<span class="hljs-number">1</span>  # via apache-superset (setup.py), flask-appbuilder<br><span class="hljs-attribute">sqlalchemy</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">12</span>        # via alembic, apache-superset (setup.py), flask-sqlalchemy, marshmallow-sqlalchemy, sqlalchemy-utils<br><span class="hljs-attribute">sqlparse</span>==<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>           # via apache-superset (setup.py)<br><span class="hljs-attribute">urllib3</span>==<span class="hljs-number">1</span>.<span class="hljs-number">25</span>.<span class="hljs-number">8</span>           # via selenium<br><span class="hljs-attribute">vine</span>==<span class="hljs-number">1</span>.<span class="hljs-number">3</span>.<span class="hljs-number">0</span>               # via amqp, celery<br><span class="hljs-attribute">webencodings</span>==<span class="hljs-number">0</span>.<span class="hljs-number">5</span>.<span class="hljs-number">1</span>       # via bleach<br><span class="hljs-attribute">werkzeug</span>==<span class="hljs-number">0</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span>          # via flask, flask-jwt-extended<br><span class="hljs-attribute">wtforms</span>-json==<span class="hljs-number">0</span>.<span class="hljs-number">3</span>.<span class="hljs-number">3</span>       # via apache-superset (setup.py)<br><span class="hljs-attribute">wtforms</span>==<span class="hljs-number">2</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span>            # via flask-wtf, wtforms-json<br><span class="hljs-attribute">zipp</span>==<span class="hljs-number">2</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>               # via importlib-metadata<br><br></code></pre></td></tr></table></figure><p>然后执行 ：</p><p><code> pip3 install -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com -r requirement.txt</code></p><p>从阿里的镜像源安装这些依赖</p><p>接下来是安装Superset</p><p>到了这一步，就可能会报错，就是gcc的错误，那是因为安装没有成功，我安装了6次才成功，</p><p>执行 ；</p><p><code>pip3 install apache-superset==0.37.1  -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com</code></p><p>然后<strong>安装Mysql数据包</strong></p><p><code>install sqlalchemy==1.3.24 -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</code></p><p><code>pip3 install mysqlclient -i http://pypi.douban.com/simple --trusted-host pypi.douban.com</code></p><p><code>pip3 install &quot;pymssql&lt;3.0&quot; -i http://pypi.douban.com/simple --trusted-host pypi.douban.com </code></p><p>接下来我们去我们的mysql里执行</p><p><code>CREATE DATABASE </code>superset <code>/*!40100 DEFAULT CHARACTER SET utf8 */;</code></p><p>创建其源数据库</p><p><strong>修改superset元数据库</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk"> vim superset-py3<span class="hljs-regexp">/lib/</span>python3.<span class="hljs-number">6</span><span class="hljs-regexp">/site-packages/</span>superset/config.py<br><br>修改：<br>SQLALCHEMY_DATABASE_URI = <span class="hljs-string">&#x27;mysql://root:123456@hadoop102/superset?charset=utf8&#x27;</span><br></code></pre></td></tr></table></figure><p>如果没有这个文件的同学，就是上面安装superset的那一步出问题了，要重新执行</p><p><strong>初始化Supetset数据库（Supetset是一个web应用，自带数据库，需要初始化）</strong></p><p><code> superset db upgrade</code></p><p><strong>创建管理员用户</strong></p><p><code>export FLASK_APP=superset</code></p><p><code>flask fab create-admin</code></p><p><strong>说明：</strong> flask是一个python web框架，Superset使用的就是flask</p><p><strong>Superset初始化</strong></p><p><code> superset init</code></p><p>然后我们要修改mysql里的表</p><p><code>alter table superset.table_columns modify type varchar(255);</code></p><p>然后就可以启动我们的superset了</p><p><code> superset run -h 自己的机器名或者ip  -p 启动端口</code></p><p>然后访问</p><p><code>http://机器ip或者机器名字:端口/</code></p><p>老规矩接下来我们创建个启动脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">check_log_dir</span></span>()<br>&#123;<br>    SUPERSET_LOG_DIR=/usr/local/src/superset/logs<br>    <span class="hljs-keyword">if</span> [ ! -d <span class="hljs-variable">$SUPERSET_LOG_DIR</span> ]<br>    <span class="hljs-keyword">then</span><br>        <span class="hljs-built_in">mkdir</span> -p <span class="hljs-variable">$SUPERSET_LOG_DIR</span><br>    <span class="hljs-keyword">fi</span><br>&#125;<br><br><span class="hljs-comment">#检查进程是否运行正常，参数1为进程名，参数2为进程端口</span><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">check_process</span></span>()<br>&#123;<br>    pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i <span class="hljs-variable">$1</span> | awk <span class="hljs-string">&#x27;&#123;print $2&#125;&#x27;</span>)<br>    ppid=$(netstat -nltp 2&gt;/dev/null | grep <span class="hljs-variable">$2</span> | awk <span class="hljs-string">&#x27;&#123;print $7&#125;&#x27;</span> | <span class="hljs-built_in">cut</span> -d <span class="hljs-string">&#x27;/&#x27;</span> -f 1)<br>    <span class="hljs-built_in">echo</span> <span class="hljs-variable">$pid</span><br>    [ <span class="hljs-string">&quot;<span class="hljs-variable">$ppid</span>&quot;</span> ] &amp;&amp; <span class="hljs-built_in">return</span> 0 || <span class="hljs-built_in">return</span> 1<br>&#125;<br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">superset_start</span></span>()<br>&#123;<br>    metapid=$(check_process superset 8889)<br>    cmd=<span class="hljs-string">&quot;cd /root/公共/Python-3.6.6;source superset-py3/bin/activate;nohup superset run -h bigdata4 -p 8889 &gt;<span class="hljs-variable">$SUPERSET_LOG_DIR</span>/superset.log 2&gt;&amp;1 &amp;&quot;</span><br>    <span class="hljs-built_in">eval</span> <span class="hljs-variable">$cmd</span> || <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;superset服务已启动&quot;</span><br>&#125;<br><br><br><span class="hljs-keyword">function</span> <span class="hljs-function"><span class="hljs-title">superset_stop</span></span>()<br>&#123;<br>    metapid=$(check_process superset 8889)<br>    [ <span class="hljs-string">&quot;<span class="hljs-variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="hljs-built_in">kill</span> <span class="hljs-variable">$metapid</span> || <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;superset服务未启动&quot;</span><br>&#125;<br><br><br><span class="hljs-keyword">case</span> <span class="hljs-variable">$1</span> <span class="hljs-keyword">in</span><br><span class="hljs-string">&quot;start&quot;</span>)<br>     check_log_dir<br>     superset_start<br>    ;;<br><span class="hljs-string">&quot;stop&quot;</span>)<br>     superset_stop<br>    ;;<br><span class="hljs-string">&quot;status&quot;</span>)<br>     check_process superset 8889 &gt;/dev/null &amp;&amp; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;superset服务运行正常&quot;</span> || <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;superset服务运行异常&quot;</span><br>    ;;<br>*)<br>    <span class="hljs-built_in">echo</span> Invalid Args!<br>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;Usage: &#x27;</span>$(<span class="hljs-built_in">basename</span> <span class="hljs-variable">$0</span>)<span class="hljs-string">&#x27; start|stop|status&#x27;</span><br>    ;;<br><span class="hljs-keyword">esac</span><br><br><br></code></pre></td></tr></table></figure><p>关于superset的原生安装就ok了</p><h1 id="dataease"><a href="#dataease" class="headerlink" title="dataease"></a>dataease</h1><p>先在官网下载官网地址 ： <a href="https://www.fit2cloud.com/dataease/features.html">https://www.fit2cloud.com/dataease/features.html</a></p><p>目前没有时间等周六周日补上</p><p>dataease安装特别简单而且图形炫酷，首推</p><p>但是有问题：安装dataease的机器上不能有mysql或者你把mysql的端口改掉，因为它要占用3306端口</p><p>不管是在线安装还是离线安装对我们的数据库都有要求，mysql 5.7起步</p><p>而且要求我们编辑&#x2F;etc&#x2F;my.cnf文件</p><p>然后添加以下内容 </p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[mysqld]<br><span class="hljs-attribute">datadir</span>=/var/lib/mysql<br><br><span class="hljs-attribute">default-storage-engine</span>=INNODB<br><span class="hljs-attribute">character_set_server</span>=utf8<br><span class="hljs-attribute">lower_case_table_names</span>=1<br><span class="hljs-attribute">table_open_cache</span>=128<br><span class="hljs-attribute">max_connections</span>=2000<br><span class="hljs-attribute">max_connect_errors</span>=6000<br><span class="hljs-attribute">innodb_file_per_table</span>=1<br><span class="hljs-attribute">innodb_buffer_pool_size</span>=1G<br><span class="hljs-attribute">max_allowed_packet</span>=64M<br><span class="hljs-attribute">transaction_isolation</span>=READ-COMMITTED<br><span class="hljs-attribute">innodb_flush_method</span>=O_DIRECT<br><span class="hljs-attribute">innodb_lock_wait_timeout</span>=1800<br><span class="hljs-attribute">innodb_flush_log_at_trx_commit</span>=0<br><span class="hljs-attribute">sync_binlog</span>=0<br><span class="hljs-attribute">group_concat_max_len</span>=1024000<br><span class="hljs-attribute">sql_mode</span>=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION<br>skip-name-resolve<br><br>[mysql]<br><span class="hljs-attribute">default-character-set</span>=utf8<br><br>[mysql.server]<br><span class="hljs-attribute">default-character-set</span>=utf8<br></code></pre></td></tr></table></figure><p>在线安装 ：<code>curl -sSL https://github.com/dataease/dataease/releases/latest/download/quick_start.sh | sh</code></p><p>就可以了</p><p>离线安装：</p><p>先下载好安装包然后解压，之后到解压的目录，然后编辑install.conf文件下面是install.conf的配置</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment"># 基础配置</span><br><span class="hljs-comment">## 安装目录</span><br><span class="hljs-attr">DE_BASE</span>=/opt<br><span class="hljs-comment">## Service 端口</span><br><span class="hljs-attr">DE_PORT</span>=<span class="hljs-number">80</span><br><span class="hljs-comment">## 部署及运行模式，可选值有 local、simple、cluster，分别对应 本地模式、精简模式、集群模式</span><br><span class="hljs-attr">DE_ENGINE_MODE</span>=simple<br><span class="hljs-comment">## docker 网段设置</span><br><span class="hljs-attr">DE_DOCKER_SUBNET</span>=<span class="hljs-number">172.19</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">16</span><br><span class="hljs-comment">## docker 网关 IP</span><br><span class="hljs-attr">DE_DOCKER_GATEWAY</span>=<span class="hljs-number">172.19</span>.<span class="hljs-number">0.1</span><br><span class="hljs-comment">## Apache Doris FE IP (外部 Doris 此参数无效)</span><br><span class="hljs-attr">DE_DORIS_FE_IP</span>=<span class="hljs-number">172.19</span>.<span class="hljs-number">0.198</span><br><span class="hljs-comment">## Apache Doris BE IP (外部 Doris 此参数无效)</span><br><span class="hljs-attr">DE_DORIS_BE_IP</span>=<span class="hljs-number">172.19</span>.<span class="hljs-number">0.199</span><br><br><span class="hljs-comment"># 数据库配置</span><br><span class="hljs-comment">## 是否使用外部数据库</span><br><span class="hljs-attr">DE_EXTERNAL_MYSQL</span>=<span class="hljs-literal">false</span><br><span class="hljs-comment">## 数据库地址</span><br><span class="hljs-attr">DE_MYSQL_HOST</span>=mysql<br><span class="hljs-comment">## 数据库端口</span><br><span class="hljs-attr">DE_MYSQL_PORT</span>=<span class="hljs-number">3306</span><br><span class="hljs-comment">## DataEase 数据库库名</span><br><span class="hljs-attr">DE_MYSQL_DB</span>=dataease<br><span class="hljs-comment">## 数据库用户名</span><br><span class="hljs-attr">DE_MYSQL_USER</span>=root<br><span class="hljs-comment">## 数据库密码</span><br><span class="hljs-attr">DE_MYSQL_PASSWORD</span>=Password123@mysql<br><br><span class="hljs-comment"># Apache Doris 配置</span><br><span class="hljs-comment">## 是否使用外部 Apache Doris</span><br><span class="hljs-attr">DE_EXTERNAL_DORIS</span>=<span class="hljs-literal">false</span><br><span class="hljs-comment">## Doris 地址</span><br><span class="hljs-attr">DE_DORIS_HOST</span>=doris-fe<br><span class="hljs-comment">## Doris 查询连接端口</span><br><span class="hljs-attr">DE_DORIS_PORT</span>=<span class="hljs-number">9030</span><br><span class="hljs-comment">## Doris http端口</span><br><span class="hljs-attr">DE_DORIS_HTTPPORT</span>=<span class="hljs-number">8030</span><br><span class="hljs-comment">## Doris 数据库名称</span><br><span class="hljs-attr">DE_DORIS_DB</span>=dataease<br><span class="hljs-comment">## Doris 用户名</span><br><span class="hljs-attr">DE_DORIS_USER</span>=root<br><span class="hljs-comment">## Doris 密码</span><br><span class="hljs-attr">DE_DORIS_PASSWORD</span>=Password123@doris<br><br><span class="hljs-comment"># Kettle 配置</span><br><span class="hljs-comment">## 是否使用外部 Kettle - (目前还不支持外部Kettle，除非不需运行Kettle，否则请不要修改此参数)</span><br><span class="hljs-attr">DE_EXTERNAL_KETTLE</span>=<span class="hljs-literal">false</span><br><span class="hljs-comment">## Kettle 服务器地址</span><br><span class="hljs-attr">DE_CARTE_HOST</span>=kettle<br><span class="hljs-comment">## Kettle 访问端口</span><br><span class="hljs-attr">DE_CARTE_PORT</span>=<span class="hljs-number">18080</span><br><span class="hljs-comment">## Kettle 用户名</span><br><span class="hljs-attr">DE_CARTE_USER</span>=cluster<br><span class="hljs-comment">## Kettle 密码</span><br><span class="hljs-attr">DE_CARTE_PASSWORD</span>=cluster<br></code></pre></td></tr></table></figure><p>安装模式有三种 ：</p><p><strong>DE_ENGINE_MODE&#x3D;local</strong><br>使用本地模式安装，DataEase 会自带 Doris 与 Kettle 组件，无需再做额外配置，但各组件均为单点，不具备高可用特性。<br>在此模式下，Excel 数据集、API 数据集以及定时同步的数据默认保存在自带的 Doris 组件中。</p><p><strong>DE_ENGINE_MODE&#x3D;simple</strong><br>使用精简模式安装，系统不会额外安装 Doris 与 Kettle 组件，提供用户轻量级的应用系统，尤其是对接数据量较小的情况。<br>在此模式下，若用户需要使用 Excel 数据集或 API 数据集可在系统管理界面配置数据引擎（目前仅支持 MySQL 类型），相关数据会存储到该数据引擎中。若只需使用数据库直连则无需做此配置。<br><strong>注意：由于精简模式未配置 Kettle 与 Doris，故相关 SQL 数据集&#x2F;数据库数据集不提供定时同步模式。</strong></p><p><strong>DE_ENGINE_MODE&#x3D;cluster</strong><br>使用集群模式安装，系统不会额外安装 Doris 与 Kettle 组件，但会在系统管理模块提供 Doris 与 Kettle 的链接配置界面（请参考【系统管理】的【系统参数】说明），用户可独立安装 Doris 集群及 Kettle 并配置在 DataEase 中。集群模式下 Excel 数据集，API 数据集以及定时同步的数据通过 Kettle 抽取到 Doris 集群中。<br>Doris 安装部署可参考：<a href="http://doris.incubator.apache.org/zh-CN/">http://doris.incubator.apache.org/zh-CN/</a><br>Kettle 安装部署可参考：<a href="http://www.kettle.org.cn/">http://www.kettle.org.cn/</a></p><p>然后对于离线安装执行</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 进入安装包目录</span><br>cd dataease-v1.<span class="hljs-number">5.0</span>-offline<br><span class="hljs-comment"># 运行安装脚本</span><br><span class="hljs-regexp">/bin/</span>bash install.sh<br></code></pre></td></tr></table></figure><p>就可以了，效果个很酷炫</p><h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>有一个城市表 ： mysql中</p><p>有一个商品表 ： mysql中</p><p>用户行为数据 ： hdfs上的</p><p>求： 最受欢迎的商品 的 top3</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/06/12-06/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>大数据的简单构架</title>
      <link>http://zihang.fun/2022/12/05/12-05/</link>
      <guid>http://zihang.fun/2022/12/05/12-05/</guid>
      <pubDate>Mon, 05 Dec 2022 01:12:53 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;大数据的三件事&quot;&gt;&lt;a href=&quot;#大数据的三件事&quot; class=&quot;headerlink&quot; title=&quot;大数据的三件事&quot;&gt;&lt;/a&gt;大数据的三件事&lt;/h1&gt;&lt;p&gt;数据采集  ：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;采集业务数据 ： sqoop ,datax,实时采集max</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="大数据的三件事"><a href="#大数据的三件事" class="headerlink" title="大数据的三件事"></a>大数据的三件事</h1><p>数据采集  ：</p><ul><li>采集业务数据 ： sqoop ,datax,实时采集maxwell ,flinkdoc</li><li>采集日志数据 ： flume ，logstush</li></ul><p>数据存储 :</p><ul><li>hdfs (hadoop中的)</li><li>hive</li><li>hbase【大数据】</li><li>数据分析之后的结果数据 ：<ul><li>mysql</li><li>clickhouse</li><li>drios</li></ul></li></ul><p>数据分析：</p><ul><li>map reduce 但是现在不怎么用了，但是思想最重要</li><li>hive ： 主要是离线数仓</li><li>hbase</li><li>spark</li><li>flink</li></ul><p>数据可视化 ：</p><ul><li>如果有前端开发人员，可以让他们来帮忙</li><li>但是如果没有 要自己做<ul><li>superset</li><li>dataease</li><li>echarts</li><li>env</li><li>anv</li></ul></li><li>收费 : 简历上最好不要写这个<ul><li>quickbi</li><li>sugar</li></ul></li></ul><p>消息中间键 ：</p><ul><li>kafka</li><li>pular</li></ul><p>(即席查询 ： 临时查询) : presto是最好用的 clickhouse 是有bug的 对内存有要求</p><ul><li>sparksql , presto , druid , clickhouse ,kylin(cube)</li></ul><p>数据种类 ：</p><ul><li>业务数据【mysql ， es】app</li><li>日志数据 【log】linux 磁盘上 ，工作中处理的一个重点<ul><li>展现日志，点击日志，跳转日志</li></ul></li><li>其他数据</li></ul><p>架构图  ：</p><ul><li>业务数据 ： mysql -》sqoop ， datax -》 hds&#x2F;hive</li><li>日志数据 ： log文件 -》 flume -》 hdfs&#x2F;hive</li><li>hive : 构建离线数仓<ul><li>数据分层</li><li>维度建模</li><li>指标输出</li></ul></li><li>数据可实话<ul><li>hive -》 sqoop -》 mysql &#x2F; clickhouse -》数据可视化</li></ul></li></ul><p>大数据的基础平台架构</p><p>提升 ：大数据的数据平台</p><p>大数据基础是相当于 从  0-1 搭建 -》 可以学到以上的所有框架</p><p>大数据的数据平台 是基于基础平台再提升了升级 -》 这个学不到什么东西</p><p>大数据升级平台</p><p>大数据数据开发</p><ul><li>离线数仓</li><li>实时数仓</li><li>临时查询</li></ul><p>大数据的etl工程师</p><ul><li>数据清洗</li><li>数据抽取</li><li>数据转换</li></ul><p>大数据运维工程师</p><ul><li>上述的框架是它负责安装以及部署的</li><li>以及后续的维护</li><li>云原生 ， docker ，k8s</li></ul><p>大数据算法组（数据分析师sql + 数学知识统计 。数据科学家）</p><ul><li>用户画像</li><li>数据挖掘<ul><li>python</li><li>spark , flink 自带的组件 机器学习相关的组件 ： 速度要比py快</li></ul></li></ul><p>新颖的</p><ul><li>数据湖 -》主要研究方向</li><li>云原生 -》 docker ，k8s<ul><li>job -》 申请资源 是再yarn上的 ，但是当yarn 做资源隔离的时候万一有三台机器 ，到时候如果所有container 都集中在一台机器上，则会造成机器得负载太大</li><li>解决方法 ：<ul><li>yarn 的底层编码重写</li><li>联合云原生</li></ul></li></ul></li></ul><h1 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h1><p>简介 ： 可以把数据和hadoop生态圈进行数据库同步，数据传输</p><p>sqoop</p><ul><li>我们可以通过sqoop这个组件 ，把mysql 里的表 同步到 hdfs，hive ，hbase</li><li>反之也可以</li><li>原理<ul><li>sqoop 是只用map阶段 ，无reduce 阶段 （通过mapreduce 实现的）</li></ul></li><li>指定的参数<ul><li>url</li><li>username</li><li>password</li><li>驱动</li></ul></li><li>sqoop版本<ul><li>sqoop 1 ：1.4.7</li><li>sqoop 2 ：1.99.7</li><li>注意这两个是没有任何联系的</li><li>建议用1</li></ul></li></ul><h1 id="部署sqoop"><a href="#部署sqoop" class="headerlink" title="部署sqoop"></a>部署sqoop</h1><p>这里我使用的是1.4.7的sqoop包</p><p>首先我们上传到linux上</p><p>然后解压</p><p>解压之后我们进入到conf目录下，这个里面存的是我们的 配置文件</p><p>我们把sqoop-env-template.sh 改名字成 sqoop-env.sh</p><p>然后vim 它进行编辑</p><p>把hadoop home 的路径放上 ，以及 hive的路经</p><p>然后保存退出</p><p>我们接下来在全局变量中注册一下sqoop的bin目录</p><p>然后把mysql的connect包给到lib文件夹下</p><p>然后执行</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">1</span>.查看可用的数据库 【<span class="hljs-string">mysql</span>】<br><span class="hljs-string">sqoop</span> <span class="hljs-built_in">list-databases</span> \<br><span class="hljs-built_in">--connect</span> <span class="hljs-string">jdbc:mysql:</span>//<span class="hljs-string">bigdata2:3306 </span> \<br><span class="hljs-built_in">--username</span> <span class="hljs-string">root</span>  \<br><span class="hljs-built_in">--password</span> <span class="hljs-string">liuzihan010616</span><br></code></pre></td></tr></table></figure><p>1.4.7会报错 ，因为 缺少java.commons.lang包</p><p>我们把这个包上传到lib下就好了</p><h1 id="导入和导出"><a href="#导入和导出" class="headerlink" title="导入和导出"></a>导入和导出</h1><p>sqoop的导入和导出</p><p>从mysql里导出数据的时候，会默认导入到&#x2F;user&#x2F;hadoop&#x2F;*</p><p>hdfs 文件存储 默认是用 ，进行分割每个字段的</p><p>hdfs上有几个文件就是有几个map task 和reduce task</p><p>其默认的数量是4</p><p>导出</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs arduino">sqoop <span class="hljs-keyword">import</span> \<br>--connect jdbc:mysql:<span class="hljs-comment">//bigdata2:3306/hive  \</span><br><span class="hljs-comment">--username root  \</span><br><span class="hljs-comment">--password liuzihan010616 \</span><br><span class="hljs-comment">--table TBLS</span><br></code></pre></td></tr></table></figure><p>设置导出的列的参数</p><p><code>--columns</code></p><p>设置字段筛选的参数</p><p><code>--where</code></p><p>设置再yarn上的作业名称</p><p><code>--mapreduce-job-name</code></p><p>设置 map 和 reduce task 的个数</p><p><code>-m,--num-mappers &lt;n&gt; </code></p><p>用-m 或者后面的都行</p><p>设置hdfs上的文件夹</p><p><code>--target-dir</code></p><p>设置hdfs上存储的分隔符</p><p><code>--fields-terminated-by </code></p><p>删除目标文件夹</p><p><code>--delete-target-dir </code></p><p>总体应用</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-string">sqoop</span>  <span class="hljs-string">import</span> \<br><span class="hljs-built_in">--connect</span> <span class="hljs-string">jdbc:mysql:</span>//<span class="hljs-string">bigdata2:3306/</span><span class="hljs-string">hive</span>  \<br><span class="hljs-built_in">--username</span> <span class="hljs-string">root</span>  \<br><span class="hljs-built_in">--password</span> <span class="hljs-string">liuzihan010616</span> \<br><span class="hljs-built_in">--delete-target-dir</span> \<br><span class="hljs-built_in">--fields-terminated-by</span> <span class="hljs-string">&#x27;\&#x27;</span> \<br><span class="hljs-built_in">--target-dir</span> /<span class="hljs-string">ghk</span> \<br>-<span class="hljs-string">m</span> <span class="hljs-string">1</span> \<br><span class="hljs-built_in">--mapreduce-job-name</span> <span class="hljs-string">&#x27;mysql 的数据try&#x27;</span> \<br><span class="hljs-built_in">--where</span> <span class="hljs-string">&#x27;TBL_ID &gt;= 10&#x27;</span> \<br><span class="hljs-built_in">--columns</span> <span class="hljs-string">&#x27;TBL_ID , OWNER&#x27;</span> \<br><span class="hljs-built_in">--table</span> <span class="hljs-string">TBLS</span><br></code></pre></td></tr></table></figure><p>有主键的表可以直接按照上述同步</p><p>但是没主键的，要转化</p><p>如果是没有主键的表，有两种转换方法</p><p>首先是可以通过  ： -m 设置为1 或者 –split-by 列的名字</p><p>如下 ：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">sqoop  import \<br><span class="hljs-params">--connect</span> jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  \<br><span class="hljs-params">--username</span> root  \<br><span class="hljs-params">--password</span> liuzihan010616 \<br><span class="hljs-params">--delete-target-dir</span> \<br><span class="hljs-params">--fields-terminated-by</span> &#x27;\&#x27; \<br><span class="hljs-params">--target-dir</span> <span class="hljs-string">/ghk</span> \<br><span class="hljs-params">--split-by</span> empno \<br><span class="hljs-params">--mapreduce-job-name</span> &#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; \<br><span class="hljs-params">--table</span> emp<br></code></pre></td></tr></table></figure><p>空值处理 ：</p><p><code>--null-non-string 0</code></p><p>上面的那个是不是string的处理</p><p><code>--null-string &#39;&#39;</code></p><h2 id="嵌套sql"><a href="#嵌套sql" class="headerlink" title="嵌套sql"></a>嵌套sql</h2><p>用 –query</p><p>但是有注意的点</p><p>有–query 的时候，不能放–table</p><p>且–query 后面只能接单引号</p><p>如下</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">sqoop  import \<br><span class="hljs-params">--connect</span> jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  \<br><span class="hljs-params">--username</span> root  \<br><span class="hljs-params">--password</span> liuzihan010616 \<br><span class="hljs-params">--delete-target-dir</span> \<br><span class="hljs-params">--fields-terminated-by</span> &#x27;\&#x27; \<br><span class="hljs-params">--target-dir</span> <span class="hljs-string">/ghk</span> \<br><span class="hljs-params">--split-by</span> empno \<br><span class="hljs-params">--mapreduce-job-name</span> &#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; \<br><span class="hljs-params">--query</span> &#x27;select * from emp where $CONDITIONS&#x27;<br></code></pre></td></tr></table></figure><h1 id="简化"><a href="#简化" class="headerlink" title="简化"></a>简化</h1><p>如上述</p><p>我们发现太繁琐了</p><p>我们可以进行封装到一起</p><p>然后直接调用文件就行</p><p><code>sqoop --options-file 文件路径</code></p><p>文件内容如下 ：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">import <br><span class="hljs-params">--connect</span> <br>jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  <br><span class="hljs-params">--username</span> <br>root  <br><span class="hljs-params">--password</span> <br>liuzihan010616 <br><span class="hljs-params">--delete-target-dir</span> <br><span class="hljs-params">--fields-terminated-by</span> <br>&#x27;\&#x27; <br><span class="hljs-params">--target-dir</span><br><span class="hljs-string">/ghk</span> <br><span class="hljs-params">--split-by</span> <br>empno <br><span class="hljs-params">--mapreduce-job-name</span> <br>&#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; <br><span class="hljs-params">--query</span> <br>&#x27;select * from emp where $CONDITIONS&#x27;<br></code></pre></td></tr></table></figure><h3 id="sqoop-job"><a href="#sqoop-job" class="headerlink" title="sqoop job"></a>sqoop job</h3><ul><li>create 创建job</li><li>list&#x2F;show 查看job list 是查看列表 show 是查看详情</li><li>exec 执行job</li></ul><p>代码如下 ：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">scoop job <span class="hljs-params">--create</span> mysqltry -- \<br>import \<br><span class="hljs-params">--connect</span> <br>jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  \<br><span class="hljs-params">--username</span> root  \<br><span class="hljs-params">--password</span> liuzihan010616 \<br><span class="hljs-params">--delete-target-dir</span> \<br><span class="hljs-params">--fields-terminated-by</span> &#x27;\&#x27; \<br><span class="hljs-params">--target-dir</span> <span class="hljs-string">/ghk</span> \<br><span class="hljs-params">--split-by</span> empno \<br><span class="hljs-params">--mapreduce-job-name</span> &#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; \<br><span class="hljs-params">--query</span> &#x27;select * from emp where $CONDITIONS&#x27;<br></code></pre></td></tr></table></figure><h2 id="shell脚本"><a href="#shell脚本" class="headerlink" title="shell脚本"></a>shell脚本</h2><p>也可以通过shell脚本调用 sqoop</p><p>如下 ：普通表的</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><code class="hljs awk"><br><br><br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> -lt <span class="hljs-number">6</span> ];then<br> echo <span class="hljs-string">&quot;$0 use sync mysql 2 hive&quot;</span><br> echo <span class="hljs-string">&quot;USAGE:$0 mysqldb sql hivedb hivetable idautocreatetable fengefu&quot;</span><br> echo <span class="hljs-string">&quot;Example mysql的数据库 sql语句 hive的数据库  hive的表 分隔符 是不是自动创建表&quot;</span><br> <span class="hljs-keyword">exit</span> <span class="hljs-number">1</span>;<br>fi<br><br><span class="hljs-comment">#mysql parm</span><br>mysqldb=<span class="hljs-variable">$1</span><br>sql=<span class="hljs-string">&quot;$2&quot;</span><br><span class="hljs-comment">#hive parms </span><br>hivedb=<span class="hljs-variable">$3</span><br>hivetable=<span class="hljs-variable">$4</span><br>flag =<span class="hljs-variable">$6</span><br><br>try <span class="hljs-string">&#x27;select * from emp&#x27;</span> bigdata_hive3 emp6 , <span class="hljs-number">1</span><br><br>MySQL_URL=<span class="hljs-string">&quot;jdbc:mysql://bigdata2:3306/$&#123;mysqldb&#125;&quot;</span> <br>MySQL_USER=root<br>MySQL_PASSWD=liuzihan010616<br>FIELDS_TERMINATED=<span class="hljs-variable">$5</span><br><br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$&#123;flag&#125;</span> -eq <span class="hljs-number">1</span> ];then<br>sqoop import \<br>--connect <span class="hljs-variable">$&#123;MySQL_URL&#125;</span>  \<br>--username <span class="hljs-variable">$&#123;MySQL_USER&#125;</span>  \<br>--password <span class="hljs-variable">$&#123;MySQL_PASSWD&#125;</span> \<br>--mapreduce-job-name <span class="hljs-string">&#x27;mysql2hive&#x27;</span> \<br>--<span class="hljs-keyword">delete</span>-target-dir \<br>--target-dir <span class="hljs-regexp">/sqoop/</span>emp_tmp \<br>--fields-terminated-by <span class="hljs-variable">$&#123;FIELDS_TERMINATED&#125;</span> \<br>-m <span class="hljs-number">1</span> \<br>--query <span class="hljs-string">&quot;$&#123;sql&#125; and \$CONDITIONS &quot;</span> \<br>--hive-import \<br>--create-hive-table \<br>--hive-overwrite \<br>--hive-database <span class="hljs-variable">$&#123;hivedb&#125;</span> \<br>--hive-table <span class="hljs-variable">$&#123;hivetable&#125;</span><br><span class="hljs-keyword">else</span><br>sqoop import \<br>--connect <span class="hljs-variable">$&#123;MySQL_URL&#125;</span>  \<br>--username <span class="hljs-variable">$&#123;MySQL_USER&#125;</span>  \<br>--password <span class="hljs-variable">$&#123;MySQL_PASSWD&#125;</span> \<br>--mapreduce-job-name <span class="hljs-string">&#x27;mysql2hive&#x27;</span> \<br>--<span class="hljs-keyword">delete</span>-target-dir \<br>--target-dir <span class="hljs-regexp">/sqoop/</span>emp_tmp \<br>--fields-terminated-by <span class="hljs-variable">$&#123;FIELDS_TERMINATED&#125;</span> \<br>-m <span class="hljs-number">1</span> \<br>--query <span class="hljs-string">&quot;$&#123;sql&#125; and \$CONDITIONS &quot;</span> \<br>--hive-import \<br>--hive-overwrite \<br>--hive-database <span class="hljs-variable">$&#123;hivedb&#125;</span> \<br>--hive-table <span class="hljs-variable">$&#123;hivetable&#125;</span><br><span class="hljs-keyword">exit</span> <span class="hljs-number">200</span>;<br>fi<br>---------------------------------分区表--------------------------------------------<br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> -lt <span class="hljs-number">8</span> ];then<br> echo <span class="hljs-string">&quot;$0 use sync mysql 2 hive&quot;</span><br> echo <span class="hljs-string">&quot;USAGE:$0 mysqldb sql hivedb hivetable idautocreatetable fengefu hivepartition hivepartitionvalue&quot;</span><br> echo <span class="hljs-string">&quot;Example mysql的数据库 sql语句 hive的数据库  hive的table 分隔符  hive的分区属性 分区属性的值 是不是自动创建表&quot;</span><br> <span class="hljs-keyword">exit</span> <span class="hljs-number">1</span>;<br>fi<br><br><span class="hljs-comment">#mysql parm</span><br>mysqldb=<span class="hljs-variable">$1</span><br>sql=<span class="hljs-string">&quot;$2&quot;</span><br><span class="hljs-comment">#hive parms </span><br>hivedb=<span class="hljs-variable">$3</span><br>hivetable=<span class="hljs-variable">$4</span><br>hivepartition=<span class="hljs-variable">$6</span><br>hivepartitionvalue=<span class="hljs-variable">$7</span><br>flag=<span class="hljs-variable">$8</span><br>MySQL_URL=<span class="hljs-string">&quot;jdbc:mysql://bigdata2:3306/$&#123;mysqldb&#125;&quot;</span> <br>MySQL_USER=root<br>MySQL_PASSWD=liuzihan010616<br>FIELDS_TERMINATED=<span class="hljs-variable">$5</span><br><br><br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$&#123;flag&#125;</span> -eq <span class="hljs-number">1</span> ];then<br>sqoop import \<br>--connect <span class="hljs-variable">$&#123;MySQL_URL&#125;</span>  \<br>--username <span class="hljs-variable">$&#123;MySQL_USER&#125;</span>  \<br>--password <span class="hljs-variable">$&#123;MySQL_PASSWD&#125;</span> \<br>--mapreduce-job-name <span class="hljs-string">&#x27;mysql2hive&#x27;</span> \<br>--<span class="hljs-keyword">delete</span>-target-dir \<br>--target-dir <span class="hljs-regexp">/sqoop/</span>emp_tmp \<br>--fields-terminated-by <span class="hljs-variable">$&#123;FIELDS_TERMINATED&#125;</span> \<br>-m <span class="hljs-number">1</span> \<br>--query <span class="hljs-string">&quot;$&#123;sql&#125; and \$CONDITIONS &quot;</span> \<br>--hive-import \<br>--hive-overwrite \<br>--create-hive-table \ <br>--hive-database <span class="hljs-variable">$&#123;hivedb&#125;</span> \<br>--hive-table <span class="hljs-variable">$&#123;hivetable&#125;</span> \<br>--hive-partition-key <span class="hljs-variable">$&#123;hivepartition&#125;</span> \<br>--hive-partition-value <span class="hljs-variable">$&#123;hivepartitionvalue&#125;</span><br><span class="hljs-keyword">else</span><br>sqoop import \<br>--connect <span class="hljs-variable">$&#123;MySQL_URL&#125;</span>  \<br>--username <span class="hljs-variable">$&#123;MySQL_USER&#125;</span>  \<br>--password <span class="hljs-variable">$&#123;MySQL_PASSWD&#125;</span> \<br>--mapreduce-job-name <span class="hljs-string">&#x27;mysql2hive&#x27;</span> \<br>--<span class="hljs-keyword">delete</span>-target-dir \<br>--target-dir <span class="hljs-regexp">/sqoop/</span>emp_tmp \<br>--fields-terminated-by <span class="hljs-variable">$&#123;FIELDS_TERMINATED&#125;</span> \<br>-m <span class="hljs-number">1</span> \<br>--query <span class="hljs-string">&quot;$&#123;sql&#125; and \$CONDITIONS &quot;</span> \<br>--hive-import \<br>--hive-overwrite \<br>--hive-database <span class="hljs-variable">$&#123;hivedb&#125;</span> \<br>--hive-table <span class="hljs-variable">$&#123;hivetable&#125;</span> \<br>--hive-partition-key <span class="hljs-variable">$&#123;hivepartition&#125;</span> \<br>--hive-partition-value <span class="hljs-variable">$&#123;hivepartitionvalue&#125;</span><br>fi<br>-----------------------------------------------------hivetomysql的----------------------------------------------------<br><span class="hljs-keyword">if</span> [ <span class="hljs-variable">$#</span> -lt <span class="hljs-number">4</span> ];then<br>echo <span class="hljs-string">&quot;error 变量小于4个&quot;</span><br>echo <span class="hljs-string">&quot;example try , /user/hive/warehouse/bigdata_hive3.db/emp_partition/deptno=20 emp1&quot;</span><br>echo <span class="hljs-string">&quot;mysql数据库 分隔符 hdfs上的路径 mysql里的表名&quot;</span><br>fi<br><br>mysqldb=<span class="hljs-variable">$1</span><br>fengefu=<span class="hljs-variable">$2</span><br>hdfslujing=<span class="hljs-variable">$3</span><br>mysqltable=<span class="hljs-variable">$4</span><br><br>hive -e <span class="hljs-string">&quot;use bigdata_hive3 ; create table &quot;</span><br><br>sqoop export \<br>--connect jdbc:mysql:<span class="hljs-regexp">//</span>bigdata2:<span class="hljs-number">3306</span>/<span class="hljs-variable">$&#123;mysqldb&#125;</span>  \<br>--username root  \<br>--password liuzihan010616 \<br>--fields-terminated-by <span class="hljs-variable">$&#123;fengefu&#125;</span> \<br>--export-dir <span class="hljs-variable">$&#123;hdfslujing&#125;</span> \<br>--null-non-string <span class="hljs-number">0</span><br>--null-string <span class="hljs-string">&#x27;&#x27;</span><br>--table <span class="hljs-variable">$&#123;mysqltable&#125;</span> <br>----------------------------------------------hivetomysql的分区表如何同步-----------------------<br>先把hive的分区表用create table zz as elect * from xxx(分区表的名字) <br>然后把zz当成普通表传过去 ，但是在sqoop1.<span class="hljs-number">4.7</span> 目前这个功能出现了些问题<br> <br></code></pre></td></tr></table></figure><h1 id="从mysql-到-hive等工具中"><a href="#从mysql-到-hive等工具中" class="headerlink" title="从mysql 到 hive等工具中"></a>从mysql 到 hive等工具中</h1><p>大部分都和上述一样的</p><p>只不过要换个链接以及表名字</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">sqoop import \<br><span class="hljs-params">--connect</span> jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  \<br><span class="hljs-params">--username</span> root  \<br><span class="hljs-params">--password</span> liuzihan010616 \<br><span class="hljs-params">--delete-target-dir</span> \<br><span class="hljs-params">--fields-terminated-by</span> &#x27;\&#x27; \<br><span class="hljs-params">--target-dir</span> <span class="hljs-string">/ghk</span> \<br><span class="hljs-params">--split-by</span> empno \<br><span class="hljs-params">--mapreduce-job-name</span> &#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; \<br><span class="hljs-params">--query</span> &#x27;select * from emp where $CONDITIONS&#x27; \<br><span class="hljs-params">--hive-import</span> \<br><span class="hljs-params">--hive-overwrite</span> \<br><span class="hljs-params">--create-hive-table</span> \ <br><span class="hljs-params">--hive-database</span> bigdata_hive3 \<br><span class="hljs-params">--hive-table</span> emp_hive1<br></code></pre></td></tr></table></figure><p>在1.4.7的版本中其要求必须 加上 <code>--target dir 属性</code></p><p>且要从hive的lib文件夹下，把所有jar包给sqoop的lib下</p><p>上述 create-hive-table 是自动创建表</p><p>但是因为mysql里的属性只有几个 ，没hive特有的decmical等，可能会造成丢失数据</p><p>所以提议先在hive中创建表，然后再导入</p><h2 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h2><p>分区表如上 ；只不过要用</p><p><code>--hive-partition-key xxxx（列名）</code></p><p><code>--hive-partition-value xxx(分区字段的数值)</code></p><p>或者可以直接用–query 用代码的方式进行分区</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">sqoop import \<br><span class="hljs-params">--connect</span> jdbc<span class="hljs-function">:mysql</span>:<span class="hljs-string">//bigdata2</span><span class="hljs-function">:3306</span>/<span class="hljs-keyword">try</span>  \<br><span class="hljs-params">--username</span> root  \<br><span class="hljs-params">--password</span> liuzihan010616 \<br><span class="hljs-params">--delete-target-dir</span> \<br><span class="hljs-params">--fields-terminated-by</span> &#x27;\&#x27; \<br><span class="hljs-params">--target-dir</span> <span class="hljs-string">/ghk</span> \<br><span class="hljs-params">--split-by</span> empno \<br><span class="hljs-params">--mapreduce-job-name</span> &#x27;mysql 的数据<span class="hljs-keyword">try</span>&#x27; \<br><span class="hljs-params">--query</span> &#x27;select empno,ename,job,mgr,hiredate,sal,comm from emp where deptno=20 and $CONDITIONS &#x27; \<br><span class="hljs-params">--hive-import</span> \<br><span class="hljs-params">--hive-overwrite</span> \<br><span class="hljs-params">--create-hive-table</span> \<br><span class="hljs-params">--hive-database</span> bigdata_hive3 \<br><span class="hljs-params">--hive-table</span> emp_partition \<br><span class="hljs-params">--hive-partition-key</span> deptno \<br><span class="hljs-params">--hive-partition-value</span> 20<br></code></pre></td></tr></table></figure><h2 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h2><p>不管是hdfs 或者是hive 都是基于路径导出</p><p>通过export导出</p><p>代码 ：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs arduino">sqoop <span class="hljs-keyword">export</span> \<br>--connect jdbc:mysql:<span class="hljs-comment">//bigdata2:3306/try  \</span><br><span class="hljs-comment">--username root  \</span><br><span class="hljs-comment">--password liuzihan010616 \</span><br><span class="hljs-comment">--table xxxX \</span><br><span class="hljs-comment">--fields-terminated-by &#x27;分隔符&#x27; \</span><br><span class="hljs-comment">--export-dir hdfs上的数据的路径 \</span><br></code></pre></td></tr></table></figure><p>这个是hdfs导入到mysql</p><p>sqoop导入hive到mysql的时候空值要先进行处理，</p><h1 id="开启历史日志"><a href="#开启历史日志" class="headerlink" title="开启历史日志"></a>开启历史日志</h1><p>开启开关 ：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>上述是日志收集的开关</p><p>下面是日志在hdfs上存储的lujing</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log.server.url<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>http://bigdata3:19888/jobhistory/logs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>下面是设置日志收集的时间</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>259200<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>接下来我们要配置mapred -site.xml</p><p>如下 ：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>bigdata3:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>bigdata3:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure><p>然后通过命令行的方式执行命令</p><p><code>yarn timelineserver   [bigdata4]</code></p><p><code>mapred historyserver  [bigdata3] </code></p><p>提示 ： 我的namenode在bigdata3上 ，而resourcemanager 在 bigdata4上</p><p>Hive建表时，默认使用的分隔符时候一个特殊的字符，查看表决结构时候是一个’\001’</p><p>这不是真正的’\001’，其实是使用八进制编码\001表示</p><h2 id="hive-table-gt-mysql-多次导入-数据结果不同"><a href="#hive-table-gt-mysql-多次导入-数据结果不同" class="headerlink" title="hive table -&gt; mysql 多次导入 数据结果不同"></a>hive table -&gt; mysql 多次导入 数据结果不同</h2><p>幂等性 ： 多次操作 ，数据结果是不变的</p><p>mysql - &gt; hive -&gt; hive-overwrite</p><p>hive -&gt; mysql 幂等性 如何解决</p><p>方法 ：</p><p>可以通过 <code>mysql -u root -p xxx -e sql语句</code></p><p>或者 <code>mysql -uroot -pliuzihan010616 &lt; ./try.sql 这个是执行sql文件</code></p><p>上述两个语句是可以在MySQL外部直接进行执行的，不用进入到mysql里</p><p>数据库唯一主键</p><p>缺点：无法使用change buffer，InnoDB为了进行唯一性检查，必须有一次磁盘IO读页</p><p>业务状态校验</p><p>业务上根据业务ID的唯一性和业务处理的结果去做判断，但是这部分判断的逻辑需要考虑原子性。否则会因为并发问题导致幂等失效。解决途径（一）加锁，根据当前的服务环境选择单机或分布式锁。（二）采用现成方案Tomato，通过滑动窗口或者固定窗口拦截控制时间内的请求</p><p>数据库乐观锁实现幂等性</p><p>缺点：操作业务前，需要先查询出当前的version版本。会增加操作</p><p>防重 Token 令牌实现幂等性</p><p>缺点：</p><p>产生过多额外请求</p><p>先删除token，如果业务处理出现异常但token已经删除掉了，再来请求会被认定为重复请求</p><p>后删除token，如果删除redis中的token失败了，再来请求不会拦截，发生了重复请求</p><p>下游传递唯一序列号实现幂等性</p><p>缺点：无法控制下游唯一序列号的生成规则，如果序列号由时间戳生成，那么无法拦截类似重复点击这种情况下的重复请求</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/05/12-05/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>hive第四天</title>
      <link>http://zihang.fun/2022/12/02/12-02/</link>
      <guid>http://zihang.fun/2022/12/02/12-02/</guid>
      <pubDate>Fri, 02 Dec 2022 00:59:25 GMT</pubDate>
      
        
        
      <description>&lt;p&gt;维度组合分析 ：&lt;/p&gt;
&lt;p&gt;sql 关键字 ： grouping sets&lt;/p&gt;
&lt;p&gt;例子  ：&lt;/p&gt;
&lt;figure class=&quot;highlight n1ql&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;l</description>
        
      
      
      
      <content:encoded><![CDATA[<p>维度组合分析 ：</p><p>sql 关键字 ： grouping sets</p><p>例子  ：</p><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">create</span> table user_shop (<br>user_id <span class="hljs-keyword">String</span>,<br>shop_name <span class="hljs-keyword">String</span>,<br>channe <span class="hljs-keyword">String</span>,<br>os <span class="hljs-keyword">String</span><br>)<br>row format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span><br></code></pre></td></tr></table></figure><p>一般我们进行维度计算的时候，我们可以通过group by 的方式进行</p><p>但是假如我们每次都要处理一个维度，那么我们难道要写很多个sql语句吗</p><p>这明显是不行的</p><p>那么我们如何解决呢</p><p>通过grouping sets 就可以解决了</p><p>代码如下  ：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">SELECT</span> empid,custid,<br>       sum(qty) <span class="hljs-keyword">as</span> sumqty<br><span class="hljs-keyword">FROM</span> Orders<br><span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span><br>    <span class="hljs-keyword">GROUPING SETS</span><br>    (<br>        (empid,custid),<br>        (empid),(custid),<br>        ()<br>    );<br></code></pre></td></tr></table></figure><p>上面代码的意思就是 ：我要按照ｇｒｏｕｐ　ｂｙ　的方法　把empid,custid和empid和custid这几个维度都选出来，然后是上下在一起的　相当于用ｕｎｉｏｎ在一起</p><p>如果是这次选择的维度中未选择的维度，比如说　，我只选择了　维度empid　，那么custid列就会是空，但是这个比多次重复性写ｓｑｌ语句要好的多</p><h1 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h1><p>针对以下数据</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">+--------------+--------------------+<br>|<span class="hljs-string"> hanglie.ame  </span>|<span class="hljs-string"> hanglie.teresting  </span>|<br>+--------------+--------------------+<br>|<span class="hljs-string"> zuan         </span>|<span class="hljs-string"> 王者荣耀               </span>|<br>|<span class="hljs-string"> zuan         </span>|<span class="hljs-string"> 吃饭                 </span>|<br>|<span class="hljs-string"> zuan         </span>|<span class="hljs-string"> rap                </span>|<br>|<span class="hljs-string"> zuan         </span>|<span class="hljs-string"> 唱歌                 </span>|<br>|<span class="hljs-string"> chaofeng     </span>|<span class="hljs-string"> 王者荣耀               </span>|<br>|<span class="hljs-string"> chaofeng     </span>|<span class="hljs-string"> 睡觉                 </span>|<br>|<span class="hljs-string"> chaofeng     </span>|<span class="hljs-string"> 方亚                 </span>|<br>+--------------+--------------------+<br><br></code></pre></td></tr></table></figure><p>我们可以把后面散开的数据转化成一个array存起来</p><p>通过 collect_list 函数转化成array 而且可以通过 concat_ws函数设置每个参数之间的分隔符</p><p>如下</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">select</span> <br>ame,<br>collect_list(teresting) <span class="hljs-keyword">as</span> interesting,<br>concat_ws(<span class="hljs-string">&#x27;:&#x27;</span> , collect_list(teresting)) <span class="hljs-keyword">as</span> newin<br><span class="hljs-keyword">from</span> hanglie<br><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> ame<br></code></pre></td></tr></table></figure><p>结果如下：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">+<span class="hljs-params">-----------</span>+<span class="hljs-params">---------------------------</span>+<span class="hljs-params">-----------------</span>+<br>|    ame    |        interesting        |      newin      |<br>+<span class="hljs-params">-----------</span>+<span class="hljs-params">---------------------------</span>+<span class="hljs-params">-----------------</span>+<br>| chaofeng  | [<span class="hljs-string">&quot;王者荣耀&quot;</span>,<span class="hljs-string">&quot;睡觉&quot;</span>,<span class="hljs-string">&quot;方亚&quot;</span>]        | 王者荣耀:睡觉:方亚      |<br>| zuan      | [<span class="hljs-string">&quot;王者荣耀&quot;</span>,<span class="hljs-string">&quot;吃饭&quot;</span>,<span class="hljs-string">&quot;rap&quot;</span>,<span class="hljs-string">&quot;唱歌&quot;</span>]  | 王者荣耀:吃饭<span class="hljs-function">:rap</span>:唱歌  |<br>+<span class="hljs-params">-----------</span>+<span class="hljs-params">---------------------------</span>+<span class="hljs-params">-----------------</span>+<br><br></code></pre></td></tr></table></figure><h2 id="concat"><a href="#concat" class="headerlink" title="concat"></a>concat</h2><p>concat是可以更改数组分隔符的一个函数</p><p>例子 ：</p><p>拼接：</p><ul><li>concat  &#x3D;》 字符串拼接</li><li>select concat(“zuan”,”|”,”zihang”,”|”,”chaofeng”)</li><li>结果是 ：zuan|zihang|chaofeng</li><li>concat_ws(string SEP, string A, string B…) &#x3D;》 字符串拼接</li><li>select concat_ws(“|”,”zuan”,”zihang”,”chaofeng”)</li><li>可变参数 &#x3D;》 array【String】</li><li>select concat_ws(“|”,split(“a,a,a”,’,’)</li><li>select  split(“a,a,a”,’,’)  ： 这个就是切割字符串</li></ul><p>所有类型的可以转换成字符串</p><p>字符串有好处也有坏处</p><p>因为无法排序</p><p>但是经过hive优化，字符串是可以进行四则运算的</p><p>字符串排序： 按照字典序进行排序的 a-z</p><h2 id="BY"><a href="#BY" class="headerlink" title="BY"></a>BY</h2><p>四个by</p><h3 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h3><p>全局排序 ，且reduce只有一个</p><p>order by会对输入进行全局排序，因此只有一个Reducer（多个Reducer无法保证全局有序），然而只有一个Reducer会导致计算效率非常低，使用较少。事实上，在生产环境中，order by 很容易造成OOM。</p><p>如下  ：</p><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-keyword">select</span>  *  <span class="hljs-keyword">from</span> emp <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> empno;<br></code></pre></td></tr></table></figure><p>执行上述语句要开启个开关才可以</p><p>hive.mapred.mode &#x3D;&gt;some risky queries are not allowed to run 【关闭】</p><p>如果用order by 推荐和 limit搭配</p><h3 id="sort-by"><a href="#sort-by" class="headerlink" title="sort by"></a>sort by</h3><p>分区排序 ： 不能保证 全局有序</p><p>sort by不是全局排序，它会在数据进入Reducer之前完成排序。因此如果使用sort by进行排序，并且设置mapreduce.job.reduces多于一个，则sort by只会保证每个reducer的输出有序，不能保证全局有序。但是可以对最后的结果进行归并排序实现全局排序。</p><p>假如你的reduce task 个数 是 1 则它和order by 是一样的</p><p>调制reduce task 个数 ：</p><ul><li>mapred.reduce.tasks</li><li>set  mapred.reduce.tasks;</li></ul><h3 id="Distribute-By"><a href="#Distribute-By" class="headerlink" title="Distribute  By"></a>Distribute  By</h3><p>数据开发的时候会用到</p><p>distribute by的作用是控制map端如何拆分数据给reduce端。hive会根据distribute by后面的字段，对reduce的个数进行分发，默认采用的是hash算法。sort by保证每个reduce内有序，因此distribute by经常和sort by配合使用。生产环境中 distribute by + sort by用的多。</p><p>数据 如下 ：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">2020,1w<br>2020,2w<br>2020,1w<br>2020,0.5w<br>2021,10w<br>2021,20w<br>2021,19w<br>2021,1.5w<br>2022,1.3w<br>2022,2w<br>2022,1w<br>2022,0.5w<br><br>+-----------------------+--------------------------+<br>|<span class="hljs-string"> hive_distribute.year  </span>|<span class="hljs-string"> hive_distribute.earning  </span>|<br>+-----------------------+--------------------------+<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 2w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 0.5w                     </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 10w                      </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 20w                      </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 19w                      </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 1.5w                     </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 1.3w                     </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 2w                       </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 0.5w                     </span>|<br>+-----------------------+--------------------------+<br><br></code></pre></td></tr></table></figure><p>建表 ：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-built_in">create</span> <span class="hljs-built_in">table</span> hive_distribute(<br>year <span class="hljs-built_in">string</span>,<br>earning <span class="hljs-built_in">string</span><br>)<br></code></pre></td></tr></table></figure><p>执行语句 ：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">select  <span class="hljs-symbol">*</span>  from hive_distribute distribute by year   sort by earning;<br><br>+-----------------------+--------------------------+<br>|<span class="hljs-string"> hive_distribute.year  </span>|<span class="hljs-string"> hive_distribute.earning  </span>|<br>+-----------------------+--------------------------+<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 0.5w                     </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 0.5w                     </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 1.3w                     </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 1.5w                     </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 10w                      </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 19w                      </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 1w                       </span>|<br>|<span class="hljs-string"> 2021                  </span>|<span class="hljs-string"> 20w                      </span>|<br>|<span class="hljs-string"> 2022                  </span>|<span class="hljs-string"> 2w                       </span>|<br>|<span class="hljs-string"> 2020                  </span>|<span class="hljs-string"> 2w                       </span>|<br>+-----------------------+--------------------------+<br><br><br></code></pre></td></tr></table></figure><h2 id="Cluster-By"><a href="#Cluster-By" class="headerlink" title="Cluster By"></a>Cluster By</h2><p>ClusterByis a short-cut for both DistributeByand Sort By.</p><p>distributeby year   sort by year  《&#x3D;》 ClusterBy year 正确</p><p>当distribute by 和 sort by字段相同时，可以使用cluster by。<br>cluster by除了具有distribute by的功能外还兼具sort by的排序功能。但是排序只能是默认的升序，无法指定排序规则。</p><h3 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h3><p>hdfs上的文件 ，本地文件会找不到文件，一般只能识别hdfs上的</p><p>分桶表是对列值取哈希值的方式，将不同数据放到不同文件中存储。 对于 hive 中每一个表、分区都可以进一步进行分桶。 由列的哈希值除以桶的个数来决定每条数据划分在哪个桶中。</p><p>要先开启分桶支持</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-built_in">set</span> hive.enforce.<span class="hljs-attribute">bucketing</span>=<span class="hljs-literal">true</span>;<br></code></pre></td></tr></table></figure><p>分桶表的創建</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-meta">[</span>CLUSTERED <span class="hljs-keyword">BY</span> (col_name, col_name, <span class="hljs-params">...</span>) <br> <span class="hljs-keyword">INTO</span> num_buckets BUCKETS<span class="hljs-meta">]</span><br></code></pre></td></tr></table></figure><p>数据</p><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-number">1</span>,<span class="hljs-symbol">name1</span><br><span class="hljs-number">2</span>,<span class="hljs-symbol">name2</span><br><span class="hljs-number">3</span>,<span class="hljs-symbol">name3</span><br><span class="hljs-number">4</span>,<span class="hljs-symbol">name4</span><br><span class="hljs-number">5</span>,<span class="hljs-symbol">name5</span><br><span class="hljs-number">6</span>,<span class="hljs-symbol">name6</span><br><span class="hljs-number">7</span>,<span class="hljs-symbol">name7</span><br><span class="hljs-number">8</span>,<span class="hljs-symbol">name8</span><br></code></pre></td></tr></table></figure><p>创建表</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> hive_bucket(<br>id <span class="hljs-type">int</span>,<br><span class="hljs-type">name</span> string <br>)<br>clustered <span class="hljs-keyword">by</span> (id) <span class="hljs-keyword">into</span> <span class="hljs-number">4</span> buckets<br><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> &quot;,&quot;;<br></code></pre></td></tr></table></figure><p>查询桶中数据</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">select</span> id,<span class="hljs-type">name</span> <span class="hljs-keyword">from</span> hive_bucket <span class="hljs-keyword">tablesample</span>(bucket <span class="hljs-number">4</span> <span class="hljs-keyword">out</span> <span class="hljs-keyword">of</span> <span class="hljs-number">4</span> <span class="hljs-keyword">on</span> <span class="hljs-type">name</span>); //bucket后面的数字就是我们要查看的桶的编号 <span class="hljs-keyword">out</span> <span class="hljs-keyword">of</span> 后面的是总数 ，<span class="hljs-keyword">on</span> 后面的是我们分桶的属性<br></code></pre></td></tr></table></figure><p>mapreduce:</p><p>hash % reducetask个数</p><p>文件存储格式</p><ul><li>行式存储  ：<ul><li>里面的列 掺杂很多数据类型</li><li>一行内容所有的列都在一个 block里面</li><li>行式存储加载所 是把所有的列都查询出来 再过滤出 用户需要的列</li><li>如果用户 仅仅查几个字段  &#x3D;》 磁盘io 开销比较大</li><li>textfile 文本文件</li><li>SequenceFile 文本文件</li></ul></li><li>列式存储 ：<ul><li>按照列进行存储</li><li>前提： 企业 table 字段 几十个 到几百个</li><li>RCFile  &#x3D;》 行 &#x3D;》 列</li><li>ORC Files + Parquet</li><li>查询几个列</li><li>加载表中所有字段</li></ul></li><li>列式存储文件 数据量 比 行式存储的数据量少 【前提 都采用压缩】</li></ul><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-built_in">create</span> table hive_distribute_col(<br>year <span class="hljs-keyword">string</span>,<br>earning <span class="hljs-keyword">string</span><br>)<br>row <span class="hljs-built_in">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span><br>stored <span class="hljs-keyword">as</span> orc;<span class="hljs-comment"> // 这个就是存储形式</span><br></code></pre></td></tr></table></figure><h2 id="hive-中文件存储格式-vs-压缩"><a href="#hive-中文件存储格式-vs-压缩" class="headerlink" title="hive 中文件存储格式 vs 压缩"></a>hive 中文件存储格式 vs 压缩</h2><p>压缩格式 ：</p><p>Hive支持的压缩格式有bzip2、gzip、deflate、snappy、lzo等。Hive依赖Hadoop的压缩方法，所以Hadoop版本越高支持的压缩方法越多，可以在$HADOOP_HOME&#x2F;conf&#x2F;core-site.xml中进行配置：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs stylus">&lt;property&gt;  <br>        &lt;name&gt;io<span class="hljs-selector-class">.compression</span>.codecs&lt;/name&gt;  <br>        &lt;value&gt;org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.compress</span><span class="hljs-selector-class">.GzipCodec</span>,org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.compress</span><span class="hljs-selector-class">.DefaultCodec</span>,com<span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.compression</span><span class="hljs-selector-class">.lzo</span><span class="hljs-selector-class">.LzoCodec</span>,com<span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.compression</span><span class="hljs-selector-class">.lzo</span><span class="hljs-selector-class">.LzopCodec</span>,org<span class="hljs-selector-class">.apache</span><span class="hljs-selector-class">.hadoop</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.compress</span><span class="hljs-selector-class">.BZip2Codec</span><br>        &lt;/value&gt;  <br>&lt;/property&gt;  <br><br></code></pre></td></tr></table></figure><p>常见的压缩格式 ：</p><table><thead><tr><th>压缩格式</th><th>算法实现</th><th>压缩比</th><th>效率</th><th>可切分</th><th>内置</th><th>扩展名</th><th>Native</th><th>Java</th><th>描述</th></tr></thead><tbody><tr><td>bzip2</td><td>bzip2</td><td>最高</td><td>慢</td><td>yes</td><td>Y</td><td>.bz2</td><td>yes</td><td>yes</td><td>压缩率最高，一般是源文件的30%左右 ：<br />压缩或者解压效率最慢</td></tr><tr><td>deflate</td><td>DEFLATE</td><td>高</td><td>慢</td><td>no</td><td>Y</td><td>.deflate</td><td>no</td><td>yes</td><td>标准的压缩格式</td></tr><tr><td>gzip</td><td>DEFLATE</td><td>高</td><td>慢</td><td>no</td><td>Y</td><td>.gz</td><td>no</td><td>yes</td><td>相比deflate增加文件头，尾，<br />压缩率比较高，压缩或者解压的效率比较慢</td></tr><tr><td>zlib</td><td>DEFLATE</td><td>高</td><td>慢</td><td>no</td><td>Y</td><td>.zl</td><td>yes</td><td>no</td><td>相比deflate增加文件头，尾</td></tr><tr><td>lz4</td><td>lz4</td><td>最低</td><td>最快</td><td>no</td><td>Y</td><td>.zl4</td><td>yes</td><td>no</td><td>压缩率比较低，不过压缩和解压效率最快</td></tr><tr><td>lzo</td><td>lzo</td><td>较低</td><td>快</td><td>yes</td><td>N</td><td>.lzo_deflate</td><td>yes</td><td>no</td><td>压缩率比较低，不过压缩和解压效率最快</td></tr><tr><td>lzop</td><td>snappy</td><td>较低</td><td>快</td><td>yes</td><td>N</td><td>.lzo</td><td>yes</td><td>no</td><td>压缩率比较低，不过压缩和解压效率最</td></tr><tr><td>snappy</td><td>snappy</td><td>较低</td><td>快</td><td>yes</td><td>N</td><td>.snappy</td><td>yes</td><td>no</td><td>压缩率比较低，不过压缩和解压效率最</td></tr></tbody></table><p>其中压缩比bzip2 &gt; zlib &gt; gzip &gt; deflate &gt; snappy &gt; lzo &gt; lz4，在不同的测试场景中，会有差异，这仅仅是一个大概的排名情况。bzip2、zlib、gzip、deflate可以保证最小的压缩，但在运算中过于消耗时间。</p><p>从压缩性能上来看：lz4 &gt; lzo &gt; snappy &gt; deflate &gt; gzip &gt; bzip2，其中lz4、lzo、snappy压缩和解压缩速度快，压缩比低。</p><p>所以一般在生产环境中，经常会采用lz4、lzo、snappy压缩，以保证运算效率。</p><h2 id="Native-Libraries"><a href="#Native-Libraries" class="headerlink" title="Native Libraries"></a>Native Libraries</h2><p>Hadoop由Java语言开发，所以压缩算法大多由Java实现；但有些压缩算法并不适合Java进行实现，会提供本地库Native Libraries补充支持。Native Libraries除了自带bzip2, lz4, snappy, zlib压缩方法外，还可以自定义安装需要的功能库（snappy、lzo等）进行扩展。</p><p>而且使用本地库Native Libraries提供的压缩方式，性能上会有50%左右的提升。</p><p>使用命令可以查看native libraries的加载情况：<br><code>hadoop checknative -a</code></p><p>完成对Hive表的压缩，有两种方式：配置MapReduce压缩、开启Hive表压缩功能。因为Hive会将SQL作业转换为MapReduce任务，所以直接对MapReduce进行压缩配置，可以达到压缩目的；当然为了方便起见，Hive中的特定表支持压缩属性，自动完成压缩的功能。</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/02/12-02/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>hive第三天</title>
      <link>http://zihang.fun/2022/12/01/12-01/</link>
      <guid>http://zihang.fun/2022/12/01/12-01/</guid>
      <pubDate>Thu, 01 Dec 2022 01:47:23 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;内部和外部表和普通表和分区表&quot;&gt;&lt;a href=&quot;#内部和外部表和普通表和分区表&quot; class=&quot;headerlink&quot; title=&quot;内部和外部表和普通表和分区表&quot;&gt;&lt;/a&gt;内部和外部表和普通表和分区表&lt;/h1&gt;&lt;p&gt;分区表 ： 提升查询效率的表&lt;/p&gt;
&lt;p&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="内部和外部表和普通表和分区表"><a href="#内部和外部表和普通表和分区表" class="headerlink" title="内部和外部表和普通表和分区表"></a>内部和外部表和普通表和分区表</h1><p>分区表 ： 提升查询效率的表</p><p>关于hive的查询 ： 对于普通表 则是要先读取所有的数据然后进行筛选的 ， 但是对于分区表，则是把数据进行分区，如果要查询的话，则是针对符合的数据进行查询</p><p>往往用分区表进行查询，普通表数据量较少的时候可以用</p><p>创建分区表 ：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">order</span>(<br><br>orderid <span class="hljs-type">int</span>,<br><br>oredergg String<br><br>)<br><br>PARTITIONED <span class="hljs-keyword">BY</span> (dt String)<br><br><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span><br></code></pre></td></tr></table></figure><p>show partitions 表名 &#x2F;&#x2F;查看现在这个表的分区</p><p>修改分区  ：</p><p>删除分区  ：<code>alter table 表名 drop partition(分区列 = &#39;分区名&#39;)</code></p><p>创建分区 ： 在建表的时候创建</p><p>导入数据 ： load&#x2F;insert</p><ul><li>load : load data (local) inpath ‘’ (overwrite) into table 表名 partition (分区名称) ：数据列数如果对不上就会出现问题 : 加上overwrite则是把一个分区的数据给覆盖掉</li><li>insert : insert into table partition(分区) …</li><li>insert into 是追加的</li><li>如果不要追加则要进行覆盖 insert 后面的 into 变成 overwrite</li></ul><h2 id="使用一个sql让所有数据落到对应的分区里"><a href="#使用一个sql让所有数据落到对应的分区里" class="headerlink" title="使用一个sql让所有数据落到对应的分区里"></a>使用一个sql让所有数据落到对应的分区里</h2><p>动态分区：相当于我们要进行分区的字段是我们的数据的字段，就可以直接用那个字段当我们的分区但是要打开一个开关</p><p><code>set hive.exec.dynamic.partition.mode=nonstrict;</code></p><p>静态分区：就是自己制定好分区的标题的</p><p>离线任务 ： 业务周期性 T+1</p><p>就是延迟一天处理</p><p>默认底层创建的是内部表</p><p>内部表 ： 受hive管控的 ： 如果有删表的操作，那么会清理干净，所有数据都会被删除</p><p>外部表 ： 如果被删除的情况下，只是hdfs上指向metastore的索引被删除了，源数据不会被删除 ，而且我们还可通过建表的方式让他们的索引再次关联上</p><p>创建外部表 ：</p><p>相互转换 ：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sql">外部转内部<br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> 外部表名字 <span class="hljs-keyword">SET</span> TBLPROPERTIES (&quot;EXTERNAL&quot; <span class="hljs-operator">=</span> &quot;true&quot;);<br><br>内部转外部<br><span class="hljs-keyword">ALTER</span> <span class="hljs-keyword">TABLE</span> 外部表名字 <span class="hljs-keyword">SET</span> TBLPROPERTIES (&quot;EXTERNAL&quot; <span class="hljs-operator">=</span> &quot;false&quot;);<br>但是这上述的<span class="hljs-keyword">EXTERNAL</span> 是不能小写的会造成失效的问题<br></code></pre></td></tr></table></figure><h1 id="复杂的数据类型"><a href="#复杂的数据类型" class="headerlink" title="复杂的数据类型"></a>复杂的数据类型</h1><p>中小企业用的不多，，大企业用的多</p><p>会建表 ，会查询</p><p>maps: <code>MAP&lt;primitive_type, data_type&gt; </code></p><p>数据如下 ：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clean"><span class="hljs-number">1</span>,zhangsan,father:xiaoming#mother:xiaohuang#brother:xiaoxu,<span class="hljs-number">28</span><br><span class="hljs-number">2</span>,lisi,father:mayun#mother:huangyi#brother:guanyu,<span class="hljs-number">22</span><br><span class="hljs-number">3</span>,wangwu,father:wangjianlin#mother:ruhua#sister:jingtian,<span class="hljs-number">29</span><br><span class="hljs-number">4</span>,mayun,father:mayongzhen#mother:angelababy,<span class="hljs-number">26</span><br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> hive_map(<br>id <span class="hljs-type">int</span>  <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;用户id&#x27;</span>,<br><span class="hljs-type">name</span> string <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;用户名字&#x27;</span>,<br>relation map&lt;string,string&gt; <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;家庭成员&#x27;</span>,<br>age <span class="hljs-type">int</span> <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;年龄&#x27;</span><br>)<br><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span>  delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span><br>collection items terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;#&#x27;</span><br>map keys terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;:&#x27;</span>;<br></code></pre></td></tr></table></figure><p>arrays:  <code>ARRAY&lt;data_type&gt;</code></p><p>数据</p><p><code>zihan   beijing,shanghai,chengdu,dalian</code></p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> hive_array(<br><span class="hljs-type">name</span> String,<br>locations <span class="hljs-keyword">array</span>&lt;String&gt;<br>)<br><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span><br>collection items terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span>;<br></code></pre></td></tr></table></figure><p>structs:<code>STRUCT&lt;col_name : data_type [COMMENT col_comment], ...&gt;</code></p><p>数据</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">192.168.1.1</span>#zhangsan:<span class="hljs-number">40</span><br><span class="hljs-number">192.168.1.2</span>#lisi:<span class="hljs-number">50</span><br><span class="hljs-number">192.168.1.3</span>#wangwu:<span class="hljs-number">60</span><br><span class="hljs-number">192.168.1.4</span>#zhaoliu:<span class="hljs-number">70</span><br></code></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> hive_struct(<br>ip string,<br>userinfo STRUCT&lt;<span class="hljs-type">name</span>:string,age:<span class="hljs-type">int</span>&gt;<br>)<br><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span>  delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;#&#x27;</span><br>collection items terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;:&#x27;</span>;<br></code></pre></td></tr></table></figure><h1 id="数据形式的不同使用方法"><a href="#数据形式的不同使用方法" class="headerlink" title="数据形式的不同使用方法"></a>数据形式的不同使用方法</h1><h2 id="array"><a href="#array" class="headerlink" title="array"></a>array</h2><p>案例分析：</p><p>1.查询每个用户第一个工作地点？</p><p>select  name ,locations[0] as first_loc_work from  hive_array;</p><p>2.查询每个人 工作地点的数量</p><p>select  name , size(locations) from  hive_array ;</p><p>3.查询在shanghai 工作的有哪些人</p><p>select  * from hive_array  where array_contains(locations,’shanghai’);</p><h3 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h3><p>思路是先把一个array的元素炸开，然后通过显示出来</p><p>显示手段 ： LATERAL VIEW（侧写视图）</p><ul><li><p>LATERAL VIEW udtf(expression) tableAlias AS columnAlias</p></li><li><p>udtf : 一进多出</p></li><li><p>FROM baseTable (lateralView)*</p></li><li><p>最终代码 ：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> name,location<br><span class="hljs-keyword">from</span> hive_array <span class="hljs-keyword">lateral</span> <span class="hljs-keyword">view</span> explode(locations) loc_table <span class="hljs-keyword">as</span> location;<br></code></pre></td></tr></table></figure></li></ul><h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><p>需求： 1.查询表中每个人的father的名字</p><p>select id,name,age,relation[‘father’] as father from hive_map;</p><p>2.查询表中 每个人的家庭成员   keys</p><p>select id,name,age,map_keys(relation) as members from hive_map;</p><p>3.查询表中 每个人的家庭成员的名字 values</p><p>select id,name,age,map_values(relation) as members from hive_map;</p><p>4.查询表中 有brother的人以及brother的名字</p><p>select<br> id,name,age,relation[‘brother’] as brother<br>from hive_map<br>where<br>relation[‘brother’] is not null;</p><p>或者可以</p><p>select<br> id,name,age,relation[‘brother’] as brother<br>from hive_map<br>where<br>array_contains(map_keys(relation), ‘brother’);</p><p>&#x2F;&#x2F; map_key()函数的意思是可以把这个列的map的key当作array取出来</p><h2 id="structs"><a href="#structs" class="headerlink" title="structs"></a>structs</h2><p>select ip,userinfo.name as name ,userinfo.age as age from hive_struct;</p><h2 id="开窗函数-："><a href="#开窗函数-：" class="headerlink" title="开窗函数 ："></a>开窗函数 ：</h2><ul><li>分析函数：对开窗函数的分析的函数<ul><li>rank : 使用方法 rank()over(partition by xx order by yy) as rk  : 如果有重复的数据，会丢失排名</li><li>dense_rank :使用方法同上 ： 如果有重复数据 ，则不会丢失排名 ：</li><li>row_number:同上 ： 排名相同且不会重复 ， 就是会顺序往下 ：</li></ul></li></ul><p>上述的常用手段 ： 求topn的排名</p><p>比如要求top3 的</p><p>作业 ：</p><p>统计每个店铺的uv</p><p>统计top3的用户记录</p><p>pv ： 页面的浏览量</p><p>uv ： 访客的次数</p>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/12/01/12-01/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>hive第二天</title>
      <link>http://zihang.fun/2022/11/30/11-30/</link>
      <guid>http://zihang.fun/2022/11/30/11-30/</guid>
      <pubDate>Wed, 30 Nov 2022 01:57:50 GMT</pubDate>
      
        
        
      <description>&lt;h1 id=&quot;关于hive里的数据类型&quot;&gt;&lt;a href=&quot;#关于hive里的数据类型&quot; class=&quot;headerlink&quot; title=&quot;关于hive里的数据类型&quot;&gt;&lt;/a&gt;关于hive里的数据类型&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;整数&lt;ul&gt;
&lt;li&gt;int&lt;/li&gt;
&lt;li&gt;</description>
        
      
      
      
      <content:encoded><![CDATA[<h1 id="关于hive里的数据类型"><a href="#关于hive里的数据类型" class="headerlink" title="关于hive里的数据类型"></a>关于hive里的数据类型</h1><ul><li>整数<ul><li>int</li><li>bigint &#x3D;&#x3D;long</li></ul></li><li>小数 ：<ul><li>float</li><li>double</li><li>Decimal</li></ul></li><li>字符串：<ul><li>String (建议统一用String)</li><li>varchar</li><li>char</li></ul></li><li>时间：<ul><li>时间日期 DATE 格式：YYYY-MM-DD</li><li>时间戳：TIMESTAMP YYYY-MM-DD HH:MM:SS</li></ul></li></ul><h1 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h1><p>CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name<br>  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], … [constraint_specification])]<br>  [COMMENT table_comment]<br>  [PARTITIONED BY (col_name data_type [COMMENT col_comment], …)]<br>  [CLUSTERED BY (col_name, col_name, …) [SORTED BY (col_name [ASC|DESC], …)] INTO num_buckets BUCKETS]<br>  [<br>   [ROW FORMAT row_format]<br>   [STORED AS file_format]<br>     | STORED BY ‘storage.handler.class.name’ [WITH SERDEPROPERTIES (…)]  – (Note: Available in Hive 0.6.0 and later)<br>  ]</p><p>数据字段名字 字段类型</p><p>例如</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> mytest(<br>id String <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;用户id&#x27;</span>,<br><span class="hljs-type">name</span> string,<br>age <span class="hljs-type">bigint</span><br>) <span class="hljs-keyword">comment</span> <span class="hljs-string">&#x27;第一个表&#x27;</span><br><span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span> //指定分隔符<br>STORED <span class="hljs-keyword">as</span> TEXTFILE; // 存储形式<br><br>或者<br><br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> emp2 <span class="hljs-keyword">like</span> emp;<br>复制表结构<br><br>或者<br></code></pre></td></tr></table></figure><h2 id="为什么要分隔符"><a href="#为什么要分隔符" class="headerlink" title="为什么要分隔符"></a>为什么要分隔符</h2><p>因为我们的元数据都在hdfs上，对于hdfs上的数据可以通过分隔符进行自动导入到hive里，比如上述是，分割的，然后我hdfs上有如下数据</p><p>1，zihan,11</p><p>2,zhangsan,23</p><p>3,liu,33</p><p>就会自动按照每一行进行insert</p><p>导入数据 ： load data local inpath ‘本地的绝对路径’ into table 表名</p><p>清空表的操作 ： truncate table 表名</p><h1 id="删除库"><a href="#删除库" class="headerlink" title="删除库"></a>删除库</h1><p>DROP (DATABASE|SCHEMA) [IF EXISTS] database_name [RESTRICT|CASCADE];</p><p>DROP DATABASE bigdata_hive4;</p><p>DROP DATABASE bigdata_hive2 CASCADE; &#x3D;&gt;删库跑路的操作</p><p>CASCADE : 代表联合删除 ，一般删除的时候如果里面有表，会造成无法删除的问题，但是联合删除会直接删除掉</p><h1 id="DMl"><a href="#DMl" class="headerlink" title="DMl"></a>DMl</h1><h2 id="load-："><a href="#load-：" class="headerlink" title="load ："></a>load ：</h2><ul><li>加载本地数据</li><li>加载hdfs上的数据</li></ul><p>LOAD原本是追加，不是覆盖 ， 但是可以通过 加上 overwrite 关键字 进行 覆盖操作</p><h2 id="覆盖例子"><a href="#覆盖例子" class="headerlink" title="覆盖例子"></a>覆盖例子</h2><p>load data local inpath ‘&#x2F;home&#x2F;hadoop&#x2F;tmp&#x2F;emp.txt’ OVERWRITE INTO TABLE emp;</p><h2 id="上传"><a href="#上传" class="headerlink" title="上传"></a>上传</h2><p>本地：load data inpath ‘本地路径’ into table 表名</p><p>hdfs ： load data inpath ‘hdfs上的路径’ into table 表名</p><p>上述的hdfs上的相当于把其路径里的文件移动到table 表名的下面 并且改名，且关联到metastore</p><p>但是我们的hdfs mv 是不会关联到metastore的</p><p>在hive 里 update 和 delete 不要做 &#x3D;》 因为效率低下</p><p>把所有的update和delete都转化成insert和overwrite</p><h2 id="插入语句-："><a href="#插入语句-：" class="headerlink" title="插入语句 ："></a>插入语句 ：</h2><p>Inserting data into Hive Tables from queries</p><p>insert into|OVERWRITE table tablename selectQury</p><p>2.Inserting values into tables from SQL 【不推荐使用】<br>INSERT INTO TABLE tablename<br>VALUES values_row [, values_row …]<br>1.每导入一条数据 就会触发一次 mapreduce job  效率太低</p><p>emp2：<br>    insert into table emp2<br>    select *  from emp;<br>insert overwrite table emp2<br>select *  from emp where deptno&#x3D;10;</p><h2 id="关于hive里的一些函数以及使用"><a href="#关于hive里的一些函数以及使用" class="headerlink" title="关于hive里的一些函数以及使用"></a>关于hive里的一些函数以及使用</h2><h3 id="1-where-过滤条件"><a href="#1-where-过滤条件" class="headerlink" title="1.where 过滤条件"></a>1.where 过滤条件</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">where_condition<br> &lt;<br> &gt;<br> =<br> &lt;&gt;  !=<br> <span class="hljs-keyword">and</span><br><span class="hljs-keyword"></span> <span class="hljs-keyword">or</span><br><span class="hljs-keyword"></span> in<br> not in<br> <span class="hljs-keyword">between </span> <span class="hljs-keyword">and</span><br><span class="hljs-keyword"></span> is<br> is not<br></code></pre></td></tr></table></figure><h3 id="需求：查询表中-deptno-20-10"><a href="#需求：查询表中-deptno-20-10" class="headerlink" title="需求：查询表中 deptno 20 10"></a>需求：查询表中 deptno 20 10</h3><figure class="highlight csharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs csharp"><span class="hljs-keyword">select</span><br>*<br><span class="hljs-keyword">from</span> emp<br><span class="hljs-keyword">where</span> deptno=<span class="hljs-number">20</span> <span class="hljs-keyword">or</span> deptno =<span class="hljs-number">10</span>;<br><br><span class="hljs-keyword">select</span><br>*<br><span class="hljs-function"><span class="hljs-keyword">from</span> emp</span><br><span class="hljs-function"><span class="hljs-keyword">where</span> deptno <span class="hljs-title">in</span> (<span class="hljs-params"><span class="hljs-number">10</span>,<span class="hljs-number">20</span></span>)</span>;<br><br><span class="hljs-keyword">select</span><br>*<br><span class="hljs-keyword">from</span> emp<br><span class="hljs-keyword">where</span> deptno &lt;&gt; <span class="hljs-number">20</span>;<br><span class="hljs-keyword">select</span><br>*<br><span class="hljs-keyword">from</span> emp<br><span class="hljs-keyword">where</span> deptno != <span class="hljs-number">20</span>;<br></code></pre></td></tr></table></figure><h3 id="2-order-by-排序语法"><a href="#2-order-by-排序语法" class="headerlink" title="2.order by  排序语法"></a>2.order by  排序语法</h3><figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs axapta"><span class="hljs-number">1.</span>默认<span class="hljs-keyword">asc</span> 升序<br><span class="hljs-number">2.</span>降序 <span class="hljs-keyword">desc</span><br><br><span class="hljs-keyword">select</span><br>sal<br><span class="hljs-keyword">from</span> emp<br><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sal <span class="hljs-keyword">desc</span>;<br></code></pre></td></tr></table></figure><h3 id="3-like-语法-模糊匹配"><a href="#3-like-语法-模糊匹配" class="headerlink" title="3.like 语法 模糊匹配"></a>3.like 语法 模糊匹配</h3><figure class="highlight erlang-repl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs erlang-repl"><span class="hljs-number">1</span>._  占位符<br><span class="hljs-number">2</span>.<span class="hljs-comment">%  模糊</span><br>rlike regexp<br></code></pre></td></tr></table></figure><h3 id="4-合并表"><a href="#4-合并表" class="headerlink" title="4.合并表"></a>4.合并表</h3><figure class="highlight arcade"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arcade"><span class="hljs-built_in">union</span>  去重<br><br><span class="hljs-built_in">union</span> <span class="hljs-built_in">all</span>  不去重<br></code></pre></td></tr></table></figure><h3 id="例子："><a href="#例子：" class="headerlink" title="例子："></a>例子：</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> a(id <span class="hljs-type">int</span> ,<span class="hljs-type">name</span> string) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span>  delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span> ;<br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> b(id <span class="hljs-type">int</span> ,<span class="hljs-type">name</span> string) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span>  delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;,&#x27;</span> ;<br><br><span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath &quot;/home/hadoop/tmp/a.txt&quot; <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> a;<br><span class="hljs-keyword">load</span> data <span class="hljs-keyword">local</span> inpath &quot;/home/hadoop/tmp/b.txt&quot; <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> b;<br><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span> <span class="hljs-keyword">from</span> a<br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span> <span class="hljs-keyword">from</span> b;<br><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span> <span class="hljs-keyword">from</span> a<br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span> <span class="hljs-keyword">from</span> b<br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> &quot;lisi&quot; <span class="hljs-keyword">as</span> <span class="hljs-type">name</span> ;<br><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span>,&quot;1&quot; <span class="hljs-keyword">as</span> pk <span class="hljs-keyword">from</span> a<br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> <span class="hljs-type">name</span>,&quot;2&quot; <span class="hljs-keyword">as</span> pk <span class="hljs-keyword">from</span> b<br><span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><br><span class="hljs-keyword">select</span> &quot;lisi&quot; <span class="hljs-keyword">as</span> <span class="hljs-type">name</span>,&quot;3&quot; <span class="hljs-keyword">as</span> id ;<br></code></pre></td></tr></table></figure><p>思考： hive建表 默认column 分割符是什么？</p><h3 id="5-null-处理"><a href="#5-null-处理" class="headerlink" title="5.null 处理"></a>5.null 处理</h3><pre><code>1. 过滤    where xxx is not nullis null 作用一样 &lt;=&gt;2. etl 转换    ifnull  =&gt; hive里没有    coalesce =》    nvl  =》</code></pre><h3 id="补充："><a href="#补充：" class="headerlink" title="补充："></a>补充：</h3><pre><code>查看hive支持的function ：            y=f(x)    SHOW FUNCTIONS [LIKE &quot;`&lt;pattern&gt;`&quot;];    show functions like nvl;  =&gt; 判断 function hive 是否存在    desc function nvl; =》  查看某个函数具体使用</code></pre><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey">select<br><span class="hljs-built_in">empno,</span><br><span class="hljs-built_in">ename,</span><br><span class="hljs-built_in">job,</span><br><span class="hljs-built_in">mgr,</span><br><span class="hljs-built_in">hiredate,</span><br><span class="hljs-built_in">sal,</span><br>nvl(comm,<span class="hljs-number">0</span>) as comm_alias,<br>deptno<br>from emp <span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><h2 id="分组-聚合函数-join"><a href="#分组-聚合函数-join" class="headerlink" title="分组 聚合函数 join"></a>分组 聚合函数 join</h2><p>聚合函数 ：</p><ul><li>sum</li><li>max</li><li>min</li><li>avg</li><li>count</li></ul><h3 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h3><ul><li>和聚合函数一起使用</li><li>一个或者多个colum进行分组</li><li>字段必须select出现 和 group by 出现要一致</li></ul><h3 id="having-："><a href="#having-：" class="headerlink" title="having ："></a>having ：</h3><ul><li>在group by 后面使用</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs stylus">select job,<br><br><span class="hljs-function"><span class="hljs-title">sum</span><span class="hljs-params">(sal)</span></span> as sal_num,<br><br><span class="hljs-function"><span class="hljs-title">max</span><span class="hljs-params">(sal)</span></span>,<br><br><span class="hljs-function"><span class="hljs-title">min</span><span class="hljs-params">(sal)</span></span>,<br><br><span class="hljs-function"><span class="hljs-title">avg</span><span class="hljs-params">(sal)</span></span>,<br><br><span class="hljs-function"><span class="hljs-title">count</span><span class="hljs-params">(<span class="hljs-number">1</span>)</span></span> as cnt<br><br>from emp<br><br>group by job<br><br>having sal_num &gt; <span class="hljs-number">6000</span><br></code></pre></td></tr></table></figure><h3 id="join"><a href="#join" class="headerlink" title="join"></a>join</h3><p>找准关联字段</p><ul><li>inner join [join]</li><li>left join</li><li>right join</li><li>full join</li></ul><h3 id="需求：既要显示聚合前的数据，又要显示聚合后的数据？"><a href="#需求：既要显示聚合前的数据，又要显示聚合后的数据？" class="headerlink" title="需求：既要显示聚合前的数据，又要显示聚合后的数据？"></a>需求：既要显示聚合前的数据，又要显示聚合后的数据？</h3><p>函数  over([partition by xxx,…] [order by xxx,….])</p><p>over: 以谁进行开窗 table、<br>parition by : 以谁进行分组   table columns<br>order by : 以谁进行排序  table columns</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs subunit">数据： <br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-10</span>,1<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-11</span>,5<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-12</span>,7<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-13</span>,3<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-14</span>,2<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-15</span>,4<br>haige,2022<span class="hljs-string">-11</span><span class="hljs-string">-16</span>,4<br></code></pre></td></tr></table></figure><p>需求：<br>    统计累计问题 ，每个用户每天累计点外卖次数</p><p>[partition by xxx,…] [order by xxx,….]</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">select</span> <br><span class="hljs-type">name</span> ,<br>dt ,<br>cnt ,<br>sum(cnt) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> <span class="hljs-type">name</span>  <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> dt ) <span class="hljs-keyword">as</span> sum_cnt<br><span class="hljs-keyword">from</span> user_mt;<br></code></pre></td></tr></table></figure><h3 id="命令行更改"><a href="#命令行更改" class="headerlink" title="命令行更改"></a>命令行更改</h3><p>command line<br>    1.hive shell<br>    2.jdbc &#x3D;&gt; hiveServer2</p><pre><code>hive clinet:    1. hive shell    2. beeline shell jdbc   开启 hiveServer2 服务 thift</code></pre><p>在beeline中 <code>!connect jdbc:hive2://localhost:10000 hadoop</code></p><p>补充：<br>beeline &#x3D;&gt; 连接 hive  &#x3D;》 hdfs<br>对hdfs 做一个设置 代理设置：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs xml">core-site.xml:<br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="http://zihang.fun/categories/%E6%97%A5%E5%BF%97/">日志</category>
      
      
      
      <comments>http://zihang.fun/2022/11/30/11-30/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
