<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/%E6%A0%91%E5%8F%B6_sleaves%20(1).png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/%E6%A0%91%E5%8F%B6_sleaves.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-flash.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zihang.fun","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":15,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="只有努力不会辜负你">
<meta property="og:type" content="website">
<meta property="og:title" content="枫叶冢">
<meta property="og:url" content="http://zihang.fun/index.html">
<meta property="og:site_name" content="枫叶冢">
<meta property="og:description" content="只有努力不会辜负你">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="liu zihang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://zihang.fun/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>枫叶冢</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/rss2.xml" title="枫叶冢" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
    <a target="_blank" rel="noopener" href="https://github.com/han2044953296" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#fff; color:#151513; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">枫叶冢</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>日程表</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/11/03/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/11/03/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
          
          <i class="fa fa-thumb-tack"></i>
          <font color=7D26CD>置顶</font>
          <span class="post-meta-divider">|</span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-11-03 13:38:31" itemprop="dateCreated datePublished" datetime="2022-11-03T13:38:31+08:00">2022-11-03</time>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>372</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bash</span><br><span class="line">$ hexo <span class="keyword">new</span> <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/16/%E5%91%A8%E5%85%AD%E6%97%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/16/%E5%91%A8%E5%85%AD%E6%97%A5/" class="post-title-link" itemprop="url">周六周日要补的</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-12-16 14:39:31 / 修改时间：16:36:45" itemprop="dateCreated datePublished" datetime="2022-12-16T14:39:31+08:00">2022-12-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BB%BB%E5%8A%A1/" itemprop="url" rel="index"><span itemprop="name">任务</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>107</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Prometheus框架监控zk"><a href="#Prometheus框架监控zk" class="headerlink" title="Prometheus框架监控zk"></a>Prometheus框架监控zk</h1><h1 id="datax"><a href="#datax" class="headerlink" title="datax"></a>datax</h1><h1 id="flume的fileSink"><a href="#flume的fileSink" class="headerlink" title="flume的fileSink"></a>flume的fileSink</h1><h2 id="kafka-custome-api"><a href="#kafka-custome-api" class="headerlink" title="kafka custome api"></a>kafka custome api</h2><h2 id="flume-gt-kafka-gt-消费"><a href="#flume-gt-kafka-gt-消费" class="headerlink" title="flume-&gt; kafka -&gt; 消费"></a>flume-&gt; kafka -&gt; 消费</h2><h2 id="kafka-gt-flume-gt-hdfs-gt-logger"><a href="#kafka-gt-flume-gt-hdfs-gt-logger" class="headerlink" title="kafka -&gt; flume -&gt; hdfs -&gt;logger"></a>kafka -&gt; flume -&gt; hdfs -&gt;logger</h2>
      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/16/12-16/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/16/12-16/" class="post-title-link" itemprop="url">kafka</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-12-16 08:44:05 / 修改时间：16:42:13" itemprop="dateCreated datePublished" datetime="2022-12-16T08:44:05+08:00">2022-12-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%BF%97/" itemprop="url" rel="index"><span itemprop="name">日志</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>17k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>16 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <p>MQ:消息中间件</p>
<ul>
<li>java -》 rabbitMq kafka</li>
<li>大数据 -》 kafka，pular ， solar</li>
</ul>
<h1 id="kafka："><a href="#kafka：" class="headerlink" title="kafka："></a>kafka：</h1><ul>
<li>在cdh平台叫cdk</li>
</ul>
<p>官网：kafka.apache.org</p>
<p>他是一个流式的分布式平台，构建实时的数据通道，流式数据分析，流式的app</p>
<p>实时处理&#x2F;流式处理</p>
<p>离线处理&#x2F;批处理</p>
<p>消息中间件：</p>
<ul>
<li>消息：event-》事件-》数据</li>
<li>数据存储的地方：中间件</li>
</ul>
<p>kafka的特性</p>
<ul>
<li>高吞吐量</li>
<li>可扩展性：支持分布式</li>
<li>永久性存储 ：有数据过期时间</li>
<li>高可用</li>
</ul>
<p>kafka的特点：</p>
<ul>
<li>读写（发布和订阅）</li>
<li>存储流式的数据</li>
<li>可以进行数据的处理<ul>
<li>正常的kafka处理，是在它后面接一个实时处理的框架 spark&#x2F;fink</li>
<li>kafkaStreaming ：是kafka自带的专门处理数据的功能（性能：以及数据的丢包什么的差距会比较大）</li>
</ul>
</li>
</ul>
<p>部署：kafka的版本要选择</p>
<ul>
<li>apache</li>
<li>cdk</li>
</ul>
<p>一般选择稳定版，最新版bug多</p>
<p>还可以根据后面的框架选择 ：根据sparkStreaming 来选择kafka的版本 ： spark对kafka的最低的版本是0.10.0 （目前3.x的spark）</p>
<p>kafka：</p>
<ul>
<li>0.10之后都可以</li>
</ul>
<p>kafka用的是scala写的</p>
<p>kafka2.8版本bug多，因为2.8版本做了个尝试，就是抛去zk，但是尝试失败了，最终出现多个bug</p>
<p>我们目前用2.2.1的版本</p>
<p>kafka的架构：</p>
<ul>
<li>生产者 ： producer 发送数据的</li>
<li>kafka ：broker 真正是属于卡夫卡的，其余是不属于kafka的组件的</li>
<li>消费者 ：customer 取出数据 ，但是数据并不会传出去，只是把副本发出去</li>
</ul>
<p>这里的数据也叫events</p>
<p>扩展架构：</p>
<ul>
<li>broker kafka的集群的一个节点 ，相当于我们的机器</li>
<li>broker：topic 主题<ul>
<li>负责存储events</li>
<li>订阅和发送都是基于topic来实现的<ul>
<li>只要订阅了这个topic，就可以知道他里面的数据</li>
<li>发送也是同理</li>
<li>一个kafka里可以有多个topic</li>
<li>相当于这个是个有编号的数据仓库</li>
<li>关于kafka的topic，我们是和他的效率成一个曲线波动的，比如在一定区间上升的比较多，一定区间反而下降</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>topic ：</p>
<ul>
<li>partition：分区<ul>
<li>一个topic可以有多个paitition</li>
<li>每个partition是一个有序的序列</li>
<li>分区并不是越多越好，最好是可以被我们的机器整除的，避免数据倾斜</li>
<li>其分区中每个分区都有一个标记信息，叫offset，在offset规定的时间里，我们可以随意的消费这个数据，他会一直在</li>
<li>而且和可以对offset的值进行修改</li>
</ul>
</li>
<li>topic的数据是放在不同的目录下面的，就是分区下面</li>
</ul>
<p>部署 ： </p>
<p>解压 - 》 软连接 -》 环境变量 -》 vim server.properties</p>
<ul>
<li>borker.id : id编号</li>
<li>log.retention.huors:数据保留的时间</li>
<li>zookeeper.connect:zk的链接</li>
<li>log.dirs：数据的存储文件夹</li>
<li>hostname：机器的名字</li>
<li>port：kafka对外的端口</li>
</ul>
<p>更改成功之后，我们启动我们的kafka</p>
<p>kafka的启动有两种方式，然后我们可以通过jps进行查看它</p>
<p>简单的命令：<code>kafka-server-start.sh  -daemon $KAFKA_HOME/config/server.properties</code></p>
<h2 id="查看kafka的topic"><a href="#查看kafka的topic" class="headerlink" title="查看kafka的topic"></a>查看kafka的topic</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics<span class="selector-class">.sh</span> \</span><br><span class="line"><span class="attr">--list</span> \</span><br><span class="line"><span class="attr">--zookeeper</span> bigdata3:<span class="number">2181</span>,bigdata4:<span class="number">2181</span>,bigdata5:<span class="number">2181</span>/kafka</span><br></pre></td></tr></table></figure>

<h2 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics<span class="selector-class">.sh</span> \</span><br><span class="line"><span class="attr">--create</span> \</span><br><span class="line"><span class="attr">--zookeeper</span> bigdata3:<span class="number">2181</span>,bigdata4:<span class="number">2181</span>,bigdata5:<span class="number">2181</span>/kafka \</span><br><span class="line"><span class="attr">--topic</span> dl2262 \</span><br><span class="line"><span class="attr">--partitions</span> <span class="number">6</span> \</span><br><span class="line"><span class="attr">--replication-factor</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>注意 ： </p>
<p>partition的随便指定，最好是机器的倍数</p>
<p>副本-》容错</p>
<p>replication-factor topic的副本数小于等于机器数</p>
<h2 id="查看详细的topic信息"><a href="#查看详细的topic信息" class="headerlink" title="查看详细的topic信息"></a>查看详细的topic信息</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kafka-topics.sh</span> <span class="string">\</span></span><br><span class="line"><span class="string">--describe</span> <span class="string">\</span></span><br><span class="line"><span class="string">--zookeeper</span> <span class="string">bigdata3:2181,bigdata4:2181,bigdata5:2181/kafka</span> <span class="string">\</span></span><br><span class="line"><span class="string">--topic</span> <span class="string">dl2262</span> </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">Topic:dl2262</span>	<span class="string">PartitionCount:6</span>	<span class="string">ReplicationFactor:3</span>	<span class="attr">Configs:</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">0</span>	<span class="attr">Leader:</span> <span class="number">1</span>	<span class="attr">Replicas:</span> <span class="number">1</span><span class="string">,0,2</span>	<span class="attr">Isr:</span> <span class="number">1</span><span class="string">,0,2</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">1</span>	<span class="attr">Leader:</span> <span class="number">2</span>	<span class="attr">Replicas:</span> <span class="number">2</span><span class="string">,1,0</span>	<span class="attr">Isr:</span> <span class="number">2</span><span class="string">,1,0</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">2</span>	<span class="attr">Leader:</span> <span class="number">0</span>	<span class="attr">Replicas:</span> <span class="number">0</span><span class="string">,2,1</span>	<span class="attr">Isr:</span> <span class="number">0</span><span class="string">,2,1</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">3</span>	<span class="attr">Leader:</span> <span class="number">1</span>	<span class="attr">Replicas:</span> <span class="number">1</span><span class="string">,2,0</span>	<span class="attr">Isr:</span> <span class="number">1</span><span class="string">,2,0</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">4</span>	<span class="attr">Leader:</span> <span class="number">2</span>	<span class="attr">Replicas:</span> <span class="number">2</span><span class="string">,0,1</span>	<span class="attr">Isr:</span> <span class="number">2</span><span class="string">,0,1</span></span><br><span class="line">	<span class="attr">Topic:</span> <span class="string">dl2262</span>	<span class="attr">Partition:</span> <span class="number">5</span>	<span class="attr">Leader:</span> <span class="number">0</span>	<span class="attr">Replicas:</span> <span class="number">0</span><span class="string">,1,2</span>	<span class="attr">Isr:</span> <span class="number">0</span><span class="string">,1,2</span></span><br><span class="line"></span><br><span class="line"><span class="string">第一行</span> <span class="string">：</span> <span class="string">topic的总体情况</span> <span class="string">topic的名字</span> <span class="string">分区数量</span> <span class="string">分区数量</span> <span class="string">副本数量</span></span><br><span class="line"><span class="string">第二行及以下</span> <span class="string">：</span> <span class="string">topic名字</span> <span class="string">分区的编号</span> <span class="string">leader的编号：负责对外进行读写的kafka的编号</span> <span class="string">Replicas:当前分区副本在哪些机器上是编号</span> <span class="string">isr：</span> <span class="string">负责对外进行读写请求的读写的顺序（机器编号）</span></span><br><span class="line"><span class="string">实际上是有个顺序的，leader的分配以及，读写的顺序</span></span><br></pre></td></tr></table></figure>

<h2 id="删除topic"><a href="#删除topic" class="headerlink" title="删除topic"></a>删除topic</h2><p>个人建议生产上不要删除topic</p>
<p>当topic的数量变多的时候，如果你删除了一个，则它可能会崩掉</p>
<p>修改也同上 ：</p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh <span class="string">\</span></span><br><span class="line">--<span class="keyword">delete</span> <span class="string">\</span></span><br><span class="line">--zookeeper bigdata3:<span class="number">2181</span>,bigdata4:<span class="number">2181</span>,bigdata5:<span class="number">2181</span>/kafka <span class="string">\</span></span><br><span class="line">--topic dl2262 </span><br></pre></td></tr></table></figure>

<p>topic ： 有俩个数据</p>
<ul>
<li>磁盘上</li>
<li>zk中的</li>
</ul>
<p>执行之后，那个topic会被打上删除的标记，但是实际上数据还是在磁盘上的</p>
<p>如果真的想删除，可以在conf里加上 ，delete.topic.enable&#x3D;true</p>
<h2 id="修改topic"><a href="#修改topic" class="headerlink" title="修改topic"></a>修改topic</h2><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics<span class="selector-class">.sh</span> \</span><br><span class="line"><span class="attr">--alter</span> \</span><br><span class="line"><span class="attr">--zookeeper</span> bigdata3:<span class="number">2181</span>,bigdata4:<span class="number">2181</span>,bigdata5:<span class="number">2181</span>/kafka \</span><br><span class="line"><span class="attr">--topic</span> dl2262 \</span><br><span class="line"><span class="attr">--partitions</span> <span class="number">6</span> \</span><br><span class="line"><span class="attr">--replication-factor</span> <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>想修改什么就加什么参数</p>
<p>但是生产上也不要用：因为可能会导致kafka崩</p>
<p>补充：</p>
<ul>
<li>kafka如何进行数据迁移</li>
<li>kafka进行压力测试</li>
</ul>
<h2 id="生产数据"><a href="#生产数据" class="headerlink" title="生产数据"></a>生产数据</h2><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.<span class="keyword">sh </span>\ </span><br><span class="line">--<span class="keyword">broker-list </span><span class="keyword">bigdata3:9092,bigdata4:9092,bigdata35:9092 </span>\</span><br><span class="line">--topic test</span><br></pre></td></tr></table></figure>

<p>正常我们是通过代码的方式进行编写的</p>
<p>官网的wproduceapi里有详细的介绍</p>
<p>首先要加入我们的代码</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-clients<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>而对于Streaming要添加</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.kafka<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>kafka-streams<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">version</span>&gt;</span>2.1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>kafka封装了一套二进制通信协议，用于对外提供各种各样的服务，对于producer而言，用户可以使用任意编程语言按照该协议的格式进行编程，从而实现向kafka发送消息。这组协议本质上为不同的协议类型分别定义了专属的紧凑二进制字节数组格式，然后通过socket发送给合适的broker，之后等待broker处理完成后返还响应给producer。</p>
<p>每个producer都是独立进行工作的，与其他producer之间没有关联，目前producer的首要功能就是向某个topic的某个分区发送一条消息，所以它首先需要确认到底向topic的哪个分区写入消息，这就是分区器（partitioner）的事情。kafka producer提供了一个默认的分区器，对于每条待发送的消息，如果该消息指定了key，那么该partitioner会根据key的哈希值来选择目标分区，若没有，会使用轮询的方式确认目标分区。当然，producer的API赋予了用户自行指定目标分区的权力。</p>
<p>在确认了目标分区后，producer要做的第二件事就是要寻找这个分区对应的leader，只有leader才能响应客户端发送过来的请求，而剩下的从节点中有一部分会同步该消息。因此在发送消息时，producer有不等待任何副本的响应便返回成功，或者只等待leader响应写入操作之后再返回成功。<br>代码如下 ；</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Producer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProducerTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> void main(<span class="keyword">String</span>[] args) &#123;</span><br><span class="line">        Properties props = <span class="keyword">new</span> <span class="type">Properties</span>();</span><br><span class="line">        <span class="comment">// 必须</span></span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>,<span class="string">&quot;121.5.240.148:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 被发送到broker的任何消息的格式都必须是字节数组</span></span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>,<span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>,<span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        <span class="comment">// 非必须参数配置</span></span><br><span class="line">        <span class="comment">// acks=0表明producer完全不管发送结果；</span></span><br><span class="line">        <span class="comment">// acks=all或-1表明producer会等待ISR所有节点均写入后的响应结果；</span></span><br><span class="line">        <span class="comment">// acks=1，表明producer会等待leader写入后的响应结果</span></span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>,<span class="string">&quot;-1&quot;</span>);</span><br><span class="line">        <span class="comment">// 发生可重试异常时的重试次数</span></span><br><span class="line">        props.put(<span class="string">&quot;retries&quot;</span>,<span class="number">3</span>);</span><br><span class="line">         <span class="comment">// producer会将发往同一分区的多条消息封装进一个batch中，</span></span><br><span class="line">        <span class="comment">// 当batch满了的时候，发送其中的所有消息,不过并不总是等待batch满了才发送消息；</span></span><br><span class="line">        props.put(<span class="string">&quot;batch.size&quot;</span>,<span class="number">323840</span>);</span><br><span class="line">         <span class="comment">// 控制消息发送延时，默认为0，即立即发送，无需关心batch是否已被填满。</span></span><br><span class="line">        props.put(<span class="string">&quot;linger.ms&quot;</span>,<span class="number">10</span>);</span><br><span class="line">        <span class="comment">// 指定了producer用于缓存消息的缓冲区大小，单位字节，默认32MB</span></span><br><span class="line">        <span class="comment">// producer启动时会首先创建一块内存缓冲区用于保存待发送的消息，然后由另一个专属线程负责从缓冲区中读取消息执行真正的发送</span></span><br><span class="line">        props.put(<span class="string">&quot;buffer.memory&quot;</span>,<span class="number">33554432</span>);</span><br><span class="line">        <span class="comment">// 设置producer能发送的最大消息大小</span></span><br><span class="line">        props.put(<span class="string">&quot;max.request.size&quot;</span>,<span class="number">10485760</span>);</span><br><span class="line">        <span class="comment">// 设置是否压缩消息，默认none</span></span><br><span class="line">        props.put(<span class="string">&quot;compression.type&quot;</span>,<span class="string">&quot;lz4&quot;</span>);</span><br><span class="line">        <span class="comment">// 设置消息发送后，等待响应的最大时间</span></span><br><span class="line">        props.put(<span class="string">&quot;request.timeout.ms&quot;</span>,<span class="number">30</span>);</span><br><span class="line"></span><br><span class="line">        Producer&lt;<span class="keyword">String</span>,<span class="keyword">String</span>&gt; producer = <span class="keyword">new</span> <span class="type">KafkaProducer</span>&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt;(props);</span><br><span class="line">        <span class="keyword">for</span>(int i = <span class="number">0</span>;i&lt;<span class="number">5</span>;i++)&#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> <span class="type">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;my-replicated-topic&quot;</span>,<span class="string">&quot;key&quot;</span>+i,<span class="string">&quot;value&quot;</span>+i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>kafka producer发送消息的主方法是send方法，在底层完全地实现了异步化发送，并且通过Java提供的Future同时实现了同步发送和异步发送+回调两种发送方式。而上述代码使用的是第三种方式，即发送之后便不再理会发送结果，这种方式在实际中是不被推荐使用的。</p>
<p><strong>如果发送时连接不上，需要修改kafka配置文件重启</strong> </p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">listeners</span>=PLAINTEXT : 外网ip</span><br><span class="line"><span class="attr">advertised.listeners</span>=PLAINTEXT : 外网ip</span><br></pre></td></tr></table></figure>

<p>异步发送 ：</p>
<p>实际上所有的写入操作默认都是异步的，send方法会返回一个Java Future对象供用户稍后获取发送结果，这就是所谓的回调机制。具体代码如下：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">producer.send(<span class="type">record</span>,<span class="built_in">new</span> Callback()&#123;</span><br><span class="line">  @Override</span><br><span class="line">  <span class="built_in">public</span> <span class="type">void</span> onCompletion(RecordMetadata metadata,<span class="keyword">Exception</span> <span class="keyword">exception</span>)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">exception</span> == <span class="keyword">null</span>)&#123;</span><br><span class="line">      <span class="keyword">System</span>.<span class="keyword">out</span>.println(&quot;消息发送成功&quot;);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">System</span>.<span class="keyword">out</span>.println(&quot;消息发送失败&quot;);</span><br><span class="line">    &#125;  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;);  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>上面的代码中，Callback就是发送消息后的回调类，其onCompletion方法的两个输入参数metadata和exception不会同时非空，当消息发送成功时，exception为null，当消息发送失败时，metadata就是null。Callback实际上是一个Java接口，因此可创建自定义的Callback实现类来处理消息发送后的逻辑。</p>
<p>同步发送</p>
<p>同步发送和异步发送其实就是通过Java的Future来区分的，调用Future.get()等待返回结果，即是同步发送，具体代码如下：</p>
<figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ProducerRecord&lt;<span class="keyword">String</span>, <span class="keyword">String</span>&gt; record = <span class="keyword">new</span> <span class="type">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;my-replicated-topic&quot;</span>,<span class="string">&quot;key&quot;</span>+i,<span class="string">&quot;value&quot;</span>+i);</span><br><span class="line"> RecordMetadata recordMetadata = producer.send(record).<span class="keyword">get</span>();</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用Future.get()方法会一直等待下去直到broker将结果返回给producer程序，当结果返回时，get()方法要么返回发送结果，要么抛出异常交由producer自行处理。如果没有错误，get将返回对应的RecordMetadata实例。</p>
<h3 id="消息分区机制"><a href="#消息分区机制" class="headerlink" title="消息分区机制"></a>消息分区机制</h3><p>producer发送过程中需要确定将消息发送到topic的哪一个分区，默认的分区器会尽力确保具有相同key的所有消息都被发送到相同的分区上；若没有指定key，会以轮询的方式来确保消息在topic的分区上均匀分配。</p>
<h3 id="kafka的发送异常"><a href="#kafka的发送异常" class="headerlink" title="kafka的发送异常"></a>kafka的发送异常</h3><p>当前kafka的错误类型包含了两类：可重试异常和不可重试异常，常见的可重试异常如下：</p>
<ul>
<li>LeaderNotAvailableException：分区对应的leader不可用，通常出现在leader换届选举时，因此是瞬时的异常，重试之后可自行恢复。</li>
<li>NotControllerException：表明controller当前不可用，在经历新一轮的选举，重试之后可自行恢复。</li>
<li>NetworkException：网络瞬时异常，可重试。</li>
</ul>
<p>所有可重试的异常都继承自or.apache.kafka.common.errors.RetriableException，对于这些可重试的异常，如果在producer程序中配置了重试次数，那么只要在规定的重试次数内自行恢复了，便不会出现在onCompletion的exception中。若超过了重试次数仍没成功，就会被封装到exception中，此时就需要producer程序自行处理这种异常。</p>
<p>没有继承自RetriableException的其他异常都属于不可重试异常，这类异常表明了一些非常严重或kafka无法处理的问题。</p>
<h3 id="自定义分区机制"><a href="#自定义分区机制" class="headerlink" title="自定义分区机制"></a>自定义分区机制</h3><p>自定义分区器需要实现org.apache.kafka.clients.producer.Partitioner接口，分区逻辑写在partition()方法中，例如：</p>
<figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">AuditPartitioner</span> implements Partitioner &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Random <span class="built_in">random</span>;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">configure</span>(Map&lt;<span class="built_in">String</span>, ?&gt; <span class="built_in">map</span>) &#123;</span><br><span class="line">        <span class="comment">// 该方法实现必要资源的初始化工作</span></span><br><span class="line">        <span class="built_in">random</span> = <span class="keyword">new </span><span class="class title_">Random</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">partition</span>(<span class="built_in">String</span> topic, <span class="built_in">Object</span> keyObj, <span class="type">byte</span>[] keyBytes, <span class="built_in">Object</span> value, <span class="type">byte</span>[] valueBytes, Cluster cluster) &#123;</span><br><span class="line">        <span class="built_in">String</span> <span class="built_in">key</span> = (<span class="built_in">String</span>)keyObj;</span><br><span class="line">        <span class="comment">// 获取该topic可用的所有分区</span></span><br><span class="line">        List&lt;PartitionInfo&gt; partitionInfoList = cluster.<span class="property">availablePartitionsForTopic</span>(topic);</span><br><span class="line">        <span class="type">int</span> partitionCount = partitionInfoList.<span class="property">size</span>();</span><br><span class="line">        <span class="type">int</span> auditPartition = partitionCount <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">key</span> == <span class="literal">null</span> || !<span class="built_in">key</span>.<span class="property">contains</span>(<span class="string">&quot;audit&quot;</span>) ? <span class="built_in">random</span>.<span class="property">nextInt</span>(auditPartition) : auditPartition;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">close</span>() &#123;</span><br><span class="line">         <span class="comment">// 该方法实现必要资源的清理</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用自定义分区器：<code>props.put(&quot;partitioner.class&quot;,&quot;xx.xx.AuditPartitioner&quot;); </code></p>
<h3 id="自定义序列化器"><a href="#自定义序列化器" class="headerlink" title="自定义序列化器"></a>自定义序列化器</h3><p>自定义序列化器需要实现org.apache.kafka.common.serialization.Serializer接口，在serializer方法中实现序列化逻辑，例如：</p>
<p>首先定义一个POJO对象</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">User</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">String</span> firstName;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">String</span> lastName;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">String</span> address;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">User</span><span class="params">(<span class="type">String</span> firstName,<span class="type">String</span> lastName,<span class="type">int</span> age,<span class="type">String</span> address)</span></span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.firstName=firstName;</span><br><span class="line">  <span class="keyword">this</span>.lastName=lastName;</span><br><span class="line">  <span class="keyword">this</span>.age=age;</span><br><span class="line">  <span class="keyword">this</span>.address=address;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">&#125;  </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由于要用jackson-mapper-asl包中的ObjectMapper来将对象转成字节数组，因此需要将其依赖引入：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.codehaus.jackson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jackson-mapper-asl<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.9.13<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>  </span><br></pre></td></tr></table></figure>

<p>接下来创建serializer</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserSerializer</span> <span class="keyword">implements</span> <span class="title class_">Serializer</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="title class_">ObjectMapper</span> objectMapper;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">configure</span>(<span class="params"><span class="built_in">Map</span> config,<span class="built_in">boolean</span> isKey</span>)&#123;</span><br><span class="line">      objectMapper = <span class="keyword">new</span> <span class="title class_">ObjectMapper</span>();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> byte[] <span class="title function_">serialize</span>(<span class="params"><span class="built_in">String</span> topic,<span class="built_in">Object</span> data</span>)&#123;</span><br><span class="line">    byte[] res = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">      res = objectMapper.<span class="title function_">writeValueAsString</span>(data).<span class="title function_">getBytes</span>(<span class="string">&quot;utf-8&quot;</span>);</span><br><span class="line">    &#125;<span class="keyword">catch</span>(<span class="title class_">Exception</span> e)&#123;</span><br><span class="line">      logger.<span class="title function_">warn</span>(<span class="string">&quot;failed to serialize the object: &#123;&#125;&quot;</span>, data, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">close</span>(<span class="params"></span>)&#123;&#125;</span><br><span class="line">&#125;         </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用自定义的序列化器 <code>props.put(&quot;value.serializer&quot;,&quot;xx.xx.UserSerializer&quot;); </code></p>
<h3 id="producer拦截器"><a href="#producer拦截器" class="headerlink" title="producer拦截器"></a>producer<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%8B%A6%E6%88%AA%E5%99%A8&spm=1001.2101.3001.7020">拦截器</a></h3><p>producer拦截器使得用户在消息发送前和producer回调逻辑执行前可对消息做一些定制化处理，允许使用多个拦截器构成拦截器链。拦截器的实现接口是org.apache.kafka.clients.producer.ProducerInterceptor。interceptor可能运行在多个线程中，因此在具体实现时用户需要确保线程安全。下面以一个简单的双interceptor组成的拦截链为例。第一个interceptor会在消息发送前将时间戳信息加到消息value的最前部，第二个interceptor会在消息发送后更新成功发送消息或失败发送消息数。</p>
<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TimeStampPrependerInterceptor</span> <span class="keyword">implements</span> <span class="title class_">ProducerInterceptor</span>&lt;<span class="title class_">String</span>,<span class="title class_">String</span>&gt; &#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * producer确保在消息被序列化前调用该方法</span></span><br><span class="line"><span class="comment">     * 可以在该方法中对消息做任何操作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title class_">ProducerRecord</span> <span class="title function_">onSend</span>(<span class="params">ProducerRecord record</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>(record.<span class="title function_">topic</span>(),record.<span class="title function_">partition</span>(),record.<span class="title function_">timestamp</span>(),record.<span class="title function_">key</span>(),<span class="title class_">System</span>.<span class="title function_">currentTimeMillis</span>() +<span class="string">&quot;,&quot;</span>+record.<span class="title function_">value</span>().<span class="title function_">toString</span>());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 该方法会在消息被应答之前或消息发送时调用</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">onAcknowledgement</span>(<span class="params">RecordMetadata recordMetadata, Exception e</span>) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">close</span>(<span class="params"></span>) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">configure</span>(<span class="params"><span class="built_in">Map</span>&lt;<span class="built_in">String</span>, ?&gt; map</span>) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CounterInterceptor</span> <span class="keyword">implements</span> <span class="title class_">ProducerInterceptor</span>&lt;<span class="title class_">String</span>,<span class="title class_">String</span>&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> int errorCounter = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">private</span> int successCounter = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title class_">ProducerRecord</span>&lt;<span class="title class_">String</span>, <span class="title class_">String</span>&gt; <span class="title function_">onSend</span>(<span class="params">ProducerRecord&lt;<span class="built_in">String</span>, <span class="built_in">String</span>&gt; record</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> record;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">onAcknowledgement</span>(<span class="params">RecordMetadata recordMetadata, Exception e</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (e == <span class="literal">null</span>) &#123;</span><br><span class="line">            successCounter++;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            errorCounter++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">close</span>(<span class="params"></span>) &#123;</span><br><span class="line">        <span class="title class_">System</span>.<span class="property">out</span>.<span class="title function_">println</span>(<span class="string">&quot;Successful sent: &quot;</span> + successCounter);</span><br><span class="line">        <span class="title class_">System</span>.<span class="property">out</span>.<span class="title function_">println</span>(<span class="string">&quot;Failed sent: &quot;</span> + errorCounter);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">void</span> <span class="title function_">configure</span>(<span class="params"><span class="built_in">Map</span>&lt;<span class="built_in">String</span>, ?&gt; map</span>) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>使用自定义interceptor：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">List&lt;String&gt; interceptors = new ArrayList&lt;&gt;();</span><br><span class="line">interceptors.<span class="built_in">add</span>(<span class="string">&quot;xx.xx.TimeStampPrependerInterceptor&quot;</span>);</span><br><span class="line">interceptors.<span class="built_in">add</span>(<span class="string">&quot;xx.xx.CounterInterceptor&quot;</span>);</span><br><span class="line">props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,interceptors);</span><br></pre></td></tr></table></figure>


<h3 id="消息的可靠发送"><a href="#消息的可靠发送" class="headerlink" title="消息的可靠发送"></a>消息的可靠发送</h3><p>Java版本的producer采用异步发送机制，send方法将消息放入缓冲区，由一个专属I&#x2F;O线程负责从缓冲区中提取消息并封装进消息batch中，然后发送出去。这个过程存在着数据丢失的窗口，即若I&#x2F;O线程发送之前producer崩溃，则存储缓冲区中的消息会全部丢失。producer的另一个问题就是消息的乱序，假设现发送record1和record2两条消息，由于某些原因导致record1未发送成功，同时kafka又配置了重试机制，那么producer重试record1成功后，record1在日志中的位置可能反而位于record2之后。</p>
<h3 id="无消息丢失配置"><a href="#无消息丢失配置" class="headerlink" title="无消息丢失配置"></a>无消息丢失配置</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 该配置控制 KafkaProducer.send() 和 KafkaProducer.partitionsFor() 将阻塞多长时间。此外这些方法被阻止，也可能是因为缓冲区已满或元数据不可用。在用户提供的序列化程序或分区器中的锁定不会计入此超时。默认为60000ms。</span></span><br><span class="line">max<span class="selector-class">.block</span>.ms=<span class="number">60000</span></span><br><span class="line"></span><br><span class="line">acks=<span class="attribute">all</span></span><br><span class="line">retries=Integer<span class="selector-class">.MAX_VALUE</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 该参数设置为1使producer在某个broker发送响应之前将无法再给broker发送请求，可防止topic同分区下的消息乱序问题，</span></span><br><span class="line">max<span class="selector-class">.in</span><span class="selector-class">.flight</span><span class="selector-class">.requests</span><span class="selector-class">.per</span>.connection=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 设置不允许非ISR中的副本被选举为leader，从而避免broker端因日志问题造成消息的丢失</span></span><br><span class="line">unclean<span class="selector-class">.leader</span>.electionenable=false</span><br><span class="line"></span><br><span class="line">replication.factor=<span class="number">3</span></span><br><span class="line"><span class="comment">// 用于控制某条消息至少被写入到ISR中的多少个副本才算成功</span></span><br><span class="line">min<span class="selector-class">.insync</span>.replicas=<span class="number">2</span></span><br><span class="line"></span><br><span class="line">enable<span class="selector-class">.auto</span>.commit=false</span><br><span class="line"></span><br><span class="line">使用带回调机制的send发送消息</span><br><span class="line">Callback逻辑中显式立即关闭producer</span><br></pre></td></tr></table></figure>


<h2 id="消费数据"><a href="#消费数据" class="headerlink" title="消费数据"></a>消费数据</h2><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh <span class="string">\</span></span><br><span class="line">--bootstrap-server bigdata3:<span class="number">9092</span>,bigdata4:<span class="number">9092</span>,bigdata5:<span class="number">9092</span> <span class="string">\</span></span><br><span class="line">--topic dl2262 <span class="string">\</span></span><br><span class="line">--<span class="keyword">from</span>-beginning </span><br></pre></td></tr></table></figure>

<p>–from.beginning :开始消费的位置</p>
<p>问题：消费乱序 ：数据产生的问题和消费顺序不一致</p>
<p>如何保证kafka消费全局有序</p>
<ul>
<li>多分区：不可能<ul>
<li>可以解决，spark ， flink 计算的结果是不对的</li>
<li>source ：mysql  id &#x3D; 1 进行的操作 ： insert delete update</li>
<li>然后把mysql里的binlog采集到kafka -》 flink&#x2F;spark -》hbase&#x2F;phonenix</li>
<li>因为消费乱序，可能会出现问题</li>
<li>思路：<ul>
<li>单分区 ：会影响spark或者flink的吞吐量 原因 ： 原来3个分区，三个并行度 ，现在一个，就慢了</li>
<li>多分区 ：可以利用单分区有序解决全局有序</li>
</ul>
</li>
</ul>
</li>
<li>单分区：可以，单分区数据是有序的</li>
</ul>
<h2 id="kafka测试"><a href="#kafka测试" class="headerlink" title="kafka测试"></a>kafka测试</h2><p>用Kafka官方自带的脚本，对Kafka进行压测。Kafka压测时，可以查看到哪个地方出现了瓶颈（CPU，内存，网络IO）。一般都是网络IO达到瓶颈。</p>
<p>kafka-consumer-<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=perf&spm=1001.2101.3001.7020">perf</a>-test.sh</p>
<p>kafka-producer-perf-test.sh</p>
<h3 id="Kafka-Producer压力测试"><a href="#Kafka-Producer压力测试" class="headerlink" title="Kafka Producer压力测试"></a>Kafka Producer压力测试</h3><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-producer-perf-test.sh  \</span><br><span class="line">--topic test \</span><br><span class="line">--record-size <span class="number">100</span> \</span><br><span class="line">--num-records <span class="number">100000</span> \</span><br><span class="line">--throughput -<span class="number">1</span> \</span><br><span class="line">--producer-props bootstrap.<span class="attr">servers=</span>bigdata3:<span class="number">9092</span>,bigdata4:<span class="number">9092</span>,bigdata5:<span class="number">9092</span></span><br><span class="line"></span><br><span class="line">record-size是一条信息有多大，单位是字节。</span><br><span class="line">num-records是总共发送多少条信息。</span><br><span class="line">throughput 是每秒多少条信息，设成-<span class="number">1</span>，表示不限流，可测出生产者最大吞吐量。</span><br><span class="line"></span><br><span class="line">他会打印下面的语句</span><br><span class="line"><span class="number">100000</span> records sent, <span class="number">149253.731343</span> records/sec (<span class="number">14.23</span> MB/sec), <span class="number">112.02</span> <span class="keyword">ms</span> <span class="title">avg</span> latency, <span class="number">207.00</span> <span class="keyword">ms</span> <span class="title">max</span> latency, <span class="number">97</span> <span class="keyword">ms</span> <span class="title">50th</span>, <span class="number">190</span> <span class="keyword">ms</span> <span class="title">95th</span>, <span class="number">206</span> <span class="keyword">ms</span> <span class="title">99th</span>, <span class="number">207</span> <span class="keyword">ms</span> <span class="title">99</span>.<span class="number">9</span>th.</span><br><span class="line">参数解析：本例中一共写入<span class="number">10</span>w条消息，吞吐量为<span class="number">14.23</span> MB/sec，每次写入的平均延迟为<span class="number">112.02</span>毫秒，最大的延迟为<span class="number">207</span>毫秒</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="Kafka-Consumer压力测试"><a href="#Kafka-Consumer压力测试" class="headerlink" title="Kafka Consumer压力测试"></a>Kafka Consumer压力测试</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-perf-test.sh </span><br><span class="line"><span class="comment">--broker-list bigdata3:9092,bigdata4:9092,bigdata35:9092 </span></span><br><span class="line"><span class="comment">--topic test </span></span><br><span class="line"><span class="comment">--fetch-size 10000 </span></span><br><span class="line"><span class="comment">--messages 10000000 </span></span><br><span class="line"><span class="comment">--threads 1</span></span><br><span class="line"> </span><br><span class="line"><span class="comment">--zookeeper 指定zookeeper的链接信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--topic 指定topic的名称</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--fetch-size 指定每次fetch的数据的大小</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--messages 总共要消费的消息个数</span></span><br><span class="line">测试结果说明：</span><br><span class="line"></span><br><span class="line"><span class="built_in">start</span>.<span class="built_in">time</span>, <span class="keyword">end</span>.<span class="built_in">time</span>, data.consumed.<span class="keyword">in</span>.MB, MB.<span class="built_in">sec</span>, data.consumed.<span class="keyword">in</span>.nMsg, nMsg.<span class="built_in">sec</span></span><br><span class="line"><span class="number">2020</span><span class="number">-03</span><span class="number">-10</span> <span class="number">03</span>:<span class="number">18</span>:<span class="number">51</span>:<span class="number">773</span>, <span class="number">2020</span><span class="number">-03</span><span class="number">-10</span> <span class="number">03</span>:<span class="number">18</span>:<span class="number">53</span>:<span class="number">815</span>, <span class="number">19.0735</span>, <span class="number">9.3406</span>, <span class="number">200000</span>, <span class="number">97943.192</span></span><br></pre></td></tr></table></figure>


<h2 id="Kafka-集群数据迁移"><a href="#Kafka-集群数据迁移" class="headerlink" title="Kafka 集群数据迁移"></a>Kafka 集群数据迁移</h2><h3 id="同集群迁移"><a href="#同集群迁移" class="headerlink" title="同集群迁移"></a>同集群迁移</h3><p>同集群之间数据迁移，比如在已有的集群中新增了一个Broker节点，此时需要将原来集群中已有的Topic的数据迁移部分到新的集群中，缓解集群压力。</p>
<p>将新的节点添加到Kafka集群很简单，只需为它们分配一个唯一的Broker ID，并在新<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cvm?from=10680">服务器</a>上启动Kafka。但是，这些新服务器节点不会自动分配任何数据分区，因此除非将分区移动到新增的节点，否则在创建新Topic之前新节点不会执行任何操作。因此，通常在将新服务器节点添加到Kafka集群时，需要将一些现有数据迁移到这些新的节点。</p>
<p>迁移数据的过程是手动启动的，执行过程是完全自动化的。在Kafka后台服务中，Kafka将添加新服务器作为其正在迁移的分区的Follower，并允许新增节点完全复制该分区中的现有数据。当新服务器节点完全复制此分区的内容并加入同步副本（ISR）时，其中一个现有副本将删除其分区的数据。</p>
<p>Kafka系统提供了一个分区重新分配工具（kafka-reassign-partitions.sh），该工具可用于在Broker之间迁移分区。理想情况下，将确保所有Broker的数据和分区均匀分配。分区重新分配工具无法自动分析Kafka群集中的数据分布并迁移分区以实现均匀的<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/clb?from=10680">负载均衡</a>。因此，管理员在操作的时候，必须弄清楚应该迁移哪些Topic或分区。</p>
<p>分区重新分配工具可以在3种互斥模式下运行：</p>
<ul>
<li>–generate：在此模式下，给定Topic列表和Broker列表，该工具会生成候选重新分配，以将指定Topic的所有分区迁移到新Broker中。此选项仅提供了一种方便的方法，可在给定Topic和目标Broker列表的情况下生成分区重新分配计划。</li>
<li>–execute：在此模式下，该工具将根据用户提供的重新分配计划启动分区的重新分配。 （使用–reassignment-json-file选项）。由管理员手动制定自定义重新分配计划，也可以使用–generate选项提供。</li>
<li>–verify：在此模式下，该工具将验证最后一次–execute期间列出的所有分区的重新分配状态。状态可以有成功、失败或正在进行等状态。</li>
</ul>
<h3 id="迁移过程实现"><a href="#迁移过程实现" class="headerlink" title="迁移过程实现"></a>迁移过程实现</h3><p>分区重新分配工具可用于将一些Topic从当前的Broker节点中迁移到新添加的Broker中。这在扩展现有集群时通常很有用，因为将整个Topic移动到新的Broker变得更容易，而不是一次移动一个分区。当执行此操作时，用户需要提供已有的Broker节点的Topic列表，以及到新节点的Broker列表（源Broker到新Broker的映射关系）。然后，该工具在新的Broker中均匀分配给指定Topic列表的所有分区。在迁移过程中，Topic的复制因子保持不变。</p>
<p>现有如下实例，将Topic为ke01，ke02的所有分区从Broker1中移动到新增的Broker2和Broker3中。由于该工具接受Topic的输入列表作为JSON文件，因此需要明确迁移的Topic并创建json文件，如下所示：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; cat topic-<span class="keyword">to</span>-<span class="keyword">move</span>.json</span><br><span class="line">&#123;&quot;topics&quot;: [&#123;&quot;topic&quot;: &quot;ke01&quot;&#125;,</span><br><span class="line">            &#123;&quot;topic&quot;: &quot;ke02&quot;&#125;],</span><br><span class="line">&quot;version&quot;:<span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>准备好JSON文件，然后使用分区重新分配工具生成候选分配，命令如下：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; bin/kafka-<span class="keyword">reassign</span>-partitions.sh <span class="comment">--zookeeper bigdata3:2181,bigdata4:2181,bigdata5:2181/kafka  --topics-to-move-json-file topics-to-move.json --broker-list &quot;1,2&quot; --generate</span></span><br></pre></td></tr></table></figure>

<p>该工具生成一个候选分配，将所有分区从Topic ke01，ke02移动到Broker1和Broker2。需求注意的是，此时分区移动尚未开始，它只是告诉你当前的分配和建议。保存当前分配，以防你想要回滚它。新的赋值应保存在JSON文件（例如expand-cluster-reassignment.json）中，以使用–execute选项执行。JSON文件如下：</p>
<figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&quot;version&quot;</span>:<span class="number">1</span>,<span class="string">&quot;partitions&quot;</span>:[&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke02&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">0</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">2</span>]&#125;,&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke02&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">1</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">1</span>]&#125;,&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke02&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">2</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">2</span>]&#125;,&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke01&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">0</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">2</span>]&#125;,&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke01&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">1</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">1</span>]&#125;,&#123;<span class="string">&quot;topic&quot;</span>:<span class="string">&quot;ke01&quot;</span>,<span class="string">&quot;partition&quot;</span>:<span class="number">2</span>,<span class="string">&quot;replicas&quot;</span>:[<span class="number">2</span>]&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>命令</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; ./kafka-<span class="keyword">reassign</span>-partitions.sh <span class="comment">--zookeeper bigdata3:2181,bigdata4:2181,bigdata5:2181/kafka --reassignment-json-file expand-cluster-reassignment.json --execute</span></span><br></pre></td></tr></table></figure>

<p>最后，–verify选项可与该工具一起使用，以检查分区重新分配的状态。需要注意的是，相同的expand-cluster-reassignment.json（与–execute选项一起使用）应与–verify选项一起使用，执行命令如下：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; ./kafka-<span class="keyword">reassign</span>-partitions.sh <span class="comment">--zookeeper bigdata3:2181,bigdata4:2181,bigdata5:2181/kafka --reassignment-json-file expand-cluster-reassignment.json --verify</span></span><br></pre></td></tr></table></figure>

<p>同时，我们可以通过<a target="_blank" rel="noopener" href="https://blog.csdn.net/m0_63722685?spm=1011.2124.3001.5343">Kafka Eagle</a>工具来查看Topic的分区情况。</p>
<h2 id="跨集群迁移"><a href="#跨集群迁移" class="headerlink" title="跨集群迁移"></a>跨集群迁移</h2><p>这里跨集群迁移，我们指的是在Kafka多个集群之间复制数据“镜像”的过程，以避免与单个集群中的节点之间发生的复制混淆。 Kafka附带了一个用于在Kafka集群之间镜像数据的工具。该工具从源集群使用并生成到目标集群。这种镜像的一个常见用例是在另一个数据中心提供副本。</p>
<p>另外，你可以运行许多此类镜像进程以提高吞吐量和容错（如果一个进程终止，其他进程将占用额外负载）。将从源集群中的Topic读取数据，并将其写入目标集群中具有相同名称的主题。事实上，“镜像”数据只不过是一个Kafka将消费者和生产者联系在了一起。</p>
<p>源集群和目标集群是完全独立的实体，它们可以具有不同数量的分区，并且偏移量将不相同。出于这个原因，镜像集群并不是真正意图作为容错机制（因为消费者的位置会有所不同）;为此，建议使用正常的集群内复制。但是，镜像进程将保留并使用消息Key进行分区，因此可以按Key保留顺序。</p>
<p>下面是一个跨集群的单Topic实例，命令如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; ./kafka-mirror-maker<span class="selector-class">.sh</span> <span class="attr">--consumer</span><span class="selector-class">.config</span> consumer<span class="selector-class">.properties</span> <span class="attr">--producer</span><span class="selector-class">.config</span> producer<span class="selector-class">.properties</span> <span class="attr">--whitelist</span> ke03</span><br></pre></td></tr></table></figure>

<p>需要注意的是，consumer.properties文件配置源Kafka集群Broker地址，producer.properties文件配置目标Kafka集群地址。如果需要迁移多个Topic，可以使用 –whitelist ‘A|B’，如果需要迁移所有的Topic，可以使用 –whitelist ‘*’。</p>
<p>执行跨集群迁移命令后，目标集群中使用Kafka Eagle中查看Topic Size大小看是否与源集群的Topic Size大小相等，或者使用SQL语句，验证是否有数据迁移过来，</p>
<p>跨集群迁移数据的本质是，Kafka启动了消费者读取源集群数据，并将消费后的数据写入到目标集群，在迁移的过程中，可以启动多个实例，提供迁出的吞吐量。</p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/15/%E6%8A%80%E6%9C%AF%E7%82%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/15/%E6%8A%80%E6%9C%AF%E7%82%B9/" class="post-title-link" itemprop="url">自我认为的知识点</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-15 16:31:20" itemprop="dateCreated datePublished" datetime="2022-12-15T16:31:20+08:00">2022-12-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-16 14:42:28" itemprop="dateModified" datetime="2022-12-16T14:42:28+08:00">2022-12-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%95%B4%E7%90%86/" itemprop="url" rel="index"><span itemprop="name">整理</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>1.9k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h1><h2 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h2><p>awk为什么会被称作linux三剑客之一，相比于cut如何？</p>
<p>场景 ： 通过ssh bigdata2 “jps | xxx | awk ‘{print $1}’” :结果如何 ？前提条件 ：bigdata2的密钥已经添加在当前的机器上，且jps能查到xxx的进程号</p>
<h2 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h2><p>场景 ： 当所有命令都提示找不到命令 ，是什么原因 ，如何解决 ？</p>
<p>场景 ： 当有命令提示找不到命令 ，是什么原因 ，如何解决 ？</p>
<h2 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h2><p>众所周知 ，root用户有最高的权限 ，那么当我们在hadoop用户启动程序通过jps能查看到信息的，切换到root用户我们可以看见信息吗</p>
<h2 id="问题4"><a href="#问题4" class="headerlink" title="问题4"></a>问题4</h2><p>一台机器里有hadoop ,zihang ,root 三个用户 ，你所在的用户是root ，当你执行su - zihang 的时候什么也没出现并且你还在root用户，这个是什么原因，如何修复</p>
<h2 id="问题5"><a href="#问题5" class="headerlink" title="问题5"></a>问题5</h2><p>linux里查看内存负载，以及所用内存，以及设置swap分区的命令及步骤，</p>
<h1 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h1><h2 id="问题1-1"><a href="#问题1-1" class="headerlink" title="问题1"></a>问题1</h2><p>shell里如何控制从控制台输入的参数，传进函数里的个数</p>
<h2 id="问题2-1"><a href="#问题2-1" class="headerlink" title="问题2"></a>问题2</h2><p>shell 里截取字符串以及替换字符串是如何实现的</p>
<h2 id="问题3-1"><a href="#问题3-1" class="headerlink" title="问题3"></a>问题3</h2><p>shell里的$全家桶</p>
<h2 id="问题4-1"><a href="#问题4-1" class="headerlink" title="问题4"></a>问题4</h2><p>shell里单引号，双引号，漂号的区别，以及两种括号的形式（）和{}的区别</p>
<h2 id="问题5-1"><a href="#问题5-1" class="headerlink" title="问题5"></a>问题5</h2><p>shell脚本执行不了，但是代码毫无问题，只是单纯提示最后一行结尾不对，原因有几种，解决办法是什么</p>
<h1 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h1><h2 id="问题1-2"><a href="#问题1-2" class="headerlink" title="问题1"></a>问题1</h2><p>mysql中where和having的区别</p>
<h2 id="问题2-2"><a href="#问题2-2" class="headerlink" title="问题2"></a>问题2</h2><p>mysql中我如果想把竖着的一列变成横着的如何操作：</p>
<table>
<thead>
<tr>
<th>人数</th>
<th>部门</th>
</tr>
</thead>
<tbody><tr>
<td>11</td>
<td>a</td>
</tr>
</tbody></table>
<p>其中5人生病，6人未生病，如何变成下面的样子:说出大概思路即可</p>
<table>
<thead>
<tr>
<th>人数</th>
<th>部门</th>
<th>生病人数</th>
<th>未生病人数</th>
</tr>
</thead>
<tbody><tr>
<td>11</td>
<td>a</td>
<td>0</td>
<td>6</td>
</tr>
<tr>
<td>11</td>
<td>a</td>
<td>5</td>
<td>0</td>
</tr>
</tbody></table>
<h2 id="问题3-2"><a href="#问题3-2" class="headerlink" title="问题3"></a>问题3</h2><p>mysql中判断空值的方法有什么，以及多路选择的方法</p>
<h2 id="问题4-2"><a href="#问题4-2" class="headerlink" title="问题4"></a>问题4</h2><p>在往mysql的表里插入数据的时候，发现带有中文的字符插入不进去，如何解决，什么原因造成的，mysql8及以后如何</p>
<h2 id="问题5-2"><a href="#问题5-2" class="headerlink" title="问题5"></a>问题5</h2><p>你认为mysql为什么到目前为止都没有被淘汰？</p>
<h1 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h1><h2 id="问题1-3"><a href="#问题1-3" class="headerlink" title="问题1"></a>问题1</h2><p>关于hadoop的基础架构，以及mr的流程</p>
<h2 id="问题2-3"><a href="#问题2-3" class="headerlink" title="问题2"></a>问题2</h2><p>关于客户端向hdfs上传输数据的流程，而且它是如何被分块的</p>
<h2 id="问题3-3"><a href="#问题3-3" class="headerlink" title="问题3"></a>问题3</h2><p>hadoop文件存储的放置策略，以及为什么这样放置</p>
<h2 id="问题4-3"><a href="#问题4-3" class="headerlink" title="问题4"></a>问题4</h2><p>Hadoop上的yarn的申请资源的流程，以及为什么要使用多块物理磁盘？</p>
<h2 id="问题5-3"><a href="#问题5-3" class="headerlink" title="问题5"></a>问题5</h2><p>hdfs上的压缩格式，以及优缺点，和我们常用的</p>
<h2 id="问题6"><a href="#问题6" class="headerlink" title="问题6"></a>问题6</h2><p>hadoop序列化</p>
<p>序列化就是把内存中的对象转换成字节序列(或其他数据传输协议)，以便存储于磁盘和网络传输。</p>
<p>优点 ：</p>
<p>紧凑：高效使用存储空间</p>
<p>快速：读写数据额外开销小</p>
<p>可扩展性：随着通讯协议的升级而升级</p>
<p>互操性：支持多语言的交互</p>
<h2 id="问题7"><a href="#问题7" class="headerlink" title="问题7"></a>问题7</h2><p>yarn调度器</p>
<h2 id="问题8"><a href="#问题8" class="headerlink" title="问题8"></a>问题8</h2><p>分区vs分桶</p>
<p>分区表：在逻辑上，将表中的数据按分区放在表目录的对应子目录中，在物理上，分区表和未分区表没有区别，分区表在表创建完成时，也可以通过alter table来添加或者删除，而且分区键一定不是原表中的列。<br>桶表：不同表对同一字段分桶，且当两张表桶数相同时，数据会分配到同一个节点上，join时会减少shuffle，和分区键不同，分桶键必须是原表中的列，分桶表中每个桶的文件作了排序，分桶数应为质数，每个桶文件大小应在100MB~200MB之间，事务表必须指定分桶，且分桶数是不可以被更新的。</p>
<h2 id="问题9"><a href="#问题9" class="headerlink" title="问题9"></a>问题9</h2><p>yarn原理</p>
<h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><h2 id="问题1-4"><a href="#问题1-4" class="headerlink" title="问题1"></a>问题1</h2><p>你所理解的hive是什么？</p>
<h2 id="问题2-4"><a href="#问题2-4" class="headerlink" title="问题2"></a>问题2</h2><p>hive在mysql中的几个关键表都是什么</p>
<h2 id="问题3-4"><a href="#问题3-4" class="headerlink" title="问题3"></a>问题3</h2><p>hive里空值如何处理，hive中mapjoin如何开启以及开启之后的原理</p>
<h2 id="问题4-4"><a href="#问题4-4" class="headerlink" title="问题4"></a>问题4</h2><p>hive里内部表和外部表的区别，以及如何转化</p>
<h2 id="问题5-4"><a href="#问题5-4" class="headerlink" title="问题5"></a>问题5</h2><p>hive里的开窗函数能用在什么函数上，开窗之后还可以分组吗</p>
<h2 id="问题6-1"><a href="#问题6-1" class="headerlink" title="问题6"></a>问题6</h2><p>hive如何把一列数据转化为数组，并且hive的适用场景是什么</p>
<h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><h2 id="问题1-5"><a href="#问题1-5" class="headerlink" title="问题1"></a>问题1</h2><p>flume如何设置传输到hdfs上的数据的压缩格式</p>
<h2 id="问题2-5"><a href="#问题2-5" class="headerlink" title="问题2"></a>问题2</h2><p>flume如何控制小文件的数量，以及如何监控flume的采集情况</p>
<h2 id="问题3-5"><a href="#问题3-5" class="headerlink" title="问题3"></a>问题3</h2><p>flume如何控制多个channel和Sink，以及控制形式都有什么</p>
<h2 id="问题4-5"><a href="#问题4-5" class="headerlink" title="问题4"></a>问题4</h2><p>现阶段如何解决日志数据延迟性问题</p>
<h2 id="问题5-5"><a href="#问题5-5" class="headerlink" title="问题5"></a>问题5</h2><p>flume采集的数据文件会丢失吗，为什么以及taildir所谓的断点续传是什么，由什么控制</p>
<h1 id="sqoop"><a href="#sqoop" class="headerlink" title="sqoop"></a>sqoop</h1><h2 id="问题1-6"><a href="#问题1-6" class="headerlink" title="问题1"></a>问题1</h2><p>sqoop同步mysql到hive的时候如何设置分区表</p>
<h2 id="问题2-6"><a href="#问题2-6" class="headerlink" title="问题2"></a>问题2</h2><p>sqoop是走mr程序吗？为什么sqoop运行如此的慢</p>
<h2 id="问题3-6"><a href="#问题3-6" class="headerlink" title="问题3"></a>问题3</h2><p>sqoop同步hive到mysql的时候经常因为不明原因就中断了，如何解决</p>
<h2 id="问题4-6"><a href="#问题4-6" class="headerlink" title="问题4"></a>问题4</h2><p>sqoop同步hive到mysql分区表的思路以及操作是什么</p>
<h2 id="问题5-6"><a href="#问题5-6" class="headerlink" title="问题5"></a>问题5</h2><p>sqoop导入数据的时候如何保证数据的幂等性</p>
<h1 id="zk"><a href="#zk" class="headerlink" title="zk"></a>zk</h1><h2 id="问题1-7"><a href="#问题1-7" class="headerlink" title="问题1"></a>问题1</h2><p>如何创建临时节点和永久节点</p>
<h2 id="问题2-7"><a href="#问题2-7" class="headerlink" title="问题2"></a>问题2</h2><p>四字命令是干什么的</p>
<h2 id="问题3-7"><a href="#问题3-7" class="headerlink" title="问题3"></a>问题3</h2><p>zk命令行监听和api监听的区别，通过上面命令进行监听</p>
<h2 id="问题4-7"><a href="#问题4-7" class="headerlink" title="问题4"></a>问题4</h2><p>如何创建顺序节点</p>
<h2 id="问题5-7"><a href="#问题5-7" class="headerlink" title="问题5"></a>问题5</h2><p>zk如何管理我们的namenode的上位，以及，如何监控的</p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/15/12-15/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/15/12-15/" class="post-title-link" itemprop="url">zookeeper</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-15 08:20:33" itemprop="dateCreated datePublished" datetime="2022-12-15T08:20:33+08:00">2022-12-15</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-16 14:41:27" itemprop="dateModified" datetime="2022-12-16T14:41:27+08:00">2022-12-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%BF%97/" itemprop="url" rel="index"><span itemprop="name">日志</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="hive的抓取策略"><a href="#hive的抓取策略" class="headerlink" title="hive的抓取策略"></a>hive的抓取策略</h1><p>什么是hive的抓取策略呢，举个简单的例子,当我们用 <code>select * from xxx</code>的时候它不会走mr阶段，会直接出来，可是有时候会走mr这个是由什么控制的？就是由我们的hive的抓取策略决定的</p>
<p>我们还可以在配置文件中进行更改，把不要mr的代码变多</p>
<p><code>hive/conf/hive-default.xml.template -》 2637行，修改hive.fetch.task.conversion为more；</code></p>
<p>就相当于把全局查找，字段查找，filter查找，limit查找等都不走MR，直接Fetch</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;<span class="type">name</span>&gt;hive.<span class="keyword">fetch</span>.task.<span class="keyword">conversion</span>&lt;/<span class="type">name</span>&gt;</span><br><span class="line">  &lt;<span class="keyword">value</span>&gt;more&lt;/<span class="keyword">value</span>&gt;</span><br><span class="line">  &lt;description&gt;</span><br><span class="line">    Expects one <span class="keyword">of</span> [<span class="keyword">none</span>, minimal, more].</span><br><span class="line">    <span class="keyword">Some</span> <span class="keyword">select</span> queries can be converted <span class="keyword">to</span> single <span class="keyword">FETCH</span> task minimizing latency.</span><br><span class="line">    Currently the query should be single sourced <span class="keyword">not</span> <span class="keyword">having</span> <span class="keyword">any</span> subquery <span class="keyword">and</span> should <span class="keyword">not</span> have</span><br><span class="line">    <span class="keyword">any</span> aggregations <span class="keyword">or</span> distincts (which incurs RS), <span class="keyword">lateral</span> views <span class="keyword">and</span> joins.</span><br><span class="line">    <span class="number">0.</span> <span class="keyword">none</span> : <span class="keyword">disable</span> hive.<span class="keyword">fetch</span>.task.<span class="keyword">conversion</span></span><br><span class="line">    <span class="number">1.</span> minimal : <span class="keyword">SELECT</span> STAR, <span class="keyword">FILTER</span> <span class="keyword">on</span> <span class="keyword">partition</span> <span class="keyword">columns</span>, <span class="keyword">LIMIT</span> <span class="keyword">only</span></span><br><span class="line">    <span class="number">2.</span> more    : <span class="keyword">SELECT</span>, <span class="keyword">FILTER</span>, <span class="keyword">LIMIT</span> <span class="keyword">only</span> (support <span class="keyword">TABLESAMPLE</span> <span class="keyword">and</span> virtual <span class="keyword">columns</span>)</span><br><span class="line">  &lt;/description&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<p>然后还可以设置 ：</p>
<p> 用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。</p>
<p>set hive.exec.mode.local.auto&#x3D;true; &#x2F;&#x2F;开启本地mr</p>
<p>设置local mr的最大输入数据量，当输入数据量小于这个值时采用local mr的方式，默认为134217728，即128M</p>
<p>set hive.exec.mode.local.auto.inputbytes.max&#x3D;51234560;</p>
<p>设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</p>
<p>set hive.exec.mode.local.auto.input.files.max&#x3D;10;</p>
<p>调整hive里的切片大小 ：</p>
<p>mapreduce.input.fileinputformat.split.maxsize</p>
<p>mapreduce.input.fileinputformat.split.minsize</p>
<p>maxsize（切片最大值）：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。<br>minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blockSize还大。</p>
<h1 id="sql调优（speed）"><a href="#sql调优（speed）" class="headerlink" title="sql调优（speed）"></a>sql调优（speed）</h1><h2 id="小表join大表"><a href="#小表join大表" class="headerlink" title="小表join大表"></a>小表join大表</h2><p>当小表Join大表时，如果不指定MapJoin，那么hive解析器会将join操作转换为Common Join操作，在Reduce端完成join，容易发生<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C&spm=1001.2101.3001.7020">数据倾斜</a>。开启MapJoin后可以将小表全部加载到内存中，在map端进行join，避免reducer处理。</p>
<p>优点 ：</p>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">（<span class="number">1</span>）没有reducer处理，就不会产生数据倾斜；</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）没有Map -&gt; Reduce中间的shuffle操作，避免了IO</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>. 开启MapJoin设置</span><br><span class="line">（<span class="number">1</span>）设置自动选择MapJoin，默认是<span class="literal">true</span></span><br><span class="line">set hive.auto.<span class="built_in">convert</span>.<span class="built_in">join</span> = <span class="literal">true</span>;</span><br><span class="line"> </span><br><span class="line">（<span class="number">2</span>）设置小表阈值，默认是25M</span><br><span class="line">set hive.mapjoin.smalltable.filesize=<span class="number">25000000</span>;</span><br><span class="line"> </span><br><span class="line"><span class="number">2</span>. 再大表<span class="built_in">join</span>小表，与小表<span class="built_in">join</span>大表，执行速率几乎相等</span><br><span class="line"></span><br><span class="line">Hive中mapjoin的原理：</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>-side <span class="built_in">join</span>：</span><br><span class="line"></span><br><span class="line">小表数据映射成一张hashtable，再上传到分布式节点的内存中；</span><br><span class="line">大表进行分片，每个节点一部分数据，大表数据文件作为<span class="built_in">map</span>端输入，对<span class="built_in">map</span>()函数每一对输入的kv都与已加载到内存中的小表数据连接，</span><br><span class="line">把连接结果按<span class="built_in">key</span>输出，有多少个<span class="built_in">map</span> task，产生多少个结果文件；</span><br><span class="line">由于<span class="built_in">join</span>操作在<span class="built_in">map</span> task中完成，所以无需启动reduce task，没有shuffle操作和reduce端，避免io和数据倾斜</span><br><span class="line"></span><br><span class="line">reduce-side <span class="built_in">join</span>：</span><br><span class="line"></span><br><span class="line"><span class="built_in">map</span>端把结果按<span class="built_in">key</span>输出，并在value中标记出数据来源于table1还是table2</span><br><span class="line">因为在shuffle阶段已经按<span class="built_in">key</span>分组，reduce阶段会判断每个value来自哪张表，然后两表相同<span class="built_in">key</span>的记录连接</span><br><span class="line"><span class="built_in">join</span>操作在reduce task中完成</span><br><span class="line"></span><br><span class="line">缺点<span class="number">1</span>：在<span class="built_in">map</span>阶段没有对数据瘦身，shuffle的网络传输和排序性能很低</span><br><span class="line">缺点<span class="number">2</span>：reduce对<span class="number">2</span>个集合做城际计算，很耗内存，容易造成oom</span><br></pre></td></tr></table></figure>

<h2 id="大表join大表"><a href="#大表join大表" class="headerlink" title="大表join大表"></a>大表join大表</h2><p>有时join超时是因为某些key对应的数据太多了。由于相同的key对应的数据都会发送到相同的reducer上，如果出现数据倾斜可能导致内存不足。</p>
<p>常见对于key对应字段为空，可以采取的优化手段包括空值key过滤和空值key转换</p>
<p>首先我们要进行配置，开启历史服务器</p>
<figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. 首先配置mapred-site.xml</span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"></span><span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"></span><span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="language-xml">    </span><span class="language-xml"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml">    </span><span class="language-xml"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><span class="language-xml"></span></span><br><span class="line"><span class="language-xml"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="number">2</span>. 在shell端启动历史服务器</span><br><span class="line">sbin/mr-jobhistory-daemon.sh <span class="keyword">start</span> historyserver</span><br><span class="line"> </span><br><span class="line"><span class="number">3</span>. 查看jobhistory端口</span><br><span class="line">http://hadoop10<span class="number">0</span>:<span class="number">19888</span>/jobhistory</span><br></pre></td></tr></table></figure>

<p>空key过滤</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">不过滤空id列</span><br><span class="line"><span class="keyword">insert</span> overwrite table A </span><br><span class="line"><span class="keyword">select</span> b.* <span class="keyword">from</span> B b <span class="keyword">left</span> <span class="keyword">join</span> C c <span class="keyword">on</span> b.id = c.id;</span><br><span class="line"> </span><br><span class="line">过滤掉空id列</span><br><span class="line"><span class="keyword">insert</span> overwrite table A </span><br><span class="line"><span class="keyword">select</span> b.* <span class="keyword">from</span> (<span class="keyword">select</span> * <span class="keyword">from</span> B <span class="keyword">where</span> id <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">null</span>) b <span class="keyword">left</span> <span class="keyword">join</span> C c <span class="keyword">on</span> b.id = c.id;</span><br><span class="line">过滤掉空id列后，耗费时间会降低很多。</span><br></pre></td></tr></table></figure>

<p><strong>或者把它变成其他的有值的</strong></p>
<p>有时虽然某个key对应的null很多，但null并不是异常数据，不能过滤掉，必须包含在join的结果中，这样就可以考虑把表中key为null的字段赋一个随机值，使得数据随机均匀分到不同的reducer上。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">首先设置reduce个数</span><br><span class="line"><span class="keyword">set</span> mapreduce.job.reduces = <span class="number">5</span>;</span><br><span class="line"> </span><br><span class="line">然后<span class="keyword">join</span>两张表，随机设置<span class="keyword">null</span>值</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> A</span><br><span class="line"><span class="keyword">select</span> b.* <span class="keyword">from</span> B b <span class="keyword">full</span> <span class="keyword">join</span> C c <span class="keyword">on</span></span><br><span class="line"><span class="keyword">case</span> <span class="keyword">when</span> b.id <span class="keyword">is</span> <span class="keyword">null</span> <span class="keyword">then</span> concat (<span class="string">&#x27;hive&#x27;</span>,rand()) <span class="keyword">else</span> b.id end = c.id;</span><br></pre></td></tr></table></figure>

<p>原理：当表b的字段id为null时，如果null过多所有null对应同一个key即id，都挤到一个reduce上，通过优化将表b的key&#x3D;id换成key&#x3D;hive随机数，这样null分配到不同的key上，避免数据倾斜。</p>
<p>case when A then B else C end语法：</p>
<p>当b表的字段id为null时，对id取值为拼接字符串（hive+随机数），否则依然取b.id；然后on条件为：hive随机数&#x3D;c.id或者b.id&#x3D;c.id。</p>
<h2 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h2><p>对于group by聚合，默认情况下，Map阶段同一Key的数据发给一个reduce，若某个key的数据量太大，可能会造成数据倾斜。</p>
<p>如果在Map端就直接完成部分聚合，最后在Reduce端得出最终结果，就可以避免数据倾斜。</p>
<p>需要在Map端进行聚合参数设置：</p>
<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 是否在<span class="built_in">Map</span>端进行聚合，默认是<span class="literal">true</span></span><br><span class="line"><span class="built_in">set</span> hive.<span class="built_in">map</span>.aggr = <span class="literal">true</span></span><br><span class="line"> </span><br><span class="line"><span class="number">2.</span> 在<span class="built_in">Map</span>端进行聚合操作的条目数，默认<span class="number">10</span>w条</span><br><span class="line"><span class="built_in">set</span> hive.groupby.mapaggr.checkinterval = <span class="number">100000</span></span><br><span class="line"> </span><br><span class="line"><span class="number">3.</span> 有数据倾斜时进行负载均衡，默认<span class="literal">false</span></span><br><span class="line"><span class="built_in">set</span> hive.groupby.skewindata = <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>原理是当set hive.groupby.skewindata &#x3D; true后，会生成两个MR Job，启两个任务。</p>
<p>job1将group by的key，相同的key可能随机分发到不同的Reduce中，然后Reduce依据key对数据进行聚合，此时每一个Reduce中每个数据的key不一定相同，但是经过这一步聚合后，大大减少了数据量。</p>
<p>job2是真正意义上MR的底层实现，将相同的key分配到同一个reduce中，进行key的聚合操作。</p>
<p>第一步job1实现负载均衡，第二步job2实现聚合需求。</p>
<p>如果skewindata参数&#x3D;false，也就是默认情况下，只会进行job2操作，进行一次MapReduce。</p>
<h2 id="count"><a href="#count" class="headerlink" title="count"></a>count</h2><p>用 count(distinct key)处理数据</p>
<p>当数据量大的时候，由于count（distinct key）去重聚合是全聚合操作，即便是设定了reduce tasks的个数，例如set mapred.reduce.tasks&#x3D;100；hive也只会启动一个reducer（order by也是这个情况），这就造成一个reducer处理的数据量太大，导致整个Job完成的很慢。</p>
<p>可以将count（distinct key）的方式，改为先group by 再count的方式，也就是将distinct换成group by。</p>
<p>这种优化可以增加reducer的个数，虽然会用多个Job完成，但是适合处理数据量大的情况。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原始：  <span class="keyword">select</span> count(<span class="keyword">distinct</span> id) <span class="keyword">from</span> <span class="keyword">table</span>;</span><br><span class="line"> </span><br><span class="line">优化后：<span class="keyword">select</span> count(id) <span class="keyword">from</span> (<span class="keyword">select</span> id <span class="keyword">from</span> <span class="keyword">table</span> <span class="keyword">group</span> <span class="keyword">by</span> id) a;</span><br></pre></td></tr></table></figure>

<h2 id="行列过滤（分区过滤，先where再join嵌套子查询）——谓词下推"><a href="#行列过滤（分区过滤，先where再join嵌套子查询）——谓词下推" class="headerlink" title="行列过滤（分区过滤，先where再join嵌套子查询）——谓词下推"></a>行列过滤（分区过滤，先where再join嵌套子查询）——谓词下推</h2><p>列处理：在select中，只拿需要的列，如果有分区，尽量使用分区字段查询（分区过滤），避免使用select *全表扫描select key from tablename where 分区字段 &#x3D; ‘~’</p>
<p>行处理：两表连接时，对一个表的数据先where过滤，再join（如果先join再过滤，过滤的数据量会很大），即嵌套子查询</p>
<p>在Hive中，可以通过将参数hive.optimize.ppd设置为true，启用谓词下推。与它对应的逻辑优化器是PredicatePushDown。该优化器就是将OperatorTree中的FilterOperator向上提</p>
<p>Hive中与列裁剪和分区裁剪优化相关的配置参数分别为：hive.optimize.cp和hive.optimize.pruner，默认都是true。</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">eg：join两张表，A表joinB表，要求是把B表中<span class="built_in">id</span>&lt;<span class="number">10</span>的过滤掉后，只查询联结表的<span class="built_in">id</span>列</span><br><span class="line">原始： select a.<span class="built_in">id</span> <span class="keyword">from</span> A a join B b <span class="keyword">on</span> a.<span class="built_in">id</span>=b.<span class="built_in">id</span> <span class="keyword">where</span> b.<span class="built_in">id</span>&lt;<span class="number">10</span></span><br><span class="line"> </span><br><span class="line">优化后：select a.<span class="built_in">id</span> <span class="keyword">from</span> A a join (select <span class="built_in">id</span> <span class="keyword">from</span> B <span class="keyword">where</span> <span class="built_in">id</span>&lt;<span class="number">10</span>) b <span class="keyword">on</span> a.<span class="built_in">id</span>=b.<span class="built_in">id</span></span><br></pre></td></tr></table></figure>

<h2 id="动态分区"><a href="#动态分区" class="headerlink" title="动态分区"></a>动态分区</h2><p>分区列是表的一个伪列，它对应HDFS的一个分区文件夹，并且分区列存在于表的最后。</p>
<p>如果不设定动态分区，往分区表中导入数据的方式如下：</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> 创建分区表</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu_par(id <span class="type">int</span>,<span class="type">name</span> string)</span><br><span class="line">partitioned <span class="keyword">by</span> (month string)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"> </span><br><span class="line"><span class="number">2.</span> 往分区中导入数据</span><br><span class="line"><span class="keyword">load</span> data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> stu_par <span class="keyword">partition</span>(month=<span class="string">&#x27;10&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p>如果设定动态分区，导入数据就不再需要指定分区字段了</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>. 设置为非严格模式（默认strict，表示必须指定至少一个分区为静态分区；nonstrict表示允许所有分区可使用动态分区）</span><br><span class="line"></span><br><span class="line">hive<span class="selector-class">.exec</span><span class="selector-class">.dynamic</span><span class="selector-class">.partition</span>.mode=nonstrict</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>. 默认配置</span><br><span class="line"></span><br><span class="line">（<span class="number">1</span>）开启动态分区功能（默认true，开启）</span><br><span class="line"></span><br><span class="line">hive<span class="selector-class">.exec</span><span class="selector-class">.dynamic</span>.partition=true</span><br><span class="line"></span><br><span class="line">（<span class="number">2</span>）在所有执行MR节点上，最大一共可以创建多少个动态分区，默认<span class="number">1000</span>个</span><br><span class="line"></span><br><span class="line">hive<span class="selector-class">.exec</span><span class="selector-class">.max</span><span class="selector-class">.dynamic</span>.partitions=<span class="number">1000</span></span><br><span class="line"></span><br><span class="line">（<span class="number">3</span>）在每个执行MR的节点上，最大可以创建多少个分区，默认值<span class="number">100</span></span><br><span class="line"></span><br><span class="line">eg：若源数据包含一年的数据，按照天数分区，day字段应该有<span class="number">365</span>个值，这里的默认值<span class="number">100</span>就应该修改为大于<span class="number">365</span>的数。</span><br><span class="line"></span><br><span class="line">hive<span class="selector-class">.exec</span><span class="selector-class">.max</span><span class="selector-class">.dynamic</span><span class="selector-class">.partitions</span>.pernode=<span class="number">100</span></span><br><span class="line"></span><br><span class="line">（<span class="number">4</span>）整个MR job中，最大可以创建多少个HDFS文件，默认<span class="number">100000</span></span><br><span class="line"></span><br><span class="line">hive<span class="selector-class">.exec</span><span class="selector-class">.max</span><span class="selector-class">.created</span>.files=<span class="number">100000</span></span><br></pre></td></tr></table></figure>

<p>操作 ：</p>
<figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">1. 创建分区表</span><br><span class="line">create table dept_par(id string,name string) partitioned by (location int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line"> </span><br><span class="line">2. 设置动态分区非严格模式</span><br><span class="line">set hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line"> </span><br><span class="line">3. 查看dept表</span><br><span class="line">+--------------+-------------+-----------+--+</span><br><span class="line">|<span class="string"> dept.deptno  </span>|<span class="string"> dept.dname  </span>|<span class="string"> dept.loc  </span>|</span><br><span class="line">+--------------+-------------+-----------+--+</span><br><span class="line">|<span class="string"> 10           </span>|<span class="string"> ACCOUNTING  </span>|<span class="string"> 1700      </span>|</span><br><span class="line">|<span class="string"> 20           </span>|<span class="string"> RESEARCH    </span>|<span class="string"> 1800      </span>|</span><br><span class="line">|<span class="string"> 30           </span>|<span class="string"> SALES       </span>|<span class="string"> 1900      </span>|</span><br><span class="line">|<span class="string"> 40           </span>|<span class="string"> OPERATIONS  </span>|<span class="string"> 1700      </span>|</span><br><span class="line">+--------------+-------------+-----------+--+</span><br><span class="line"> </span><br><span class="line">4. 分区表动态导入数据（并未指定分区字段的值）</span><br><span class="line">insert into table dept_par partition(location) select deptno,dname,loc from dept;</span><br><span class="line">...</span><br><span class="line">	Loading partition &#123;location=1900&#125;</span><br><span class="line">	Loading partition &#123;location=1800&#125;</span><br><span class="line">	Loading partition &#123;location=1700&#125;</span><br><span class="line">...</span><br><span class="line"> </span><br><span class="line">5. 查看分区表的分区情况</span><br><span class="line">hive (hive_db1)&gt; show partitions dept_par;</span><br><span class="line">OK</span><br><span class="line">partition</span><br><span class="line">location=1700</span><br><span class="line">location=1800</span><br><span class="line">location=1900</span><br><span class="line"> </span><br><span class="line">6. 查询分区表</span><br><span class="line">select <span class="symbol">*</span> from dept_par where location=&#x27;1700&#x27;;</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> dept_par.id  </span>|<span class="string"> dept_par.name  </span>|<span class="string"> dept_par.location  </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> 10           </span>|<span class="string"> ACCOUNTING     </span>|<span class="string"> 1700               </span>|</span><br><span class="line">|<span class="string"> 40           </span>|<span class="string"> OPERATIONS     </span>|<span class="string"> 1700               </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line"> </span><br><span class="line">select <span class="symbol">*</span> from dept_par where location=&#x27;1800&#x27;;</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> dept_par.id  </span>|<span class="string"> dept_par.name  </span>|<span class="string"> dept_par.location  </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> 20           </span>|<span class="string"> RESEARCH       </span>|<span class="string"> 1800               </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line"> </span><br><span class="line">select <span class="symbol">*</span> from dept_par where location=&#x27;1900&#x27;;</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> dept_par.id  </span>|<span class="string"> dept_par.name  </span>|<span class="string"> dept_par.location  </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br><span class="line">|<span class="string"> 30           </span>|<span class="string"> SALES          </span>|<span class="string"> 1900               </span>|</span><br><span class="line">+--------------+----------------+--------------------+--+</span><br></pre></td></tr></table></figure>

<p><strong>原理：</strong></p>
<p>将select的最后一列，认为是分区列（因为分区列在表的最后），将最后一列字段值相同的行，导入同一个分区中；</p>
<p>好处是避免了指定分区字段的值，直接动态的将值相同的行导入同一个分区中，加大效率。</p>
<p>ps：如果把deptno放在select最后一列，那么会生成四个分区</p>
<h2 id="分桶"><a href="#分桶" class="headerlink" title="分桶"></a>分桶</h2><p>适合对数据进行抽样查询的情况，clustered by 字段 into x buckets，将表数据以（字段hash值%分桶数）按照取模结果，对数据进行分桶，也就是随机分布成几块。</p>
<p>ps：分区列是伪列，需要指明字段类型；分桶列是实际列，不需要指明字段类型。</p>
<p>分桶前，需要设置属性set hive.enforce.bucketing &#x3D; true</p>
<h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><p>主要目的是提高hive查询效率，避免全表查询 select * from tablename where 分区字段 &#x3D; ‘~’</p>
<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><p>生产上namenode是两个是没有snn的，同样yarn的老大也是两个，是忘了防止一个老大突然挂掉，然后让下一个上位</p>
<p>控制整个老大的更换的就是zookeeper</p>
<p>hadoop ： 请求服务是不用关注所有节点的ip的，我们只用关注namenode的，但是当是两个namenode的时候（生产上），这个时候就会把两个namenode放在一起，形成一个namespace-》zookeeper实现</p>
<p>部署 ：</p>
<ul>
<li>单点</li>
<li>分布式</li>
<li>要求 ：部署的机器数量有要求 ，2n + 1 台机器</li>
</ul>
<p>主从架构 ：如果老大挂了，后面的老二就会上位</p>
<p>zookeeper版本有很多：但是对于我们现在能用就行 ： 3.8.0</p>
<p>部署 ：</p>
<p>有前置要求：具体查看官网 ：对系统有要求 ： jdk 1.8orlater</p>
<p>先把包解压 -》 软连接 -》 zookeeper -》 环境变量 -》 *cmd的是windows上运行的 -》 进入 conf目录 zoo.cfg（改名之后）</p>
<ul>
<li>单点：直接dataDir:改成自己的 - 》 启动</li>
<li>分布 ：dataDir ,三台机器的id，以及机器id的端口号</li>
</ul>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">bigdata3</span></span><br><span class="line"><span class="attribute">dataDir</span>=xxxxx</span><br><span class="line"><span class="attribute">server</span>.<span class="number">1</span>=bigdata3:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line"><span class="attribute">server</span>.<span class="number">2</span>=bigdata4:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line"><span class="attribute">server</span>.<span class="number">3</span>=bigdata5:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">myid</span> : 指定机器号 ： 在zookeeper的数据文件夹下创建一个myid，id号就是server点的数字</span><br></pre></td></tr></table></figure>

<p>然后启动zk ： 通过zkServer.sh start</p>
<p>分布式要每一台机器上都整</p>
<p>分布式：查看status之后会出现 follower 和leader 就是副手和老大</p>
<p>然后创建一个群起脚本</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt <span class="number">1</span> ];then</span><br><span class="line">echo <span class="string">&quot;start|stop|status&quot;</span></span><br><span class="line"><span class="keyword">exit</span> <span class="number">1</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> startzk()&#123;</span><br><span class="line"> nohup zkServer.sh start  &gt; ~<span class="regexp">/log/</span>zk.log <span class="number">1</span>&gt;&amp;<span class="number">2</span> &amp;</span><br><span class="line"> ssh bigdata4 <span class="string">&quot;zkServer.sh start&quot;</span></span><br><span class="line"> ssh bigdata5 <span class="string">&quot;zkServer.sh start&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> stopzk()&#123;</span><br><span class="line"> nohup zkServer.sh stop  &gt; ~<span class="regexp">/log/</span>zk.log <span class="number">1</span>&gt;&amp;<span class="number">2</span> &amp;</span><br><span class="line"> ssh bigdata4 <span class="string">&quot;zkServer.sh stop&quot;</span></span><br><span class="line"> ssh bigdata5 <span class="string">&quot;zkServer.sh stop&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> statuszk()&#123;</span><br><span class="line">echo <span class="string">&quot;-----------------bigdata3------------------&quot;</span></span><br><span class="line">jps | grep QuorumPeerMain</span><br><span class="line">echo <span class="string">&quot;-----------------bigdata4------------------&quot;</span></span><br><span class="line">ssh bigdata4 <span class="string">&quot;jps | grep QuorumPeerMain&quot;</span></span><br><span class="line">echo <span class="string">&quot;-----------------bigdata5------------------&quot;</span></span><br><span class="line">ssh bigdata5 <span class="string">&quot;jps | grep QuorumPeerMain&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">case <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line">    <span class="string">&quot;start&quot;</span>)</span><br><span class="line">    startzk</span><br><span class="line">    ;;</span><br><span class="line">    <span class="string">&quot;stop&quot;</span>)</span><br><span class="line">    stopzk</span><br><span class="line">    ;;</span><br><span class="line">    <span class="string">&quot;status&quot;</span>)</span><br><span class="line">    statuszk</span><br><span class="line">    ;;</span><br><span class="line">    *)</span><br><span class="line">    echo <span class="string">&quot;error input&quot;</span></span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="zk是干什么的？"><a href="#zk是干什么的？" class="headerlink" title="zk是干什么的？"></a>zk是干什么的？</h2><p>zk可以做监控，可以检查到机器是不是还活着，</p>
<p>管理配置信息的</p>
<h2 id="zk的数据模型"><a href="#zk的数据模型" class="headerlink" title="zk的数据模型"></a>zk的数据模型</h2><p>层级式的结构，一个树形的结构，和linux差不多</p>
<p>节点&#x2F;目录</p>
<ul>
<li>节点就是目录</li>
<li>节点保存数据的内容</li>
<li>zk里的所有的目录都可以叫节点</li>
</ul>
<p>通过命令 ：zkCli.sh 访问zk</p>
<p>然后我们可以对其数据进行操作 ：</p>
<ul>
<li><p>查看节点 ：ls name</p>
</li>
<li><p>查看节点内容 ： get name</p>
</li>
<li><p>节点</p>
<ul>
<li>临时节点 ：只在当前session有效 ，关闭当前会话，则就失效，不可以存放子节点</li>
<li>永久节点 ：永久存在的，可以存放子节点</li>
</ul>
</li>
<li><p>zk 每个节点都有自己的id，节点号，不会重复 ， 数据是存放在节点上的</p>
</li>
<li><p>数据不是很大的数据</p>
</li>
<li><p>仅仅是比较小的数据</p>
</li>
<li><p>如果存放的数据发生变更，数据版本号也会发生变更</p>
</li>
<li><p>创建节点 ： create : <code>create /dl2262 zihang</code></p>
</li>
<li><p>stat path :获取当前节点状态 ： <code>stat /dl2262</code></p>
</li>
<li><pre><code>cZxid = 0x300000002 id
ctime = Thu Dec 15 14:52:29 CST 2022
mZxid = 0x300000002
mtime = Thu Dec 15 14:52:29 CST 2022
pZxid = 0x300000002
cversion = 0 
dataVersion = 0 数据版本
aclVersion = 0 权限的版本
ephemeralOwner = 0x0 是不是临时节点 0x0 不是临时节点 其余就是临时节点
dataLength = 6 数据的长度：zihang就是6个字节
numChildren = 0 下面的子节点
</code></pre>
</li>
<li><p>create -e ：创建临时节点 ：<code>create -e /dl2262 zuan</code> 临时节点也有自己的过期时间，时间一过就会自动删除（重新启动客户端的时候）</p>
</li>
<li><p>顺序节点 ： create -s  默认会给节点后面加一个自增的序列： <code>create -s /dl2262/ziyuan</code></p>
</li>
<li><p>不可以创建深层文件夹的方式命令，如果使用zk的api则可以，或者java代码的方式</p>
</li>
<li><p>修改数据内容的 ： set :   <code>set [-s] [-v version] path data-&gt;set /dl2262 xxxx  </code></p>
<ul>
<li>数据版本 ： 如果数据版本不对应，就会报错的</li>
</ul>
</li>
<li><p>删除节点 ：delete ： <code>delete [-v version] path</code></p>
</li>
<li><p>如果版本不对还是要出错的</p>
</li>
<li><p>zk自带的监控 ， 监听器</p>
</li>
<li><p>命令中有-w的就是可以监听的</p>
</li>
<li><p>针对每一个节点都可以执行的，每个节点都有一个监听器，当每个节点发生变化，就会触发watch事件</p>
</li>
<li><p>但是zk的shell命令每次只能监听一次 ， zk的原生的api不行，但是curator 的可以一直监听</p>
</li>
<li><p>命令 stat -w nodenpath 就可以监听，或者get -w nodepath等</p>
</li>
<li><p>但是命令行的方式只能触发一次</p>
</li>
</ul>
<p>zk的四字命令</p>
<ul>
<li>zk要对外进行服务的</li>
<li>通过器对外的端口对其进行监控这个是对zk进行监控的</li>
<li>使用前提 ： 要编辑配置文件 ：在zoo.cng这个配置文件里添加 <code>4lw.commands.whitelist=*</code></li>
<li>stat ：可以列出自己的服务端和客户端的一些详细信息</li>
<li>使用方式 ： 直接在linux命令行操作 ， <code>echo stat | telnet localhost 2181</code></li>
<li>ruok : are you ok ? 就是检测服务的功能启动了吗</li>
<li>dump ：列出最近的会话和临时节点的详细信息</li>
<li>conf ： 打印机器的配置</li>
</ul>
<p>或者可以使用Prometheus框架监控</p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/12/k8s%E7%9A%84%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Sealos/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/12/k8s%E7%9A%84%E9%83%A8%E7%BD%B2%E5%B7%A5%E5%85%B7Sealos/" class="post-title-link" itemprop="url">Sealos</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2022-12-12 12:35:07 / 修改时间：13:41:14" itemprop="dateCreated datePublished" datetime="2022-12-12T12:35:07+08:00">2022-12-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BA%91%E5%8E%9F%E7%94%9F%EF%BC%88%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">云原生（哔哩哔哩）</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>630</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Sealos"><a href="#Sealos" class="headerlink" title="Sealos"></a>Sealos</h1><p>是部署工具 ， 用go语言开发的干净且清凉的k8s的部署工具</p>
<h1 id="Sealos的优势"><a href="#Sealos的优势" class="headerlink" title="Sealos的优势"></a>Sealos的优势</h1><p>他的证书有效时间是100年</p>
<p>不依赖ansible haproxy keepalived 是零依赖</p>
<p>离线安装</p>
<p>kubelet其默认通过ipvs实现localLB，占用资源少稳定可靠</p>
<p>更容易在集群节点上增加&#x2F;删除管理</p>
<p>上千用户使用，在阿里云oss上有，不用担心网速的问题</p>
<p>dashboard ingress prometheus 等 APP 同样支持离线打包安装</p>
<p>当不超过三个独立集群，都是免费的，超过则要订阅服务了</p>
<h1 id="rancher是目前企业中认知度最好的-：-周六周日补上"><a href="#rancher是目前企业中认知度最好的-：-周六周日补上" class="headerlink" title="rancher是目前企业中认知度最好的 ： 周六周日补上"></a>rancher是目前企业中认知度最好的 ： 周六周日补上</h1><h1 id="Sealos常用的参数"><a href="#Sealos常用的参数" class="headerlink" title="Sealos常用的参数"></a>Sealos常用的参数</h1><p>–master master的节点服务器地址</p>
<p>–node node节点服务器地址列表</p>
<p>–user 服务器 SSH 用户名</p>
<p>–password 服务器 SSH 用户的密码</p>
<p>–pkg-url 离线包所在的位置，可以是本地，也可以是http</p>
<p>–version 指定要部署的k8s的版本</p>
<p> –pk 指定 SSH 私钥所在的位置 默认是在&#x2F;root&#x2F;.ssh&#x2F;id_rsa</p>
<p>–podcidr 自定义 pod网段</p>
<p>–svccidr 参数指定clusterip网段</p>
<h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>需要纯净的linux ： centos7 对于centos8 需要调试很多的</p>
<p>或者是ubantu</p>
<p>尽量用新版本的Sealos</p>
<p>注意 ： 服务器时间必须同步</p>
<p>主机名字不可以重复</p>
<p>master的cpu要2个以上</p>
<p>cni组件选择cilium 时的内核版本不低于5.4</p>
<p>k8s一般用回退两个版本</p>
<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>47.25</p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/12/12-12/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/12/12-12/" class="post-title-link" itemprop="url">flume</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-12 08:49:24" itemprop="dateCreated datePublished" datetime="2022-12-12T08:49:24+08:00">2022-12-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-15 16:21:02" itemprop="dateModified" datetime="2022-12-15T16:21:02+08:00">2022-12-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%BF%97/" itemprop="url" rel="index"><span itemprop="name">日志</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>54k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>49 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <p>xxl：任务调度的时候</p>
<ul>
<li>设置一个xxl job 完成任务 ，解耦不好，就是代码中常规定义的高内聚 ，低偶合</li>
<li>设置多个xxl job，可以解决上述的问题 ， 但是时间不好把握 ， 就是第一个任务和第二个任务的交界处，就是如何判断第一个任务执行完了，如何开启第二个，xxl中有可以控制这个的功能</li>
<li>在任务编辑页面中，点击添加子任务id，就可以了</li>
</ul>
<p>然后只用执行父任务就好</p>
<p>但是不太方便</p>
<p>任务调度框架 ： 推荐dolphinscheduler  官网  ：<code>dolphinscheduler.apache.org</code></p>
<p>周六周日学会</p>
<p>首选dolphinscheduler</p>
<p>airflow 也是比较擅长制作dag（有向无关图）的一个框架官网 ： <code>airflow.apache.org</code></p>
<p>他的dag能力非常好用，但是是要求用python使用的，同样周六周日学会</p>
<p>或者自己开发&#x3D;》java团队</p>
<p>sqoop是要在yarn上申请资源，然后进行map阶段，它不走reduce阶段，它在yarn上申请资源，就是消耗时间的最大问题</p>
<h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><p>主要是收集我们的日志数据的</p>
<p>数据采集&#x2F;数据收集</p>
<p>数据采集：把数据采集到服务器上</p>
<p>数据收集：把数据移动到指定位置</p>
<p>上述是老师之前公司的定义</p>
<p>flume的架构地位 ： 一般采集日志数据，并不用我们做，是java团队要做的</p>
<p>日志数据 -》flume-》hdfs</p>
<p>业务数据 通过sqoop存到hdfs上</p>
<p>数据处理的两种方式 ： 离线 ，实时</p>
<p>上述所处的数据处理方式是离线处理，</p>
<p>实时处理是来一个数据，就处理一个</p>
<p>离线处理是把一定时间内的数据放到一起来进行处理也叫p处理</p>
<p>实时处理的架构线和离线处理的差不多，因为flume采集数据就是实时的</p>
<p>实时 ： 日志数据 -》 flume -》 kafka -》 实时处理框架</p>
<p>离线 ： 日志数据 -》 flume -》 hdfs -》 hive</p>
<p>但是现在有一种框架如下 ：</p>
<p>日志数据 -》 flume -》 kafka</p>
<ul>
<li>-》实时</li>
<li>-》flume -》hdfs -》离线</li>
</ul>
<p>并不意味着下面的架构比上面两种好，架构没有好与坏，只有合适不合适</p>
<p>因为下面意味着要多加一层维护，消耗人力以及物资</p>
<p>官网 ： <code>flume.apache.org</code></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>官方介绍 ：</p>
<p>收集，聚合，移动日志文件 <code>Flume is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.</code></p>
<p>flume ：采集数据是实时采集的而且支持恢复机制 <code> It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms.</code></p>
<p>flume组件</p>
<ul>
<li>source ：采集数据</li>
<li>channel ： 管道，存储采集过来的数据</li>
<li>sink ： 移动数据</li>
</ul>
<p>flume ： 使用场景</p>
<p>采集数据日志-》 hdfs上</p>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><p>以后操作flume，就是编写agent里面的配置</p>
<p>agent ： 包括上面的那三个组件</p>
<h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>我们部署的化用1.9版本</p>
<p>第一步 ： 先解压 到app下</p>
<p>第二步 ： 软连接 + 环境变量</p>
<p>第三步 ： 配置flume，修改flume的env.sh文件，把java_home加上</p>
<p>第四步 ： 使用flume ： 配置agent 配置文件</p>
<p>flume user guide ：基本使用</p>
<p>flume develop guide ：二次开发</p>
<p>常用的 source</p>
<ul>
<li>avro 序列化框架的source ****</li>
<li>exec 日志文件</li>
<li>spooling dir 日志文件</li>
<li>kafka Source</li>
<li>Netcat Source 通过端口采集数据</li>
<li>taildir Source 日志文件 ****</li>
<li>等 ，可以自己开发</li>
<li>其余都是两个星</li>
</ul>
<p>常用的channel</p>
<ul>
<li>Memory ****</li>
<li>File  ****</li>
<li>JDBC *</li>
<li>kafka *</li>
<li>Custom ： 用户开发 *</li>
<li>等</li>
</ul>
<p>常用的sink</p>
<ul>
<li>hdfs ****</li>
<li>hive ****</li>
<li>avro ****</li>
<li>logger 控制台，打印 **</li>
<li>HBase *</li>
<li>kafka *</li>
<li>http *</li>
<li>custom *</li>
<li>等</li>
</ul>
<p>如何配置agent</p>
<p>用什么查什么 ： 不用记</p>
<p>需求  ：从指定端口的地方获取数据并输出到控制套</p>
<p>分析  ：</p>
<p>source ：Netcat</p>
<p>channel ： memory</p>
<p>sink ： logger</p>
<p>然后编写一个flume的文件，文件内容如下</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>event  ：就是我们的flume的一条数据，代表数据是通过这三个阶段的一条数据</p>
<p>关于source的参数，下列以netcat为例</p>
<figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">Property</span> Name	<span class="keyword">Default</span>	Description</span><br><span class="line">channels	–	 </span><br><span class="line"><span class="keyword">type</span>	–	The <span class="keyword">component</span> <span class="keyword">type</span> name, needs <span class="keyword">to</span> be netcat</span><br><span class="line">bind	–	Host name <span class="keyword">or</span> IP address <span class="keyword">to</span> bind <span class="keyword">to</span></span><br><span class="line"><span class="keyword">port</span>	–	<span class="keyword">Port</span> # <span class="keyword">to</span> bind <span class="keyword">to</span></span><br><span class="line">max-<span class="literal">line</span>-length	<span class="number">512</span>	Max <span class="literal">line</span> length per event <span class="keyword">body</span> (<span class="keyword">in</span> bytes)</span><br><span class="line">ack-every-event	<span class="literal">true</span>	Respond <span class="keyword">with</span> an “OK” <span class="keyword">for</span> every event received</span><br><span class="line">selector.<span class="keyword">type</span>	replicating	replicating <span class="keyword">or</span> multiplexing</span><br><span class="line">selector.*	 	Depends <span class="keyword">on</span> the selector.<span class="keyword">type</span> value</span><br><span class="line">interceptors	–	Space-separated list <span class="keyword">of</span> interceptors</span><br><span class="line">interceptors.*	 	 </span><br></pre></td></tr></table></figure>

<p>关于channel参数</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Property <span class="type">Name</span>	<span class="keyword">Default</span>	Description</span><br><span class="line"><span class="keyword">type</span>	–	The component <span class="keyword">type</span> <span class="type">name</span>, needs <span class="keyword">to</span> be memory</span><br><span class="line">capacity	<span class="number">100</span>	The maximum number <span class="keyword">of</span> events stored <span class="keyword">in</span> the channel</span><br><span class="line">transactionCapacity	<span class="number">100</span>	The maximum number <span class="keyword">of</span> events the channel will take <span class="keyword">from</span> a source <span class="keyword">or</span> give <span class="keyword">to</span> a sink per <span class="keyword">transaction</span></span><br><span class="line">keep-alive	<span class="number">3</span>	Timeout <span class="keyword">in</span> seconds <span class="keyword">for</span> adding <span class="keyword">or</span> removing an event</span><br><span class="line">byteCapacityBufferPercentage	<span class="number">20</span>	Defines the percent <span class="keyword">of</span> buffer <span class="keyword">between</span> byteCapacity <span class="keyword">and</span> the estimated total size <span class="keyword">of</span> <span class="keyword">all</span> events <span class="keyword">in</span> the channel, <span class="keyword">to</span> account <span class="keyword">for</span> data <span class="keyword">in</span> headers. See below.</span><br><span class="line">byteCapacity	see description	Maximum total bytes <span class="keyword">of</span> memory allowed <span class="keyword">as</span> a sum <span class="keyword">of</span> <span class="keyword">all</span> events <span class="keyword">in</span> this channel. The implementation <span class="keyword">only</span> counts the Event body, which <span class="keyword">is</span> the reason <span class="keyword">for</span> providing the byteCapacityBufferPercentage <span class="keyword">configuration</span> parameter <span class="keyword">as</span> well. Defaults <span class="keyword">to</span> a computed <span class="keyword">value</span> equal <span class="keyword">to</span> <span class="number">80</span>% <span class="keyword">of</span> the maximum memory available <span class="keyword">to</span> the JVM (i.e. <span class="number">80</span>% <span class="keyword">of</span> the -Xmx <span class="keyword">value</span> passed <span class="keyword">on</span> the command <span class="type">line</span>). Note that <span class="keyword">if</span> you have multiple memory channels <span class="keyword">on</span> a single JVM, <span class="keyword">and</span> they happen <span class="keyword">to</span> hold the same physical events (i.e. <span class="keyword">if</span> you are <span class="keyword">using</span> a replicating channel selector <span class="keyword">from</span> a single source) <span class="keyword">then</span> those event sizes may be <span class="type">double</span>-counted <span class="keyword">for</span> channel byteCapacity purposes. Setting this <span class="keyword">value</span> <span class="keyword">to</span> <span class="number">0</span> will cause this <span class="keyword">value</span> <span class="keyword">to</span> fall back <span class="keyword">to</span> a hard <span class="type">internal</span> <span class="keyword">limit</span> <span class="keyword">of</span> about <span class="number">200</span> GB.</span><br></pre></td></tr></table></figure>

<p>关于sink</p>
<figure class="highlight delphi"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">Property</span> <span class="keyword">Name</span>	<span class="keyword">Default</span>	Description</span><br><span class="line">channel	–	 </span><br><span class="line"><span class="keyword">type</span>	–	The component <span class="keyword">type</span> <span class="keyword">name</span>, needs <span class="keyword">to</span> be logger</span><br><span class="line">maxBytesToLog	<span class="number">16</span>	Maximum number <span class="keyword">of</span> bytes <span class="keyword">of</span> the Event body <span class="keyword">to</span> log</span><br></pre></td></tr></table></figure>

<p>然后启动我们的flume</p>
<p>执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p>
<p>然后执行telent localhost 44444</p>
<p>往里面发送内容，在我们启动flume的session就会发现内容</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">53</span>,<span class="number">172</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">31</span> <span class="number">0</span>D                                           <span class="number">1</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">54</span>,<span class="number">427</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">32</span> <span class="number">0</span>D                                           <span class="number">2</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">54</span>,<span class="number">877</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">33</span> <span class="number">0</span>D                                           <span class="number">3</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">55</span>,<span class="number">237</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">34</span> <span class="number">0</span>D                                           <span class="number">4</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">55</span>,<span class="number">565</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">35</span> <span class="number">0</span>D                                           <span class="number">5</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">55</span>,<span class="number">891</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">36</span> <span class="number">0</span>D                                           <span class="number">6</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">56</span>,<span class="number">238</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">37</span> <span class="number">0</span>D                                           <span class="number">7</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">56</span>,<span class="number">609</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">38</span> <span class="number">0</span>D                                           <span class="number">8</span>. &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">11</span>:<span class="number">57</span>,<span class="number">272</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">39</span> <span class="number">0</span>D                                           <span class="number">9</span>. &#125;</span><br></pre></td></tr></table></figure>

<p>如上 ：</p>
<p>生产上常见的</p>
<ul>
<li>采集log文件到hdfs上</li>
<li>采集log文件到hive</li>
<li>待机log文件到kafka里</li>
<li>采集kafka数据到hdfs</li>
<li>采集kafka数据到hive</li>
<li>采集数据到下一个agent里</li>
</ul>
<p>source ：</p>
<ul>
<li>netcat ： 采集端口数据 ： 学习测试</li>
<li>日志文件</li>
<li>kafka</li>
<li>agent</li>
</ul>
<p>采集日志文件</p>
<ul>
<li>exec</li>
<li>spooldir</li>
<li>taildir</li>
</ul>
<p>采集数据文件到控制台</p>
<ul>
<li>source ： exec</li>
<li>channel  ： memory</li>
<li>sink ： logger</li>
</ul>
<h1 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h1><p>编写agent</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = exec</span><br><span class="line"><span class="attr">a1.sources.r1.command</span> = tail -F /home/hadoop/data/loger.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>然后执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p>
<p>结果如下 ：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">39</span>:<span class="number">25</span>,<span class="number">755</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">31</span>                                              <span class="number">1</span> &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">39</span>:<span class="number">55</span>,<span class="number">761</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">61</span>                                     aaaa &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">40</span>:<span class="number">01</span>,<span class="number">909</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">61</span>                                     aaaa &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">40</span>:<span class="number">10</span>,<span class="number">910</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">73</span> <span class="number">73</span>                               aaaass &#125;</span><br><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">12</span> <span class="number">14</span>:<span class="number">44</span>:<span class="number">40</span>,<span class="number">961</span> (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.<span class="built_in">process</span>(LoggerSink.java:<span class="number">95</span>)] Event: &#123; headers:&#123;&#125; <span class="selector-tag">body</span>: <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">61</span> <span class="number">73</span> <span class="number">73</span> <span class="number">64</span> <span class="number">73</span> <span class="number">61</span> <span class="number">61</span> <span class="number">64</span> <span class="number">73</span>             aaaassdsaads &#125;</span><br></pre></td></tr></table></figure>

<p>上面的body里的东西是ascII码值的16进制</p>
<p>exec 的方式采集数据的时候，如果停掉flume，然后重新启动的时候，还会再次把文件里的数据再采集一次，造成数据双倍，能用，但是不建议</p>
<h1 id="spoolingdir"><a href="#spoolingdir" class="headerlink" title="spoolingdir"></a>spoolingdir</h1><p>接下来spooldir的采集文件夹下的文件</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = spooldir</span><br><span class="line"><span class="attr">a1.sources.r1.spoolDir</span> = 数据文件夹</span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>然后执行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p>
<p>被采集过的文件会被打上标记，会重命名文件命名为xxx.completed</p>
<p>然后就不会再次采集到这个文件，哪怕是关闭之后重新启动</p>
<p>而且往已经采集的文件下再次加入文件内容的时候，flume会被重新启动，且不能采集到新加的内容，而且文件名字不可以重复，如果重复，flume会挂掉，生产上不怎么使用</p>
<h1 id="taildir"><a href="#taildir" class="headerlink" title="taildir"></a>taildir</h1><p>接下来是taildir ：既可以采集文件夹，也可以采集单个文件，且有断点续传的作用</p>
<p>但是它并不能运行在windows上</p>
<p>编写agent</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f1.headerKey1</span> = value1</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey1</span> = value2</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="number">2</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">a1.sources.ri.maxBatchCount</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>然后运行 <code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p>
<p>它可以实时性的采集数据，是生产上重点，一般都用它，在flume里模糊匹配的语法要加个点在可以</p>
<p>断点续传的文件，a1.sources.r1.positionFile &#x3D; &#x2F;var&#x2F;log&#x2F;flume&#x2F;taildir_position.json</p>
<p>可以自己定义，或者是默认，默认是在~&#x2F;.flume&#x2F;taildir_position.json</p>
<h1 id="Sink-：hdfs"><a href="#Sink-：hdfs" class="headerlink" title="Sink ：hdfs"></a>Sink ：hdfs</h1><p>指定到hdfs上</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f1.headerKey1</span> = value1</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey1</span> = value2</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="number">2</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">a1.sources.ri.maxBatchCount</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = hdfs</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = hdfs://bigdata3:<span class="number">9000</span>/data</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>flume存储的数据才hdfs山观察看不了，因为其默认的数据格式不对</p>
<p>更改</p>
<ul>
<li>hdfs.filetype DataStream</li>
<li>hdfs.writeFormat : Text</li>
</ul>
<p>如下</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/try.txt</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f1.headerKey1</span> = value1</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f2</span> = /home/hadoop/data/flumetestdata/.*.log</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey1</span> = value2</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f2.headerKey2</span> = value2-<span class="number">2</span></span><br><span class="line"><span class="attr">a1.sources.r1.fileHeader</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">a1.sources.ri.maxBatchCount</span> = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = hdfs</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = hdfs://bigdata3:<span class="number">9000</span>/flume/events/%Y-%m-%d</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.writeFormat</span> = Text</span><br><span class="line"><span class="comment"># 控制小文件的参数</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="number">134217728</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="number">21600</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 控制大文件的滚动</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.round</span> = <span class="literal">true</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundUnit</span> = minute</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="number">1200</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="number">21</span></span><br><span class="line"><span class="comment"># 修改文件前缀和后缀</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = events</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileSuffix</span> = .log</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">5000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>执行 ：<code>flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file /home/hadoop/data/flumeexample.txt -Dflume.root.logger=info,console --name a1</code></p>
<p>采集的时候要注意：</p>
<p>因为采集数据会造成小文件问题就是当flume在采集的时候，如果文件一直发生变化的时候，flume可能会造成有多个小文件</p>
<p>可以通过增加参数进行设置</p>
<ul>
<li>按照条数进行滚动：就是生成下一个文件</li>
<li>按照时间进行滚动：就是生成下一个文件</li>
<li>hdfs.round &#x3D;&gt; 文件滚动的开关</li>
<li>hdfs.batchSize &#x3D;&gt; 按照条目数滚动，一般不会用</li>
<li>hdfs.roundUnit &#x3D;&gt; 按照时间滚动</li>
<li>hdfs.roundValue &#x3D;&gt; 时间滚动的具体值</li>
<li>文件进行滚动，是针对文件来说的，计算说当一个滚动的时候其余的文件滚动会重置</li>
</ul>
<h3 id="上面的对小文件的时候不好用，下面是一定好用的"><a href="#上面的对小文件的时候不好用，下面是一定好用的" class="headerlink" title="上面的对小文件的时候不好用，下面是一定好用的"></a>上面的对小文件的时候不好用，下面是一定好用的</h3><ul>
<li>hdfs.rollSize &#x3D;&gt; 按照大小进行滚动 默认是字节</li>
<li>hdfs.rollInterval &#x3D;&gt;按照时间进行滚动，秒为单位</li>
<li>hdfs.rollCount &#x3D;&gt; 文件里存的数据条数进行滚动</li>
</ul>
<h3 id="更改文件前缀和后缀"><a href="#更改文件前缀和后缀" class="headerlink" title="更改文件前缀和后缀"></a>更改文件前缀和后缀</h3><ul>
<li>hdfs.filePrefix : 文件前缀</li>
<li>hdfs.fileSuffix ：文件后缀</li>
<li>可以在path后面的问价夹地方放上时间戳</li>
<li>然后文件夹会自动生成 <code>a1.sinks.k1.hdfs.path = /flume/events/%Y-%m-%d/%H%M/%S </code></li>
<li><code>文件夹如下 ：/flume/events/2012-06-12/1150/00 </code></li>
<li>进行上述更改之后，我们要再次添加上 <code>hdfs.useLocalTimeStamp = true</code></li>
<li>这样之后相当于数据分组是用机器的时间，而不是数据本身的时间</li>
</ul>
<h3 id="event"><a href="#event" class="headerlink" title="event"></a>event</h3><ul>
<li>由两部分组成</li>
<li>headers ： 描述信息 ，但是一般的时候，这个里面是空的 ， 如果path设置成上述的靠时间戳，则这里不能为空，或者用本地时间代替</li>
<li>body ： 实实在在的数据 ：8进制的ASCII码值</li>
</ul>
<h3 id="业界问题"><a href="#业界问题" class="headerlink" title="业界问题"></a>业界问题</h3><ul>
<li>数据延迟的问题，对于数据假如在，23.58分采集，而flume有延迟，两分钟后才同步过来，就会出现数据本身的时间（采集时间）和本机local时间不一样，然后会影响到hdfs上文件夹的目录的存储</li>
<li>解决方法  ： log -》 flume -》 hive</li>
<li>定义udf ：函数 ： 保证正确的数据重新落盘到正确的分区 ： 数据清理</li>
<li>从flume 源头解决： 用文件创建的时间，就是在header里设置时间<ul>
<li>要二次开发才可以解决</li>
</ul>
</li>
</ul>
<h2 id="同步到hive中"><a href="#同步到hive中" class="headerlink" title="同步到hive中"></a>同步到hive中</h2><p>我们可以通过同步到hdfs中然后同步到ihive上，因为hive的数据在hdfs上</p>
<h3 id="普通表："><a href="#普通表：" class="headerlink" title="普通表："></a>普通表：</h3><p>对于普通表我们之间把文件放到hive的存储路径下，只要分隔符对，就可以了</p>
<h3 id="分区表："><a href="#分区表：" class="headerlink" title="分区表："></a>分区表：</h3><p>对于已经有的分区，之间把数据往分区文件夹里存储就好</p>
<p>对于没有的分区，把数据按照文件夹传输上去之后，我们还要在hive的源数据库里添加分区</p>
<p>通过：<code>alter table emp_partition add partition(deptno=10);</code></p>
<p>然后建完分区，它就会显示数据了</p>
<h1 id="Sink-hive"><a href="#Sink-hive" class="headerlink" title="Sink:hive"></a>Sink:hive</h1><p>以下是官方提供的hive的flume参数</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = hive // 类型</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1 </span><br><span class="line"><span class="attr">a1.sinks.k1.hive.metastore</span> = thrift://bigdata3:<span class="number">9083</span> //元数据库</span><br><span class="line"><span class="attr">a1.sinks.k1.hive.database</span> = logsdb 数据库</span><br><span class="line"><span class="attr">a1.sinks.k1.hive.table</span> = weblogs 表</span><br><span class="line"><span class="attr">a1.sinks.k1.hive.partition</span> = asia,%&#123;country&#125;,%Y-%m-%d-%H-%M 分区字段</span><br><span class="line"><span class="attr">a1.sinks.k1.useLocalTimeStamp</span> = <span class="literal">false</span> 是不是使用本地时间戳</span><br><span class="line"><span class="attr">a1.sinks.k1.round</span> = <span class="literal">true</span> </span><br><span class="line"><span class="attr">a1.sinks.k1.roundValue</span> = <span class="number">10</span></span><br><span class="line"><span class="attr">a1.sinks.k1.roundUnit</span> = minute </span><br><span class="line"><span class="attr">a1.sinks.k1.serializer</span> = DELIMITED   负责解析事件中的字段并将它们映射到hive表中的列 </span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.delimiter</span> = <span class="string">&quot;\t&quot;</span> 传入数据的分隔符（每个字段之间的）</span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.serdeSeparator</span> = <span class="string">&#x27;\t&#x27;</span> 输出字段分隔符,单引号括起来，例如<span class="string">&#x27;\t&#x27;</span></span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.fieldnames</span> =id,,msg 参数名字（表的）</span><br></pre></td></tr></table></figure>

<p>然后我们自己写一个</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = /home/hadoop/data/flumepostion/taildir_position.json</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = f1</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = /home/hadoop/data/emp_202211301118.csv</span><br><span class="line"><span class="attr">a1.sources.r1.headers.f1.headerKey1</span> = value1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = hive</span><br><span class="line"><span class="attr">a1.sinks.k1.serializer</span> = DELIMITED</span><br><span class="line"><span class="attr">a1.sinks.k1.hive.metastore</span> = thrift://bigdata3:<span class="number">9083</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hive.database</span> = bigdata_hive3</span><br><span class="line"><span class="attr">a1.sinks.k1.hive.table</span> = emp22</span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.delimiter</span> = <span class="string">&quot;,&quot;</span></span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.serdeSeparator</span> = <span class="string">&#x27;,&#x27;</span></span><br><span class="line"><span class="attr">a1.sinks.k1.serializer.fieldnames</span> =emp<span class="literal">no</span>,ename,job,mgr,hiredate,sal,comm,dept<span class="literal">no</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>按照上述操作之后会报错，原因 ： 缺少依赖包</p>
<p>报错信息如下：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2022</span>-<span class="number">12</span>-<span class="number">13</span> <span class="number">11</span>:<span class="number">19</span>:<span class="number">42</span>,<span class="number">806</span> (conf-file-poller-<span class="number">0</span>) <span class="selector-attr">[ERROR - org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run(PollingPropertiesFileConfigurationProvider.java:150)]</span> Failed to start agent because dependencies were not found <span class="keyword">in</span> classpath. Error follows.</span><br><span class="line">java<span class="selector-class">.lang</span><span class="selector-class">.NoClassDefFoundError</span>: org/apache/hive/hcatalog/streaming/RecordWriter</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.createSerializer</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">220</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.configure</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">203</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.conf</span><span class="selector-class">.Configurables</span><span class="selector-class">.configure</span>(Configurables<span class="selector-class">.java</span>:<span class="number">41</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.node</span><span class="selector-class">.AbstractConfigurationProvider</span><span class="selector-class">.loadSinks</span>(AbstractConfigurationProvider<span class="selector-class">.java</span>:<span class="number">453</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.node</span><span class="selector-class">.AbstractConfigurationProvider</span><span class="selector-class">.getConfiguration</span>(AbstractConfigurationProvider<span class="selector-class">.java</span>:<span class="number">106</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.node</span>.PollingPropertiesFileConfigurationProvider<span class="variable">$FileWatcherRunnable</span><span class="selector-class">.run</span>(PollingPropertiesFileConfigurationProvider<span class="selector-class">.java</span>:<span class="number">145</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span>.Executors<span class="variable">$RunnableAdapter</span><span class="selector-class">.call</span>(Executors<span class="selector-class">.java</span>:<span class="number">511</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.FutureTask</span><span class="selector-class">.runAndReset</span>(FutureTask<span class="selector-class">.java</span>:<span class="number">308</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span>.ScheduledThreadPoolExecutor<span class="variable">$ScheduledFutureTask</span>.access$<span class="number">301</span>(ScheduledThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">180</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span>.ScheduledThreadPoolExecutor<span class="variable">$ScheduledFutureTask</span><span class="selector-class">.run</span>(ScheduledThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">294</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span><span class="selector-class">.ThreadPoolExecutor</span><span class="selector-class">.runWorker</span>(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">1142</span>)</span><br><span class="line">	at java<span class="selector-class">.util</span><span class="selector-class">.concurrent</span>.ThreadPoolExecutor<span class="variable">$Worker</span><span class="selector-class">.run</span>(ThreadPoolExecutor<span class="selector-class">.java</span>:<span class="number">617</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">745</span>)</span><br><span class="line">Caused by: java<span class="selector-class">.lang</span><span class="selector-class">.ClassNotFoundException</span>: org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.RecordWriter</span></span><br><span class="line">	at java<span class="selector-class">.net</span><span class="selector-class">.URLClassLoader</span><span class="selector-class">.findClass</span>(URLClassLoader<span class="selector-class">.java</span>:<span class="number">381</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.ClassLoader</span><span class="selector-class">.loadClass</span>(ClassLoader<span class="selector-class">.java</span>:<span class="number">424</span>)</span><br><span class="line">	at sun<span class="selector-class">.misc</span>.Launcher<span class="variable">$AppClassLoader</span><span class="selector-class">.loadClass</span>(Launcher<span class="selector-class">.java</span>:<span class="number">331</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.ClassLoader</span><span class="selector-class">.loadClass</span>(ClassLoader<span class="selector-class">.java</span>:<span class="number">357</span>)</span><br><span class="line">	... <span class="number">13</span> more</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>而且其中的metastore要进行启动</p>
<h3 id="启动metastore"><a href="#启动metastore" class="headerlink" title="启动metastore"></a>启动metastore</h3><p><code>hive --service metastore</code></p>
<p>然后才能进去</p>
<p>上述错误是因为我们缺少依赖造成的是 <code>hive-hcatalog-streaming.jar</code></p>
<p>我们可以通过idea的maven项目进行下载</p>
<p>下载之后导入到我们的flume&#x2F;lib目录下，就可以运行了</p>
<p>然后还可能遇见以下的问题：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">22</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">11</span>:<span class="number">09</span>:<span class="number">26</span> WARN hive<span class="selector-class">.HiveSink</span>: k2 : Failed connecting to EndPoint &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span>.HiveWriter<span class="variable">$ConnectException</span>: Failed connecting to EndPoint &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveWriter</span>.&lt;init&gt;(HiveWriter<span class="selector-class">.java</span>:<span class="number">99</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.getOrCreateWriter</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">346</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.drainOneBatch</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">297</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.process</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">254</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.DefaultSinkProcessor</span><span class="selector-class">.process</span>(DefaultSinkProcessor<span class="selector-class">.java</span>:<span class="number">67</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span>.SinkRunner<span class="variable">$PollingRunner</span><span class="selector-class">.run</span>(SinkRunner<span class="selector-class">.java</span>:<span class="number">145</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">748</span>)</span><br><span class="line">Caused by: org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.StreamingException</span>: Cannot stream to <span class="selector-tag">table</span> that has not been bucketed : &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.AbstractRecordWriter</span>.&lt;init&gt;(AbstractRecordWriter<span class="selector-class">.java</span>:<span class="number">69</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.DelimitedInputWriter</span>.&lt;init&gt;(DelimitedInputWriter<span class="selector-class">.java</span>:<span class="number">115</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveDelimitedTextSerializer</span><span class="selector-class">.createRecordWriter</span>(HiveDelimitedTextSerializer<span class="selector-class">.java</span>:<span class="number">66</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveWriter</span>.&lt;init&gt;(HiveWriter<span class="selector-class">.java</span>:<span class="number">89</span>)</span><br><span class="line">	... <span class="number">6</span> more</span><br><span class="line"><span class="number">22</span>/<span class="number">03</span>/<span class="number">24</span> <span class="number">11</span>:<span class="number">09</span>:<span class="number">26</span> ERROR flume<span class="selector-class">.SinkRunner</span>: Unable to deliver event. Exception follows.</span><br><span class="line">org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.EventDeliveryException</span>: org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span>.HiveWriter<span class="variable">$ConnectException</span>: Failed connecting to EndPoint &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.process</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">269</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.DefaultSinkProcessor</span><span class="selector-class">.process</span>(DefaultSinkProcessor<span class="selector-class">.java</span>:<span class="number">67</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span>.SinkRunner<span class="variable">$PollingRunner</span><span class="selector-class">.run</span>(SinkRunner<span class="selector-class">.java</span>:<span class="number">145</span>)</span><br><span class="line">	at java<span class="selector-class">.lang</span><span class="selector-class">.Thread</span><span class="selector-class">.run</span>(Thread<span class="selector-class">.java</span>:<span class="number">748</span>)</span><br><span class="line">Caused by: org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span>.HiveWriter<span class="variable">$ConnectException</span>: Failed connecting to EndPoint &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveWriter</span>.&lt;init&gt;(HiveWriter<span class="selector-class">.java</span>:<span class="number">99</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.getOrCreateWriter</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">346</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.drainOneBatch</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">297</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveSink</span><span class="selector-class">.process</span>(HiveSink<span class="selector-class">.java</span>:<span class="number">254</span>)</span><br><span class="line">	... <span class="number">3</span> more</span><br><span class="line">Caused by: org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.StreamingException</span>: Cannot stream to <span class="selector-tag">table</span> that has not been bucketed : &#123;metaStoreUri=<span class="string">&#x27;thrift://cdh-1:9083&#x27;</span>, database=<span class="string">&#x27;ods&#x27;</span>, table=<span class="string">&#x27;ods_flume_log&#x27;</span>, partitionVals=<span class="selector-attr">[20220324]</span> &#125;</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.AbstractRecordWriter</span>.&lt;init&gt;(AbstractRecordWriter<span class="selector-class">.java</span>:<span class="number">69</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.hive</span><span class="selector-class">.hcatalog</span><span class="selector-class">.streaming</span><span class="selector-class">.DelimitedInputWriter</span>.&lt;init&gt;(DelimitedInputWriter<span class="selector-class">.java</span>:<span class="number">115</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveDelimitedTextSerializer</span><span class="selector-class">.createRecordWriter</span>(HiveDelimitedTextSerializer<span class="selector-class">.java</span>:<span class="number">66</span>)</span><br><span class="line">	at org<span class="selector-class">.apache</span><span class="selector-class">.flume</span><span class="selector-class">.sink</span><span class="selector-class">.hive</span><span class="selector-class">.HiveWriter</span>.&lt;init&gt;(HiveWriter<span class="selector-class">.java</span>:<span class="number">89</span>)</span><br><span class="line">	... <span class="number">6</span> more</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这个是因为Flume写入hive表时，需要hive表支持事务，所以hive表必须是事务表</p>
<h3 id="开启事务表"><a href="#开启事务表" class="headerlink" title="开启事务表"></a>开启事务表</h3><p>在hive命令行运行以下命令：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">SET</span> hive.support.concurrency = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">SET</span> hive.enforce.bucketing = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">SET</span> hive.exec.dynamic.partition.mode = nonstrict;</span><br><span class="line"><span class="built_in">SET</span> hive.txn.manager = org.apache.hadoop.hive.ql.lockmgr.DbTxnManager;</span><br><span class="line"><span class="built_in">SET</span> hive.compactor.initiator.on = <span class="literal">true</span>;</span><br><span class="line"><span class="built_in">SET</span> hive.compactor.worker.threads = 1;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>创建分区分桶表并开启事务</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> ods_flume_log(<span class="type">line</span> string) </span><br><span class="line">partitioned <span class="keyword">by</span> (dt string) </span><br><span class="line">clustered <span class="keyword">by</span> (<span class="type">line</span>) <span class="keyword">into</span> <span class="number">1</span> buckets </span><br><span class="line">stored <span class="keyword">as</span> orc tblproperties (<span class="string">&#x27;transactional&#x27;</span>=<span class="string">&#x27;true&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">---------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">partitioned <span class="keyword">by</span> (dt string) - 指定分区字段</span><br><span class="line">clustered <span class="keyword">by</span> (<span class="type">line</span>) – 指定分桶的字段</span><br><span class="line">stored <span class="keyword">as</span> orc - 分桶格式orc</span><br><span class="line">tblproperties (‘transactional’=‘<span class="keyword">true</span>’) - tblproperties可以添加一些hive属性，这里是开启事务</span><br><span class="line"></span><br><span class="line">我这里只有一个字段，因为按时间分区了，所以只设置了一个桶，各位看自己情况创建。</span><br><span class="line"></span><br><span class="line">再次运行Flume后，数据正常写入hive中</span><br></pre></td></tr></table></figure>

<h3 id="我们要不要使用双层flume-：-不要"><a href="#我们要不要使用双层flume-：-不要" class="headerlink" title="我们要不要使用双层flume ： 不要"></a>我们要不要使用双层flume ： 不要</h3><h3 id="avro"><a href="#avro" class="headerlink" title="avro"></a>avro</h3><p>使用场景 ： 第一个agent的输出作为第二个的输入</p>
<p>需求 ：读取1111端口的数据并发送到2222端口，然后把数据写入hdfs</p>
<p>分析 ： 两层flume</p>
<p>agent ：</p>
<ul>
<li>nc-mem-avro</li>
<li>avro-mem-hdfs&#x2F;logger</li>
</ul>
<p>agent1：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">a1<span class="selector-class">.sources</span> = r1</span><br><span class="line">a1<span class="selector-class">.sinks</span> = k1</span><br><span class="line">a1<span class="selector-class">.channels</span> = c1</span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.type</span> = netcat</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.bind</span> = localhost</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.port</span> = <span class="number">1111</span></span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.channels</span><span class="selector-class">.c1</span><span class="selector-class">.type</span> = memory</span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.type</span> = avro</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span>.hostname=bigdata32</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span>.port=<span class="number">2222</span></span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.channels</span> = c1</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.channel</span> = c1</span><br></pre></td></tr></table></figure>

<p>agent2:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">a1<span class="selector-class">.sources</span> = r1</span><br><span class="line">a1<span class="selector-class">.sinks</span> = k1</span><br><span class="line">a1<span class="selector-class">.channels</span> = c1</span><br><span class="line"></span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.type</span> = avro</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.bind</span> = bigdata32</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.port</span> = <span class="number">2222</span></span><br><span class="line">a1<span class="selector-class">.channels</span><span class="selector-class">.c1</span><span class="selector-class">.type</span> = memory</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.type</span> = logger</span><br><span class="line">a1<span class="selector-class">.sources</span><span class="selector-class">.r1</span><span class="selector-class">.channels</span> = c1</span><br><span class="line">a1<span class="selector-class">.sinks</span><span class="selector-class">.k1</span><span class="selector-class">.channel</span> = c1</span><br></pre></td></tr></table></figure>

<h1 id="编写脚本："><a href="#编写脚本：" class="headerlink" title="编写脚本："></a>编写脚本：</h1><p>关于上述的文件每次更改都要进行一次的编写，为避免有些太麻烦了</p>
<p>于是我们可以通过编写shell脚本的方式进行编写</p>
<p>如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br></pre></td><td class="code"><pre><span class="line">if [ $# -lt 3 ];then</span><br><span class="line">echo &quot;使用教程，把taildir的position路径改成自己的，还有hdfs的机器名改成自己的，以及hive的机器名&quot;</span><br><span class="line">echo &quot;error more fouth was need&quot;</span><br><span class="line">echo &quot;Source channel Slink&quot;</span><br><span class="line">echo  &quot;第一个变量以及第二个变量分别是有几个channel和几个Sink flagSink=1 flagChannel=2 第三个参数是Source然后是其内部配置，然后是channel，以此类推，下面分别介绍各种配置参数&quot;</span><br><span class="line">echo &quot;source : exec sqoo avro taildir netcat&quot;</span><br><span class="line">echo &quot;taildir 选择模式:1是文件模式，2是文件夹模式，3是一起的 本地文件或者文件夹路径，最多支持一个文件以及一个文件夹，用，分割  具体的文件夹/文件路径 是不是开启阻断1是开启，其他是不开启 选择channel&quot;</span><br><span class="line">echo &quot;exec/spoo 文件/文件夹 是不是开启阻断 选择channel&quot;</span><br><span class="line">echo &quot;netcat/avro 主机ip 端口 是不是开启阻断 选择channel&quot;</span><br><span class="line">echo &quot;阻断： type key value&quot;</span><br><span class="line">echo &quot;Channel : mem file&quot;</span><br><span class="line">echo &quot;mem 容量 事务容量 选择Sink&quot;</span><br><span class="line">echo &quot;file point文件夹 data文件夹 选择Sink&quot;</span><br><span class="line">echo &quot;Sink : hdfs hive avro logger&quot;</span><br><span class="line">echo &quot;hdfs hdfs上的路经 文件前缀 文件后缀 要不要打开压缩1是开启，其他是不开启 设置压缩格式（开启之后）&quot;</span><br><span class="line">echo &quot;hive hive数据库 hive表 差分文件的分隔符 输入表的分隔符 字段的映射&quot;</span><br><span class="line">echo &quot;avro 主机ip 端口&quot;</span><br><span class="line">echo &quot;logger&quot;</span><br><span class="line">echo &quot;文件命名采用随机数的方式+变量组合的方式&quot;</span><br><span class="line">echo  &quot;多通道例子   2 2 failover replicating 15000 10 6 taildir 1 &#x27;/home/hadoop/data/1.log&#x27; 1 static 1-boy boy mem 10000 10000 file /home/hadoop/data/flumepostion/ /home/hadoop/data/flumedata/ logger avro localhost 1111 0&quot;</span><br><span class="line">echo &quot;单通道 1 1 avro localhost 1111 0 file /home/hadoop/data/flumepostion/ /home/hadoop/data/flumedata/ logger 0&quot;</span><br><span class="line">echo &quot;最后一个参数是控制是不是开启http监控的监控端口是5555 1是开启监控 其他是不开启&quot;</span><br><span class="line">exit 1;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">filename=$(($RANDOM%9999+6))-$1-$2-$3</span><br><span class="line"></span><br><span class="line">echo &quot;a1.sources = r1 &quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line"></span><br><span class="line">Sinkhead=&quot;a1.sinks = &quot;</span><br><span class="line">Sinklist=&quot;&quot;</span><br><span class="line">flagSink=$1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function Sinkgt1()&#123;</span><br><span class="line">if [ $&#123;flagSink&#125; -ne 1 ];then</span><br><span class="line">for ((i=1;i&lt;=$&#123;flagSink&#125;;i++))</span><br><span class="line">do</span><br><span class="line">    Sinklist=$&#123;Sinklist&#125;k$i&quot; &quot;</span><br><span class="line">done</span><br><span class="line">echo $&#123;Sinkhead&#125;$&#123;Sinklist&#125; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sinkgroups = g1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sinkgroups.g1.sinks = &quot;$&#123;Sinklist&#125; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sinkgroups.g1.processor.type = $1&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">Channelgt1 $&#123;@:2&#125;</span><br><span class="line">else </span><br><span class="line">echo &quot;a1.sinks = k1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">Channelgt1 $&#123;@:1&#125;</span><br><span class="line">fi </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Channelhead=&quot;a1.channels = &quot;</span><br><span class="line">Channelist=&quot;&quot;</span><br><span class="line">flagChannel=$2</span><br><span class="line">SinkChannelHead=&quot;a1.sources.r1.channels = &quot;</span><br><span class="line"></span><br><span class="line">function Channelgt1()&#123;</span><br><span class="line">if [ $&#123;flagChannel&#125; -ne 1 ];then</span><br><span class="line">for ((i=1;i&lt;=$&#123;flagChannel&#125;;i++))</span><br><span class="line">do</span><br><span class="line">    Channelist=$&#123;Channelist&#125;c$i&quot; &quot;</span><br><span class="line">done</span><br><span class="line">echo $&#123;Channelhead&#125;$&#123;Channelist&#125; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo $&#123;SinkChannelHead&#125;$&#123;Channelist&#125; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sources.r1.selector.type = $1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">panduan $&#123;@:2&#125;</span><br><span class="line">else </span><br><span class="line">echo &quot;a1.channels = c1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sources.r1.channels = c1&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">panduan $&#123;@:1&#125;</span><br><span class="line">fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function Fileordir()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    case $1 in</span><br><span class="line">    1)</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups = f1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups.f1 = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f1.headerKey1 = value1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.fileHeader = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.ri.maxBatchCount = 1000&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        case $3 in</span><br><span class="line">        1)</span><br><span class="line">        interceptors $&#123;@:4&#125;</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        selectchinnal $&#123;@:4&#125;</span><br><span class="line">        ;;</span><br><span class="line">        esac</span><br><span class="line">    ;;</span><br><span class="line">    2)</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups = f2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups.f2 = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f2.headerKey1 = value2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f2.headerKey2 = value2-2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.fileHeader = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.ri.maxBatchCount = 1000&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        case $3 in</span><br><span class="line">        1)</span><br><span class="line">        interceptors $&#123;@:4&#125;</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        selectchinnal $&#123;@:4&#125;</span><br><span class="line">        ;;</span><br><span class="line">        esac</span><br><span class="line">    ;;</span><br><span class="line">    3)</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups = f1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups.f1 = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f1.headerKey1 = value1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups = f2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.filegroups.f2 = $3&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f2.headerKey1 = value2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.headers.f2.headerKey2 = value2-2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.fileHeader = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.ri.maxBatchCount = 1000&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        case $4 in</span><br><span class="line">        1)</span><br><span class="line">        interceptors $&#123;@:5&#125;</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        selectchinnal $&#123;@:5&#125;</span><br><span class="line">        ;;</span><br><span class="line">        esac</span><br><span class="line">    ;; </span><br><span class="line">    esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function interceptors()&#123;</span><br><span class="line"></span><br><span class="line">echo &quot;a1.sources.r1.interceptors = example&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sources.r1.interceptors.example.type = $1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sources.r1.interceptors.example.key = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">echo &quot;a1.sources.r1.interceptors.example.value = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">selectchinnal $&#123;@:4&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">flagChannellins=$&#123;flagChannel&#125;</span><br><span class="line">function selectchinnal() </span><br><span class="line">&#123;</span><br><span class="line">case $1 in</span><br><span class="line">    &quot;mem&quot;)</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.type = memory&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.capacity = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.transactionCapacity = $3&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        flagChannellins=$(($&#123;flagChannellins&#125;-1))</span><br><span class="line">        if [ $&#123;flagChannellins&#125; == 0 ];then</span><br><span class="line">        selectSinks $&#123;@:4&#125;</span><br><span class="line">        else</span><br><span class="line">        selectchinnal $&#123;@:4&#125;</span><br><span class="line">        fi</span><br><span class="line">    ;;</span><br><span class="line">    &quot;file&quot;)</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.type = file&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.checkpointDir = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.channels.c$&#123;flagChannellins&#125;.dataDirs = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        flagChannellins=$(($&#123;flagChannellins&#125;-1))</span><br><span class="line">        if [ $&#123;flagChannellins&#125; == 0 ];then</span><br><span class="line">        selectSinks $&#123;@:4&#125;</span><br><span class="line">        else</span><br><span class="line">        selectchinnal $&#123;@:4&#125;</span><br><span class="line">        fi</span><br><span class="line">    ;;</span><br><span class="line">    *)</span><br><span class="line">        echo &quot;无匹配的channel&quot;</span><br><span class="line">        exit 1</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">flagSinklins=$&#123;flagSink&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function selectSinks()</span><br><span class="line">&#123;</span><br><span class="line">        case $1 in</span><br><span class="line">            &quot;logger&quot;)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.type = logger&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:2&#125;</span><br><span class="line">                fi</span><br><span class="line"></span><br><span class="line">            ;;</span><br><span class="line">            &quot;hdfs&quot;)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.type = hdfs&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.path = hdfs://bigdata3:9000$2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.filePrefix = $3&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.fileSuffix = $4&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.writeFormat = Text&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.rollSize = 134217728&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.rollInterval = 21600&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.rollCount = 1000&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.round = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.roundUnit = minute&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.batchSize = 1200&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.roundValue = 21&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.useLocalTimeStamp = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                case $5 in </span><br><span class="line">                1)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.codeC = $6&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.fileType = CompressedStream&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins $&#123;@:7&#125;</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:7&#125;</span><br><span class="line">                fi</span><br><span class="line">                ;;</span><br><span class="line">                *)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.fileType = DataStream&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins $&#123;@:6&#125;</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:6&#125;</span><br><span class="line">                fi</span><br><span class="line">                ;;</span><br><span class="line">                esac</span><br><span class="line">            ;;</span><br><span class="line">            &quot;avro&quot;)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.type = avro &quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hostname=$2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.port=$3&quot;  &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins $&#123;@:4&#125;</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:4&#125;</span><br><span class="line">                fi</span><br><span class="line">            ;;</span><br><span class="line">            &quot;hive&quot;)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.type = hive&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.serializer = DELIMITED&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hive.metastore = thrift://bigdata3:9083&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hive.database =$2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hive.table = $3&quot;  &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.serializer.delimiter = $4&quot;  &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.serializer.serdeSeparator = $5&quot;  &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.serializer.fieldnames =  $6&quot;  &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlinshive $&#123;@:7&#125;</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:7&#125;</span><br><span class="line">                fi</span><br><span class="line">            ;;</span><br><span class="line">            *)</span><br><span class="line">                echo &quot;无匹配的Sink&quot;</span><br><span class="line">                exit 1</span><br><span class="line">            ;;</span><br><span class="line">        esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function codeC()&#123;</span><br><span class="line">    case $5 in </span><br><span class="line">                1)</span><br><span class="line">                echo &quot;a1.sinks.k$&#123;flagSinklins&#125;.hdfs.codeC = $6&quot;</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:7&#125;</span><br><span class="line">                fi</span><br><span class="line">                ;;</span><br><span class="line">                *)</span><br><span class="line">                flagSinklins=$(($&#123;flagSinklins&#125;-1))</span><br><span class="line">                if [ $&#123;flagSinklins&#125; == 0 ];then</span><br><span class="line">                    cleanlins</span><br><span class="line">                else</span><br><span class="line">                selectSinks $&#123;@:6&#125;</span><br><span class="line">                fi</span><br><span class="line">                ;;</span><br><span class="line">                esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function cleanlins()</span><br><span class="line">&#123;</span><br><span class="line">cat ./$&#123;filename&#125;</span><br><span class="line">case $1 in</span><br><span class="line">1)</span><br><span class="line">flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file ./$&#123;filename&#125; -Dflume.root.logger=info,console --name a1 -Dflume.monitoring.type=http -Dflume.monitoring.port=5555</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file ./$&#123;filename&#125; -Dflume.root.logger=info,console --name a1</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">rm -rf ./$&#123;filename&#125;</span><br><span class="line">exit 99</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function cleanlinshive()&#123;</span><br><span class="line">cat ./$&#123;filename&#125;</span><br><span class="line">nohup hive --service metastore &gt; ~/log/metastore.log 1&gt;&amp;2 &amp;</span><br><span class="line">case $1 in</span><br><span class="line">1)</span><br><span class="line">flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file ./$&#123;filename&#125; -Dflume.root.logger=info,console --name a1 -Dflume.monitoring.type=http -Dflume.monitoring.port=5555</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">flume-ng agent --conf $&#123;FLUME_HOME&#125;/conf --conf-file ./$&#123;filename&#125; -Dflume.root.logger=info,console --name a1</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">rm -rf ./$&#123;filename&#125;</span><br><span class="line">exit 100</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function choicein()&#123;</span><br><span class="line">        case $1 in</span><br><span class="line">        1)</span><br><span class="line">        interceptors $&#123;@:2&#125;</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        selectchinnal $&#123;@:2&#125;</span><br><span class="line">        ;;</span><br><span class="line">        esac</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function sourcechoice()&#123;</span><br><span class="line">    case $1 in</span><br><span class="line">    &quot;taildir&quot;)</span><br><span class="line">        echo &quot;a1.sources.r1.type = TAILDIR&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.positionFile = /home/hadoop/data/flumepostion/taildir_position.json&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        Fileordir $&#123;@:2&#125;</span><br><span class="line">    ;;</span><br><span class="line">    &quot;exec&quot;)</span><br><span class="line">        echo &quot;a1.sources.r1.type = exec&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.command = tail -F $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        choicein $&#123;@:3&#125;</span><br><span class="line">    ;;</span><br><span class="line">    &quot;spoo&quot;)</span><br><span class="line">        echo &quot;a1.sources.r1.type = spooldir&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.spoolDir = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.fileHeader = true&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        choicein $&#123;@:3&#125;</span><br><span class="line">    ;;</span><br><span class="line">    &quot;avro&quot;)</span><br><span class="line">        echo &quot;a1.sources.r1.type = avro&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.bind = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.port = $3&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        choicein $&#123;@:4&#125;</span><br><span class="line">    ;;</span><br><span class="line">    &quot;netcat&quot;)</span><br><span class="line">        echo &quot;a1.sources.r1.type = netcat&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.bind = $2&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        echo &quot;a1.sources.r1.port = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">        choicein $&#123;@:4&#125;</span><br><span class="line">    ;;</span><br><span class="line">    *)</span><br><span class="line">        echo &quot;无匹配的source&quot;</span><br><span class="line">        exit 1</span><br><span class="line">    ;;</span><br><span class="line">esac</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function panduan()&#123;</span><br><span class="line">if [ $&#123;flagSink&#125; -ne 1 ] &amp;&amp; [ $&#123;flagChannel&#125; == 1 ];then</span><br><span class="line">for ((i=1;i&lt;=$&#123;flagSink&#125;;i++))</span><br><span class="line">do</span><br><span class="line">echo &quot;a1.sinks.k$&#123;i&#125;.channel = c1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">done</span><br><span class="line">echo &quot;a1.sinkgroups.g1.processor.maxpenalty = $1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">case $&#123;flagSink&#125; in</span><br><span class="line">2)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    sourcechoice $&#123;@:4&#125;</span><br><span class="line">;;</span><br><span class="line">3)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:5&#125;</span><br><span class="line">;;</span><br><span class="line">4)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:6&#125;</span><br><span class="line">;;</span><br><span class="line">5)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:7&#125;</span><br><span class="line">;;</span><br><span class="line">6)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:8&#125;</span><br><span class="line">;;</span><br><span class="line">7)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k7 = $8&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:9&#125;</span><br><span class="line">;;</span><br><span class="line">8)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k7 = $8&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k8 = $9&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:10&#125;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">echo &quot;超出限制8个&quot;</span><br><span class="line">exit 10000</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $&#123;flagSink&#125; == 1 ] &amp;&amp; [ $&#123;flagChannel&#125; -ne 1 ];then</span><br><span class="line">for ((i=1;i&lt;=$&#123;flagChannel&#125;;i++))</span><br><span class="line">do</span><br><span class="line">echo &quot;a1.sinks.k1.channel = c$&#123;i&#125;&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">done</span><br><span class="line">sourcechoice $&#123;@:1&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $&#123;flagSink&#125; -ne 1 ] &amp;&amp; [ $&#123;flagChannel&#125; -ne 1 ];then</span><br><span class="line">for ((i=1;i&lt;=$&#123;flagSink&#125;;i++))</span><br><span class="line">do</span><br><span class="line">echo &quot;a1.sinks.k$&#123;i&#125;.channel = c$&#123;i&#125;&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">done</span><br><span class="line">echo &quot;a1.sinkgroups.g1.processor.maxpenalty = $1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">case $&#123;flagSink&#125; in</span><br><span class="line">2)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    sourcechoice $&#123;@:4&#125;</span><br><span class="line">;;</span><br><span class="line">3)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:5&#125;</span><br><span class="line">;;</span><br><span class="line">4)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:6&#125;</span><br><span class="line">;;</span><br><span class="line">5)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:7&#125;</span><br><span class="line">;;</span><br><span class="line">6)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:8&#125;</span><br><span class="line">;;</span><br><span class="line">7)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k7 = $8&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:9&#125;</span><br><span class="line">;;</span><br><span class="line">8)</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k1 = $2&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k2 = $3&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k3 = $4&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k4 = $5&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k5 = $6&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k6 = $7&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k7 = $8&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">    echo &quot;a1.sinkgroups.g1.processor.priority.k8 = $9&quot;&gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">     sourcechoice $&#123;@:10&#125;</span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">echo &quot;超出限制8个&quot;</span><br><span class="line">exit 10000</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ $&#123;flagSink&#125; == 1 ] &amp;&amp; [ $&#123;flagChannel&#125; == 1 ];then</span><br><span class="line">echo &quot;a1.sinks.k1.channel = c1&quot; &gt;&gt; ./$&#123;filename&#125;</span><br><span class="line">sourcechoice $&#123;@:1&#125;</span><br><span class="line">fi</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Sinkgt1 $&#123;@:3&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="channel-file"><a href="#channel-file" class="headerlink" title="channel:file"></a>channel:file</h1><p>关于Filechannel的例子官方是如下介绍的</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a1.channels = c1</span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">a1.channels.c1.checkpointDir = /mnt/flume/checkpoint</span><br><span class="line">a1.channels.c1.dataDirs = /mnt/flume/data</span><br></pre></td></tr></table></figure>

<p>于是我们可以写个简单的agent：taidir-file-logger</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">example.conf: A single-node Flume configuration</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.positionFile = /home/hadoop/data/flumepostion/taildir_position.json</span><br><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /home/hadoop/data/try.txt</span><br><span class="line">a1.sources.r1.headers.f1.headerKey1 = value1</span><br><span class="line">a1.sources.r1.fileHeader = true</span><br><span class="line">a1.sources.ri.maxBatchCount = 1000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = file</span><br><span class="line">a1.channels.c1.checkpointDir = /home/hadoop/data/flumefilepostion</span><br><span class="line">a1.channels.c1.dataDirs = /home/hadoop/data/flumedata</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>

<p>就可以了</p>
<p>关于flume的负载问题</p>
<p>我们可以设置Sink的负载就是当是多个数据输出的时候</p>
<p>可以设置负载策略，可以让它变成随机发送，或者是轮询发送等</p>
<p>均衡 ： load_balance ： 将数据分开，提供并行度的功能 减轻sink 的压力 如果突然输出的agent挂掉，数据都会发送到没有挂的Sink的agent上，但是会有个超时时间，才会进行上述所说</p>
<p>需要设置两个参数</p>
<p>容灾 ： sink出现问题的</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">processor<span class="selector-class">.backoff</span>  true </span><br><span class="line">processor<span class="selector-class">.selector</span>.maxTimeOut</span><br></pre></td></tr></table></figure>

<p>设置多个Sink的agent</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">agent1：</span><br><span class="line">agent1.sources = r1</span><br><span class="line">agent1.sinks = k1 k2</span><br><span class="line">agent1.channels = c1</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.type = netcat</span><br><span class="line">agent1.sources.r1.bind = bigdata32</span><br><span class="line">agent1.sources.r1.port = 1111</span><br><span class="line"></span><br><span class="line">agent1.channels.c1.type = memory</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 2222</span></span><br><span class="line">agent1.sinks.k1.type = avro</span><br><span class="line">agent1.sinks.k1.hostname = bigdata32</span><br><span class="line">agent1.sinks.k1.port = 2222</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 3333</span></span><br><span class="line">agent1.sinks.k2.type = avro</span><br><span class="line">agent1.sinks.k2.hostname = bigdata32</span><br><span class="line">agent1.sinks.k2.port = 3333</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink processers</span></span><br><span class="line">agent1.sinkgroups = g1</span><br><span class="line">agent1.sinkgroups.g1.sinks = k1 k2</span><br><span class="line">agent1.sinkgroups.g1.processor.type = load_balance</span><br><span class="line">agent1.sinkgroups.g1.processor.backoff = true</span><br><span class="line">agent1.sinkgroups.g1.processor.selector = round_robin</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.channels = c1</span><br><span class="line">agent1.sinks.k1.channel = c1</span><br><span class="line">agent1.sinks.k2.channel = c1</span><br><span class="line"></span><br><span class="line">agent2：2222端口</span><br><span class="line">agent2.sources = r1</span><br><span class="line">agent2.sinks = k1</span><br><span class="line">agent2.channels = c1</span><br><span class="line"></span><br><span class="line">agent2.sources.r1.type = avro</span><br><span class="line">agent2.sources.r1.bind = bigdata32</span><br><span class="line">agent2.sources.r1.port = 2222</span><br><span class="line"></span><br><span class="line">agent2.channels.c1.type = memory</span><br><span class="line">agent2.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line">agent2.sources.r1.channels = c1</span><br><span class="line">agent2.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">agent3: 3333端口</span><br><span class="line">agent3.sources = r1</span><br><span class="line">agent3.sinks = k1</span><br><span class="line">agent3.channels = c1</span><br><span class="line"></span><br><span class="line">agent3.sources.r1.type = avro</span><br><span class="line">agent3.sources.r1.bind = bigdata32</span><br><span class="line">agent3.sources.r1.port = 3333</span><br><span class="line"></span><br><span class="line">agent3.channels.c1.type = memory</span><br><span class="line">agent3.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line">agent3.sources.r1.channels = c1</span><br><span class="line">agent3.sinks.k1.channel = c1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>启动我们的agent</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">启动agent： </span><br><span class="line">	从后往前 启动 </span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent3 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/sink/agent3.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent2 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/sink/agent2.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent1 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/sink/agent1.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">telnet bigdata32 1111</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然后可以设置策略</p>
<p><code>agent1.sinkgroups.g1.processor.selector = round_robin ： 这个是轮询策略，就是一个换一个的</code></p>
<p><code>agent1.sinkgroups.g1.processor.selector = random ： 这个是随机策略的</code></p>
<p>负载，相当于是多几个备用通道，通过不同优先级进行设置通道</p>
<h1 id="Source的组件"><a href="#Source的组件" class="headerlink" title="Source的组件"></a>Source的组件</h1><p>拦截器 ： 数据转换 或者数据清洗的</p>
<p>channel选择器 ：把采集过来的数据发送到那一个channel里面</p>
<h1 id="SInk组件"><a href="#SInk组件" class="headerlink" title="SInk组件"></a>SInk组件</h1><p>Sink组件就是上述的Sink processers ：把采集的数据发送到哪一个sink上</p>
<h1 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h1><p>定义一个agent 端口 1111 采集数据</p>
<p>一个发送到hdfs上</p>
<p>另外一个发送到logger上</p>
<p>架构图就出来了 ：</p>
<p>source -&gt;</p>
<ul>
<li>channel -&gt; sink -&gt;logger</li>
<li>channel -&gt; sink -&gt;hdfs</li>
</ul>
<h2 id="思考如何配置channel选择器"><a href="#思考如何配置channel选择器" class="headerlink" title="思考如何配置channel选择器"></a>思考如何配置channel选择器</h2><p>官网如下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.channels = c1 c2 c3</span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line">a1.sources.r1.channels = c1 c2 c3</span><br><span class="line">a1.sources.r1.selector.optional = c3</span><br></pre></td></tr></table></figure>

<p>我们自己写的如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">agent1.sources = r1</span><br><span class="line">agent1.sinks = k1 k2</span><br><span class="line">agent1.channels = c1 c2</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.type = netcat</span><br><span class="line">agent1.sources.r1.bind = bigdata3</span><br><span class="line">agent1.sources.r1.port = 1111</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">agent1.sources.r1.selector.type = replicating</span><br><span class="line">agent1.sources.r1.channels = c1 c2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">agent1.channels.c1.type = memory</span><br><span class="line">agent1.channels.c2.type = memory</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink hdfs</span></span><br><span class="line">agent1.sinks.k1.type = hdfs</span><br><span class="line">agent1.sinks.k1.hdfs.path = hdfs://bigdata3:9000/flume/channel_selector/</span><br><span class="line">agent1.sinks.k1.hdfs.fileType=DataStream</span><br><span class="line">agent1.sinks.k1.hdfs.writeFormat=Text</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件前后缀</span></span><br><span class="line">agent1.sinks.k1.hdfs.filePrefix=events</span><br><span class="line">agent1.sinks.k1.hdfs.fileSuffix=.log</span><br><span class="line">agent1.sinks.k1.hdfs.useLocalTimeStamp=true</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">文件滚动</span></span><br><span class="line">agent1.sinks.k1.hdfs.rollInterval=60</span><br><span class="line">agent1.sinks.k1.hdfs.rollSize=134217728</span><br><span class="line">agent1.sinks.k1.hdfs.rollCount=1000</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink logger</span></span><br><span class="line">agent1.sinks.k2.type = logger</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">agent1.sources.r1.channels = c1 c2</span><br><span class="line">agent1.sinks.k1.channel = c1</span><br><span class="line">agent1.sinks.k2.channel = c2</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>作业 ：用三个agent 完成上面的事情</p>
<p>代码如下 ：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1 k2</span><br><span class="line">a1.channels = c1 c2</span><br><span class="line"></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = bigdata3</span><br><span class="line">a1.sources.r1.port = 1111</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">a1.sources.r1.selector.type = replicating</span><br><span class="line">a1.sources.r1.channels = c1 c2</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c2.type = memory</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 2222</span></span><br><span class="line">a1.sinks.k1.type = avro</span><br><span class="line">a1.sinks.k1.hostname = bigdata3</span><br><span class="line">a1.sinks.k1.port = 2222</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 3333</span></span><br><span class="line">a1.sinks.k2.type = avro</span><br><span class="line">a1.sinks.k2.hostname = bigdata3</span><br><span class="line">a1.sinks.k2.port = 3333</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line">a1.sinks.k2.channel = c2</span><br></pre></td></tr></table></figure>

<p>然后我们书写端口的agent</p>
<p>2222端口</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = bigdata3 </span><br><span class="line">a1.sources.r1.port = 2222 </span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 15000</span><br><span class="line">a1.channels.c1.transactionCapacity = 15000</span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://bigdata3:9000/data</span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = com</span><br><span class="line">a1.sinks.k1.hdfs.fileSuffix = .test</span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line">a1.sinks.k1.hdfs.writeFormat = Text</span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 134217728</span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 21600</span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 1000</span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = minute</span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 1200</span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 21</span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>3333端口</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line">a1.sources.r1.type = avro</span><br><span class="line">a1.sources.r1.bind = bigdata3 </span><br><span class="line">a1.sources.r1.port = 3333 </span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 15000</span><br><span class="line">a1.channels.c1.transactionCapacity = 15000</span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line">a1.sources.r1.channels = c1 </span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>flume里官方提供的拦截器很多，不过我们一般都不用，只用自己研发的</p>
<p>拦截器需求 ：</p>
<p>现在有三个数据源 ： 分别是1111端口，1112端口，1113端口，通过拦截器把数据分别发送过去</p>
<p>agent如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line">agent1:</span><br><span class="line">agent1.sources = r1</span><br><span class="line">agent1.sinks = k1</span><br><span class="line">agent1.channels = c1</span><br><span class="line"></span><br><span class="line">agent1.sources.r1.type = netcat</span><br><span class="line">agent1.sources.r1.bind = bigdata32</span><br><span class="line">agent1.sources.r1.port = 1111</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加一个拦截器 =》 数据清洗 + event打标签</span></span><br><span class="line">agent1.sources.r1.interceptors = i1</span><br><span class="line">agent1.sources.r1.interceptors.i1.type = static</span><br><span class="line">agent1.sources.r1.interceptors.i1.key = dl2262</span><br><span class="line">agent1.sources.r1.interceptors.i1.value = boy</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">agent1.sources.r1.channels = c1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">agent1.channels.c1.type = memory</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 2222</span></span><br><span class="line">agent1.sinks.k1.type = avro</span><br><span class="line">agent1.sinks.k1.hostname = bigdata32</span><br><span class="line">agent1.sinks.k1.port = 2222</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">agent1.sources.r1.channels = c1</span><br><span class="line">agent1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">agent2:</span><br><span class="line">agent2.sources = r1</span><br><span class="line">agent2.sinks = k1</span><br><span class="line">agent2.channels = c1</span><br><span class="line"></span><br><span class="line">agent2.sources.r1.type = netcat</span><br><span class="line">agent2.sources.r1.bind = bigdata32</span><br><span class="line">agent2.sources.r1.port = 1112</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加一个拦截器 =》 数据清洗 + event打标签</span></span><br><span class="line">agent2.sources.r1.interceptors = i1</span><br><span class="line">agent2.sources.r1.interceptors.i1.type = static</span><br><span class="line">agent2.sources.r1.interceptors.i1.key = dl2262</span><br><span class="line">agent2.sources.r1.interceptors.i1.value = girl</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">agent2.sources.r1.channels = c1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">agent2.channels.c1.type = memory</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 2222</span></span><br><span class="line">agent2.sinks.k1.type = avro</span><br><span class="line">agent2.sinks.k1.hostname = bigdata32</span><br><span class="line">agent2.sinks.k1.port = 2222</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">agent2.sources.r1.channels = c1</span><br><span class="line">agent2.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line">agent3:</span><br><span class="line">agent3.sources = r1</span><br><span class="line">agent3.sinks = k1</span><br><span class="line">agent3.channels = c1</span><br><span class="line"></span><br><span class="line">agent3.sources.r1.type = netcat</span><br><span class="line">agent3.sources.r1.bind = bigdata32</span><br><span class="line">agent3.sources.r1.port = 1113</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">添加一个拦截器 =》 数据清洗 + event打标签</span></span><br><span class="line">agent3.sources.r1.interceptors = i1</span><br><span class="line">agent3.sources.r1.interceptors.i1.type = static</span><br><span class="line">agent3.sources.r1.interceptors.i1.key = dl2262</span><br><span class="line">agent3.sources.r1.interceptors.i1.value = tea</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">agent3.sources.r1.channels = c1</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">agent3.channels.c1.type = memory</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink 2222</span></span><br><span class="line">agent3.sinks.k1.type = avro</span><br><span class="line">agent3.sinks.k1.hostname = bigdata32</span><br><span class="line">agent3.sinks.k1.port = 2222</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">agent3.sources.r1.channels = c1</span><br><span class="line">agent3.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line">agent4:</span><br><span class="line"></span><br><span class="line">agent4.sources = r1</span><br><span class="line">agent4.sinks = k1 k2 k3</span><br><span class="line">agent4.channels = c1 c2 c3</span><br><span class="line"></span><br><span class="line">agent4.sources.r1.type = avro</span><br><span class="line">agent4.sources.r1.bind = bigdata32</span><br><span class="line">agent4.sources.r1.port = 2222</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">0 配置<span class="built_in">source</span> channle</span></span><br><span class="line">agent4.sources.r1.selector.type = multiplexing</span><br><span class="line">agent4.sources.r1.selector.header = dl2262</span><br><span class="line">agent4.sources.r1.selector.mapping.boy = c1</span><br><span class="line">agent4.sources.r1.selector.mapping.girl = c2</span><br><span class="line">agent4.sources.r1.selector.default = c3</span><br><span class="line">agent4.sources.r1.channels = c1 c2 c3</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">1.配置两个channel</span></span><br><span class="line">agent4.channels.c1.type = memory</span><br><span class="line">agent4.channels.c2.type = memory</span><br><span class="line">agent4.channels.c3.type = memory</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义sink logger</span></span><br><span class="line">agent4.sinks.k1.type =logger</span><br><span class="line">agent4.sinks.k2.type =logger</span><br><span class="line">agent4.sinks.k3.type =logger</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">定义 连接</span></span><br><span class="line">agent4.sources.r1.channels = c1 c2 c3</span><br><span class="line">agent4.sinks.k1.channel = c1</span><br><span class="line">agent4.sinks.k2.channel = c2</span><br><span class="line">agent4.sinks.k3.channel = c3</span><br><span class="line"></span><br><span class="line">启动：</span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent4 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/many2one/agent4.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent3 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/many2one/agent3.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent2 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/many2one/agent2.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">flume-ng agent \</span><br><span class="line">--name agent1 \</span><br><span class="line">--conf $&#123;FLUME_HOME&#125;/conf \</span><br><span class="line">--conf-file /home/hadoop/project/flume/many2one/agent1.conf \</span><br><span class="line">-Dflume.root.logger=info,console</span><br><span class="line"></span><br><span class="line">telnet bigdata32 1111</span><br><span class="line">telnet bigdata32 1112</span><br><span class="line">telnet bigdata32 1113</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="周六周日-：-clickhouse-，-mongo-，-python-，-go-，-深入jvm，java-机器学习的算法"><a href="#周六周日-：-clickhouse-，-mongo-，-python-，-go-，-深入jvm，java-机器学习的算法" class="headerlink" title="周六周日 ： clickhouse ， mongo ， python ， go ， 深入jvm，java,机器学习的算法"></a>周六周日 ： clickhouse ， mongo ， python ， go ， 深入jvm，java,机器学习的算法</h1><h1 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h1><h2 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h2><p>默认的容量 ： 就是存储的容量capacity</p>
<p>事务容量 ： 就是发生错误的时候可以回撤的条数，包括写进去的时候的事务 transactionCapacity</p>
<h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>source ：</p>
<p>channel ：</p>
<p>sink ：当sink突然采集的数据变少，可能是上述两个组件出问题了</p>
<h3 id="监控手段"><a href="#监控手段" class="headerlink" title="监控手段"></a>监控手段</h3><p>flume的ganglia框架，监控</p>
<p>agent启动一些参数获取这三个组件的相关指标</p>
<p>建议用第二个：因为简单，因为第一个要安装ganglia</p>
<p>对于第二种是获取json数据进而获取的，通过采集http的接口数据，如何通过dataease或者superset进行可视化，或者给前端人员</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>在命令行加上命令就可以啦</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -c . -f conf/exec-tail.conf -n a1 -Dflume.root.<span class="attribute">logger</span>=INFO,console -Dflume.monitoring.<span class="attribute">type</span>=http -Dflume.monitoring.<span class="attribute">port</span>=1234</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/10/12-08/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/10/12-08/" class="post-title-link" itemprop="url">云原生教学视频</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-10 11:38:03" itemprop="dateCreated datePublished" datetime="2022-12-10T11:38:03+08:00">2022-12-10</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-11 16:09:21" itemprop="dateModified" datetime="2022-12-11T16:09:21+08:00">2022-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E4%BA%91%E5%8E%9F%E7%94%9F%EF%BC%88%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%EF%BC%89/" itemprop="url" rel="index"><span itemprop="name">云原生（哔哩哔哩）</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>5 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="云原生"><a href="#云原生" class="headerlink" title="云原生"></a>云原生</h1><p>理解 ： 理解上要把他们拆开理解会更好</p>
<p>云 ：云基础设施（cloud）</p>
<p>原生：native ：在云计算平台里可以原生的计算和运行的</p>
<p>云原生的概念由来：<br>2013年被prvoyal公司的Ms提出</p>
<p>2015年谷歌带头成立了云原生的计算基金会</p>
<p>云原生的定义 ：</p>
<p>基于微服务原理而开发的应用，用容器的方式打包，在运行时，容器由运行于云基础设施之上的平台进行调度，应用开发采用持续交付和devOps实践</p>
<p>2015年：容器化封装+自动化管理+面向微服务</p>
<p>2018年：容器化封装+面向微服务+服务网格+声明格式API</p>
<p>云原生有利于各种组织在共有云，私有云和混合云等新动态环境中，构建和运行可扩展性的应用</p>
<p>微服务 ：把原有的单体应用拆分为多个独立自治的组件，每个组件都可以独立开发，设计，测试，运维，部署，这个组件可以单独的对外进行服务，我们称其为微服务</p>
<p>容器化：docker容器，容器属于it基础设施层概念，是比虚拟机更轻量化的隔离工具，是微服务的最佳载体</p>
<p>使用k8s的资源调度与容器编排，可以实现docker容器更优管理，进一步实现其PaaS能力</p>
<p>服务网格</p>
<p>服务网格存在的目的，就是中心化的服务治理框架</p>
<p>以往需要对微服务或者对api接口区做治理和管理请求</p>
<p>不可以改变基础设施指的是镜像：日后如果想再次改变他的部署，可以用镜像进行改变</p>
<p>应用部署：命令行：声明式</p>
<p>DevOps</p>
<p>借助云原生的相关技术，DevOps的时代才到来</p>
<p>云原生的最佳实现的实现三个层面</p>
<p>服务编排要实现计算资源弹性化</p>
<p>服务构建和部署要实现高可用</p>
<p>实践驱动基础设施标准初始化</p>
<p>云原生应用的领域</p>
<p>云原生的生态也已经覆盖到了，大数据，人工智能，边缘计算，区域局等领域</p>
<p>云原生的编排以及管理</p>
<p>编排与调度k8s</p>
<p>原生调用grpc</p>
<p>服务代理envoy</p>
<p>api网关apisix</p>
<p>服务网格istio</p>
<p>服务发现coreDns</p>
<p>消息和流式处理kafka</p>
<p>Severless ：只是对服务器的关心比较少，并不是完全无服务器</p>
<p>自动化配置：ansible</p>
<p>数据库：不赘述了</p>
<p>容器镜像仓库：harbor</p>
<p>定义及镜像制作：helm</p>
<p>密钥管理：spiffe</p>
<p>存储技术：ceph</p>
<p>网络技术：calico</p>
<p>监控分析：prometheus</p>
<p>等</p>
<h1 id="4步制作超级精简的大厂docker镜像"><a href="#4步制作超级精简的大厂docker镜像" class="headerlink" title="4步制作超级精简的大厂docker镜像"></a>4步制作超级精简的大厂docker镜像</h1><h2 id="什么是镜像"><a href="#什么是镜像" class="headerlink" title="什么是镜像"></a>什么是镜像</h2><p>镜像是：分层联合文件系统</p>
<p>一种轻量级，可执行的独立软件包</p>
<p>镜像大小：有大有小</p>
<p>曾经网易蜂巢logo镜像只有585B</p>
<p><code>docker pull hub.c.163.com/public/logo</code></p>
<p>精简docker镜像的优势</p>
<p>减少构建时间</p>
<p>减少磁盘使用量</p>
<p>减少下载时间</p>
<p>提高安全性</p>
<h2 id="镜像的分层原理"><a href="#镜像的分层原理" class="headerlink" title="镜像的分层原理"></a>镜像的分层原理</h2><p>doccker镜像的分层</p>
<p>第一层：本机的系统</p>
<p>第二层：镜像上安装的虚拟环境比如：python</p>
<p>第三层：打的补丁文件</p>
<p><code>docker pull busybox:latest</code></p>
<p>拉下来之后我们对它进行多层的镜像,进行演示一遍</p>
<p>拉下来之后随便找个地方创建个文件叫dockerfile</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> busybox</span><br><span class="line"><span class="built_in">RUN</span> mkdir /tmp/foo</span><br><span class="line"><span class="built_in">RUN</span> dd <span class="attribute">if</span>=/dev/zero <span class="attribute">of</span>=/tmp/foo/bar <span class="attribute">bs</span>=1048576 <span class="attribute">count</span>=100</span><br><span class="line"><span class="built_in">RUN</span> rm /tmp/foo/bar</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>上面这个是设置swap的交换分区的代码，count后面跟着的是字节数，bs是每秒的吞吐量</p>
<p>然后同步到docker容器上并执行这个文件 <code>docker build -t busybox:text . </code>这个语句的意思是根据本地镜像，加上我们的文本语句，进行创建我们的一个新的docker镜像，后面的.代表这个文件夹里所有的文本文件，也可以单独指明是哪一个文本文件</p>
<p>运行之前</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-8-16-centos dockerfile]# docker images | grep busybox</span><br><span class="line">busybox                     latest    334e4a014c81   4 days ago      4.86MB</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行之后</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-8-16-centos dockerfile]# docker images | grep busybox</span><br><span class="line">busybox                     text      efa9b412f2f7   4 minutes ago   110MB</span><br><span class="line">busybox                     latest    334e4a014c81   4 days ago      4.86MB</span><br></pre></td></tr></table></figure>

<p>这个新的镜像是基于我们之前的busybox进行创建的，而且执行了上面的分区文件</p>
<p>我们通过代码查看一下我们的容器代码情况 通过 <code>docker inspect busybox:容器的标识</code></p>
<p>容器的标识就是 TAG</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REPOSITORY                  TAG       IMAGE ID       CREATED             SIZE</span><br><span class="line">busybox                     text      efa9b412f2f7   About an hour ago   110MB</span><br><span class="line">busybox                     latest    334e4a014c81   4 days ago          4.86MB</span><br><span class="line">gitlab/gitlab-ce            latest    08f00af277b7   5 days ago          2.79GB</span><br><span class="line">hub.c.163.com/public/logo   latest    6fbdd13cd204   6 years ago         585B</span><br></pre></td></tr></table></figure>

<p>然后我们分别查看一下text和latest的代码情况，我们查看最后的layter有几层</p>
<p><code>docker inspect busybox:text</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:98004ed6104b2f4cc21559ea6e4a742ebf6731e37b5d1b04013ca68862749ba3&quot;,</span><br><span class="line">                &quot;sha256:c7a7aa6d1d87d0af266545bb8a56bdedfc79a14be948c092900ffb841c919c87&quot;,</span><br><span class="line">                &quot;sha256:88d1f859f65e27bca2996107976f04ed974c062b507b33b2388b2228b5d80122&quot;,</span><br><span class="line">                &quot;sha256:8e9b239d68ef8acc6fe2b2a82c7c803a79f0bdc5bf200b6d35fc2b062de24963&quot;</span><br><span class="line">            ]</span><br></pre></td></tr></table></figure>

<p><code>docker inspect busybox:latest</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&quot;Layers&quot;: [</span><br><span class="line">               &quot;sha256:98004ed6104b2f4cc21559ea6e4a742ebf6731e37b5d1b04013ca68862749ba3&quot;</span><br><span class="line">           ]</span><br><span class="line">       &#125;,</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>简单来说，一个run就是一层</p>
<h2 id="制作精简镜像"><a href="#制作精简镜像" class="headerlink" title="制作精简镜像"></a>制作精简镜像</h2><p>但是我们如何精简镜像呢，就像上述所说，仅仅用了三个命令，就多了100m</p>
<p>而且docker最多只有127个run</p>
<p>接下来我们来制作一个精简的redis的docker镜像</p>
<p>先创建一个dockerfile2文件在文件中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">FROM 192.168.5.160/library/ubantu:trusty</span><br><span class="line">ENV VER    3.0.0</span><br><span class="line">ENV TARBALL http://download.redis.io/releases/redis-$VER.tar.gz</span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN apt-get install -y curl make gcc</span><br><span class="line">RUN curl -L $TARBALL | tar zxv</span><br><span class="line">WORKDIR redis-$$VER</span><br><span class="line">RUN make</span><br><span class="line">RUN make install</span><br><span class="line">WORKDIR /</span><br><span class="line">RUN apt-get remove -y --auto-remove curl make gcc</span><br><span class="line">RUN apt-get clean</span><br><span class="line">RUN rm -rf /var/lib/apt/lists/* /redis-$$VER</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>save 和 export</p>
<p>导出的区别 ：</p>
<p>export 导出的包括的东西更多一点，它有压缩功能，保留历史层，有历史层的可以进行回滚操作 ;算是导出容器，</p>
<p>容器相当于镜像加个读写层</p>
<p>save 导出的仅仅是镜像，不保留历史层</p>
<p>但是下完之后是300多M有点大</p>
<p>我们对他进行缩小</p>
<p>缩小的方式</p>
<p>用更小的基础镜像 <code>debain</code></p>
<p>如下</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> <span class="number">192.168</span>.<span class="number">5.160</span>/library/debain:jessie</span><br><span class="line"><span class="keyword">ENV</span> VER    <span class="number">3.0</span>.<span class="number">0</span></span><br><span class="line"><span class="keyword">ENV</span> TARBALL http://download.redis.io/releases/redis-$VER.tar.gz</span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get install -y curl make gcc</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> curl -L <span class="variable">$TARBALL</span> | tar zxv</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> redis-$<span class="variable">$VER</span></span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> make</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> make install</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get remove -y --auto-remove curl make gcc</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get clean</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">rm</span> -rf /var/lib/apt/lists/* /redis-$<span class="variable">$VER</span></span></span><br></pre></td></tr></table></figure>

<p>成功之后会发现少了很多的空间</p>
<p>然后再进一步瘦身<br>把dockerfile里的命令串联起来</p>
<p>如下</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">FROM <span class="number">192.168</span>.<span class="number">5.160</span><span class="regexp">/library/</span>debain:jessie</span><br><span class="line">ENV VER    <span class="number">3.0</span>.<span class="number">0</span></span><br><span class="line">ENV TARBALL http:<span class="regexp">//</span>download.redis.io<span class="regexp">/releases/</span>redis-<span class="variable">$VER</span>.tar.gz</span><br><span class="line">RUN apt-get update &amp;&amp; \</span><br><span class="line">apt-get install -y curl make gcc &amp;&amp; \</span><br><span class="line">curl -L <span class="variable">$TARBALL</span> | tar zxv &amp;&amp; \</span><br><span class="line">WORKDIR redis-$<span class="variable">$VER</span> &amp;&amp; \</span><br><span class="line">make &amp;&amp; \</span><br><span class="line">make install &amp;&amp; \</span><br><span class="line">WORKDIR / &amp;&amp; \</span><br><span class="line">apt-get remove -y --auto-remove curl make gcc &amp;&amp; \</span><br><span class="line">apt-get clean &amp;&amp; \</span><br><span class="line">rm -rf <span class="regexp">/var/</span>lib<span class="regexp">/apt/</span>lists<span class="regexp">/* /</span>redis-$<span class="variable">$VER</span></span><br></pre></td></tr></table></figure>

<p>通过串联命令编排之后的镜像体积比不编排的能小上一半左右</p>
<p>压缩镜像 ： 但是有时候并不会好使，但是能压缩多少就压缩多少吧，对一个外来镜像进行压缩的时候，可能会比较明显</p>
<p><code>docker save 镜像的名字 | docker-squash -verbose -t 生成的镜像的名字 | docker load 这个对mac不好使，再linux可以</code></p>
<p>使用容器专用的基础镜像 —— scratch 或者busybox作为基础镜像</p>
<p>上面两个是空镜像，所以我们可以把docker里的程序文件拿出来，打包成gz的压缩包</p>
<p>然后再用空镜像再次生成一个容器，进行极致的压缩</p>
<p>这种方式进行的docker容器对于redis而言，会被压缩到个位数的空间，而且可以正常运行</p>
<p>dockerfile</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> 压缩的文件及其依赖 /</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> redis.conf /etc/redis/redis.conf</span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">6379</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;usr/local/bin/redis-server&quot;</span>]</span></span><br><span class="line"> <span class="keyword">ENTRYPOINT</span><span class="language-bash"> [<span class="string">&quot;docker-entrypoint.sh&quot;</span>]</span></span><br></pre></td></tr></table></figure>

<p>其中压缩的文件是从debain上搞来的依赖，以及redis的包一起打的压缩</p>
<p>EXPOSE ：设置的是端口</p>
<p>查询依赖的方式，通过 ldd 查出所需要的.so文件</p>
<p>然后把所以依赖都打包成tar或者gz文件，用scratch</p>
<p>至于如何获取空镜像，我们可以通过官网命令 <code>tar cv --files-from /dev/null | docker import - scratch</code></p>
<p>就会自动获取了</p>
<p>实操</p>
<p>首先拉去空镜像</p>
<p>对于已经拉去过空镜像的同学就不用了</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar cv --files-<span class="keyword">from</span> <span class="regexp">/dev/</span><span class="keyword">null</span> | docker <span class="keyword">import</span> - scratch</span><br></pre></td></tr></table></figure>

<p>拉去之后找到我们的模板机</p>
<p>然后进入我们的模板机里 <code>docker exec -it 名字 /bin/bash</code></p>
<p>然后找到我们的程序比如我找的是redis-server</p>
<p>然后我们找到之后通过ldd命令查看他的依赖 <code>ldd redis-srever</code></p>
<p>查看到依赖之后把文件夹结构以及文件都弄出来，通过cp命令 <code> docker cp 模板机的名字:文件路径 宿主机的路径</code></p>
<p>然后我们把所有的文件，都打包成一个tar.gz <code>tar -zxcf 生成的文件名（带tar.gz的） 打包的内容的路径</code></p>
<p>然后我们编辑dockerfile文件如下</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch <span class="comment">#从什么镜像中创建</span></span><br><span class="line"><span class="keyword">ADD</span><span class="language-bash"> 压缩的文件及其依赖 / <span class="comment"># 通过ADD可以把文件自动解压</span></span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> redis.conf /etc/redis/redis.conf <span class="comment">#redis 的配置文件</span></span></span><br><span class="line"><span class="keyword">EXPOSE</span> <span class="number">6379</span> <span class="comment">#端口号</span></span><br><span class="line"><span class="keyword">CMD</span><span class="language-bash"> [<span class="string">&quot;usr/local/bin/redis-server&quot;</span>] <span class="comment">#这个相当于解释器，要用的</span></span></span><br></pre></td></tr></table></figure>

<p>然后执行 <code>docker build -t 生成的容器的内容 -f dockerfile</code></p>
<p>构建容器，最后成功之后，通过 <code>docker run -d --name 你的image的名字 你自己起的名字 </code></p>
<p>然后就运行成功了</p>
<p>我们通过docker images</p>
<p>查看一下存储大小如下 ：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">redis</span>-<span class="number">01</span>           latest    c654e9a88af9   <span class="number">13</span> minutes ago   <span class="number">22</span>.<span class="number">3</span>MB</span><br><span class="line"><span class="attribute">scratch</span>            latest    <span class="number">89</span>a161411e52   <span class="number">2</span> hours ago      <span class="number">0</span>B</span><br><span class="line"><span class="attribute">busybox</span>            latest    <span class="number">334</span>e4a014c81   <span class="number">4</span> days ago       <span class="number">4</span>.<span class="number">86</span>MB</span><br><span class="line"><span class="attribute">redis</span>              latest    <span class="number">3</span>e12e2ceb68f   <span class="number">5</span> days ago       <span class="number">117</span>MB</span><br><span class="line"><span class="attribute">gitlab</span>/gitlab-ce   latest    <span class="number">08</span>f00af277b7   <span class="number">5</span> days ago       <span class="number">2</span>.<span class="number">79</span>GB</span><br></pre></td></tr></table></figure>

<p>如上所属，redis-01 是我们自己创建的，redis是官方提供的</p>
<p>差距显而易见</p>
<h2 id="构建企业debian-10-基础测试镜像"><a href="#构建企业debian-10-基础测试镜像" class="headerlink" title="构建企业debian 10 基础测试镜像"></a>构建企业debian 10 基础测试镜像</h2>
      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/07/12-07/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/07/12-07/" class="post-title-link" itemprop="url">数据可视化</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-07 08:53:05" itemprop="dateCreated datePublished" datetime="2022-12-07T08:53:05+08:00">2022-12-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-09 13:34:57" itemprop="dateModified" datetime="2022-12-09T13:34:57+08:00">2022-12-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%BF%97/" itemprop="url" rel="index"><span itemprop="name">日志</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>9.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="数据可视化的数据库选择"><a href="#数据可视化的数据库选择" class="headerlink" title="数据可视化的数据库选择"></a>数据可视化的数据库选择</h1><p>一般选择响应数据库比较快的一般是 秒级，或者毫秒级 ： 不要选择hive</p>
<p>因为hive太慢</p>
<p>我们一般都把数据最后导入到mysql里</p>
<p>作业：</p>
<p>自己做一个dashboard</p>
<h1 id="xxl"><a href="#xxl" class="headerlink" title="xxl"></a>xxl</h1><p>定时任务调度</p>
<p>就是按照每天都要做的任务</p>
<ul>
<li>crontab 进行 用的比较少 而因为不方便</li>
<li>定时任务的调度的框架<ul>
<li>ozio , azkaban,airflow,xxl,dolphinscheduler</li>
<li>现在ozio 和 azkaban 因为操作比较反人类，所以不太推荐</li>
<li>airflow ： 通过python进行任务调度的</li>
<li>公司首选 dolphinscheduler ，其次 xxl</li>
</ul>
</li>
<li>针对 xxl 或者 dolphinscheduler 可以串联的方式进行执行调度，就是a任务完成，直接执行b任务等等</li>
<li>但是crontab它要设置时间间隔，不可以串联的方式进行执行</li>
<li>多任务之间的依赖关系 ：<ul>
<li>DAG 有向无环图</li>
</ul>
</li>
<li>xxl 官网 ： 国人开发的 <code>https://github.com/xuxueli/xxl-job</code><ul>
<li>架构：主从架构，分布式架构</li>
<li>老大：调度中心</li>
<li>小弟：调度器</li>
</ul>
</li>
<li>其他的都是apache的</li>
</ul>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>下载源码 ；</p>
<p>导入idea 进行编译</p>
<p>初始化“调度数据库”xxl源数据库 -》 mysql中</p>
<p>首先在mysql中执行语句</p>
<figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line"># XXL-JOB v2.4.0-SNAPSHOT</span><br><span class="line"># Copyright (c) 2015-present, xuxueli.</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">database</span> <span class="keyword">if</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> <span class="symbol">`xxl_job`</span> default character <span class="keyword">set</span> utf8mb4 <span class="keyword">collate</span> utf8mb4_unicode_ci;</span><br><span class="line">use `xxl_job`;</span><br><span class="line"></span><br><span class="line">SET NAMES utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_info`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`job_group`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器主键ID&#x27;</span>,</span><br><span class="line">  <span class="symbol">`job_desc`</span> varchar(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`add_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`update_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`author`</span> varchar(<span class="number">64</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;作者&#x27;</span>,</span><br><span class="line">  <span class="symbol">`alarm_email`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;报警邮件&#x27;</span>,</span><br><span class="line">  <span class="symbol">`schedule_type`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;NONE&#x27;</span> COMMENT <span class="string">&#x27;调度类型&#x27;</span>,</span><br><span class="line">  <span class="symbol">`schedule_conf`</span> varchar(<span class="number">128</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;调度配置，值含义取决于调度类型&#x27;</span>,</span><br><span class="line">  <span class="symbol">`misfire_strategy`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;DO_NOTHING&#x27;</span> COMMENT <span class="string">&#x27;调度过期策略&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_route_strategy`</span> varchar(<span class="number">50</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器路由策略&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_handler`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器任务handler&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_param`</span> varchar(<span class="number">512</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器任务参数&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_block_strategy`</span> varchar(<span class="number">50</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;阻塞处理策略&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_timeout`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;任务执行超时时间，单位秒&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_fail_retry_count`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;失败重试次数&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_type`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;GLUE类型&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_source`</span> mediumtext COMMENT <span class="string">&#x27;GLUE源代码&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_remark`</span> varchar(<span class="number">128</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;GLUE备注&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_updatetime`</span> datetime DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;GLUE更新时间&#x27;</span>,</span><br><span class="line">  <span class="symbol">`child_jobid`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;子任务ID，多个逗号分隔&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_status`</span> tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;调度状态：0-停止，1-运行&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_last_time`</span> bigint(<span class="number">13</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;上次调度时间&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_next_time`</span> bigint(<span class="number">13</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;下次调度时间&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_log`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> bigint(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`job_group`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器主键ID&#x27;</span>,</span><br><span class="line">  <span class="symbol">`job_id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;任务，主键ID&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_address`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器地址，本次执行的地址&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_handler`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器任务handler&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_param`</span> varchar(<span class="number">512</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器任务参数&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_sharding_param`</span> varchar(<span class="number">20</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器任务分片参数，格式如 1/2&#x27;</span>,</span><br><span class="line">  <span class="symbol">`executor_fail_retry_count`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;失败重试次数&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_time`</span> datetime DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;调度-时间&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_code`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;调度-结果&#x27;</span>,</span><br><span class="line">  <span class="symbol">`trigger_msg`</span> text COMMENT <span class="string">&#x27;调度-日志&#x27;</span>,</span><br><span class="line">  <span class="symbol">`handle_time`</span> datetime DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行-时间&#x27;</span>,</span><br><span class="line">  <span class="symbol">`handle_code`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行-状态&#x27;</span>,</span><br><span class="line">  <span class="symbol">`handle_msg`</span> text COMMENT <span class="string">&#x27;执行-日志&#x27;</span>,</span><br><span class="line">  <span class="symbol">`alarm_status`</span> tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;告警状态：0-默认、1-无需告警、2-告警成功、3-告警失败&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="symbol">`I_trigger_time`</span> (<span class="symbol">`trigger_time`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="symbol">`I_handle_code`</span> (<span class="symbol">`handle_code`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_log_report`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`trigger_day`</span> datetime DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;调度-时间&#x27;</span>,</span><br><span class="line">  <span class="symbol">`running_count`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;运行中-日志数量&#x27;</span>,</span><br><span class="line">  <span class="symbol">`suc_count`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;执行成功-日志数量&#x27;</span>,</span><br><span class="line">  <span class="symbol">`fail_count`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;执行失败-日志数量&#x27;</span>,</span><br><span class="line">  <span class="symbol">`update_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>),</span><br><span class="line">  <span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="symbol">`i_trigger_day`</span> (<span class="symbol">`trigger_day`</span>) <span class="keyword">USING</span> BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_logglue`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`job_id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;任务，主键ID&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_type`</span> varchar(<span class="number">50</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;GLUE类型&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_source`</span> mediumtext COMMENT <span class="string">&#x27;GLUE源代码&#x27;</span>,</span><br><span class="line">  <span class="symbol">`glue_remark`</span> varchar(<span class="number">128</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;GLUE备注&#x27;</span>,</span><br><span class="line">  <span class="symbol">`add_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`update_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_registry`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`registry_group`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`registry_key`</span> varchar(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`registry_value`</span> varchar(<span class="number">255</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="symbol">`update_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>),</span><br><span class="line">  <span class="keyword">KEY</span> <span class="symbol">`i_g_k_v`</span> (<span class="symbol">`registry_group`</span>,<span class="symbol">`registry_key`</span>,<span class="symbol">`registry_value`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_group`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`app_name`</span> varchar(<span class="number">64</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器AppName&#x27;</span>,</span><br><span class="line">  <span class="symbol">`title`</span> varchar(<span class="number">12</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;执行器名称&#x27;</span>,</span><br><span class="line">  <span class="symbol">`address_type`</span> tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> DEFAULT <span class="string">&#x27;0&#x27;</span> COMMENT <span class="string">&#x27;执行器地址类型：0=自动注册、1=手动录入&#x27;</span>,</span><br><span class="line">  <span class="symbol">`address_list`</span> text COMMENT <span class="string">&#x27;执行器地址列表，多地址逗号分隔&#x27;</span>,</span><br><span class="line">  <span class="symbol">`update_time`</span> datetime DEFAULT <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_user`</span> (</span><br><span class="line">  <span class="symbol">`id`</span> int(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  <span class="symbol">`username`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;账号&#x27;</span>,</span><br><span class="line">  <span class="symbol">`password`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;密码&#x27;</span>,</span><br><span class="line">  <span class="symbol">`role`</span> tinyint(<span class="number">4</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;角色：0-普通用户、1-管理员&#x27;</span>,</span><br><span class="line">  <span class="symbol">`permission`</span> varchar(<span class="number">255</span>) DEFAULT <span class="literal">NULL</span> COMMENT <span class="string">&#x27;权限：执行器ID列表，多个逗号分割&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`id`</span>),</span><br><span class="line">  <span class="keyword">UNIQUE</span> <span class="keyword">KEY</span> <span class="symbol">`i_username`</span> (<span class="symbol">`username`</span>) <span class="keyword">USING</span> BTREE</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> TABLE <span class="symbol">`xxl_job_lock`</span> (</span><br><span class="line">  <span class="symbol">`lock_name`</span> varchar(<span class="number">50</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> COMMENT <span class="string">&#x27;锁名称&#x27;</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span> (<span class="symbol">`lock_name`</span>)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;</span><br><span class="line"></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`xxl_job_group`</span>(<span class="symbol">`id`</span>, <span class="symbol">`app_name`</span>, <span class="symbol">`title`</span>, <span class="symbol">`address_type`</span>, <span class="symbol">`address_list`</span>, <span class="symbol">`update_time`</span>) <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;xxl-job-executor-sample&#x27;</span>, <span class="string">&#x27;示例执行器&#x27;</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="string">&#x27;2018-11-03 22:21:31&#x27;</span> );</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`xxl_job_info`</span>(<span class="symbol">`id`</span>, <span class="symbol">`job_group`</span>, <span class="symbol">`job_desc`</span>, <span class="symbol">`add_time`</span>, <span class="symbol">`update_time`</span>, <span class="symbol">`author`</span>, <span class="symbol">`alarm_email`</span>, <span class="symbol">`schedule_type`</span>, <span class="symbol">`schedule_conf`</span>, <span class="symbol">`misfire_strategy`</span>, <span class="symbol">`executor_route_strategy`</span>, <span class="symbol">`executor_handler`</span>, <span class="symbol">`executor_param`</span>, <span class="symbol">`executor_block_strategy`</span>, <span class="symbol">`executor_timeout`</span>, <span class="symbol">`executor_fail_retry_count`</span>, <span class="symbol">`glue_type`</span>, <span class="symbol">`glue_source`</span>, <span class="symbol">`glue_remark`</span>, <span class="symbol">`glue_updatetime`</span>, <span class="symbol">`child_jobid`</span>) <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;测试任务1&#x27;</span>, <span class="string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="string">&#x27;XXL&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;CRON&#x27;</span>, <span class="string">&#x27;0 0 0 * * ? *&#x27;</span>, <span class="string">&#x27;DO_NOTHING&#x27;</span>, <span class="string">&#x27;FIRST&#x27;</span>, <span class="string">&#x27;demoJobHandler&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;SERIAL_EXECUTION&#x27;</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="string">&#x27;BEAN&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;GLUE代码初始化&#x27;</span>, <span class="string">&#x27;2018-11-03 22:21:31&#x27;</span>, <span class="string">&#x27;&#x27;</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`xxl_job_user`</span>(<span class="symbol">`id`</span>, <span class="symbol">`username`</span>, <span class="symbol">`password`</span>, <span class="symbol">`role`</span>, <span class="symbol">`permission`</span>) <span class="keyword">VALUES</span> (<span class="number">1</span>, <span class="string">&#x27;admin&#x27;</span>, <span class="string">&#x27;e10adc3949ba59abbe56e057f20f883e&#x27;</span>, <span class="number">1</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="symbol">`xxl_job_lock`</span> ( <span class="symbol">`lock_name`</span>) <span class="keyword">VALUES</span> ( <span class="string">&#x27;schedule_lock&#x27;</span>);</span><br><span class="line"></span><br><span class="line">commit;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然后再把从GitHub上下载的文件夹用idea打开进行编译</p>
<p>进行配置我们的web端口以及数据库：在application.properties文件中，然后配置一下</p>
<p>配置好之后maven，之间打成jar包，然后上传到linux服务器上</p>
<p>运行java -jar 上传的文件的路径</p>
<p>然后会报错，就创建个文件夹就好了 <code>mkdir -p /data/applogs/xxl-job</code></p>
<p>使用su 进行用户切换</p>
<p>然后通过chown 进行修改组以及用户 <code>chown -R hadoop:hadoop /data</code></p>
<p>然后再次运行就可以了</p>
<p>然后在调度器管理页面添加调度器，然后分配任务就可以了</p>
<h1 id="钉钉报警"><a href="#钉钉报警" class="headerlink" title="钉钉报警"></a>钉钉报警</h1><p>钉钉机器人可发送的类型</p>
<ul>
<li>文本</li>
<li>链接</li>
<li>markdown</li>
<li>actioncard</li>
<li>feedcard</li>
</ul>
<p>weget  ： 从互联网上下载的时候用的 ： 下载安装包 ，但是占用网络资源较大，且会一直重复下载直到结果成功，所以占用的资源较大</p>
<p>curl ： 发送请求的，发送网页请求访问的，也可以进行下载</p>
<ul>
<li>-o ： 把访问的一个页面存储到文件里</li>
</ul>
<p>机器人发送消息</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl &#x27;机器人的token&#x27;</span><br><span class="line">-H <span class="symbol">&#x27;Content</span>-<span class="keyword">type</span>:application/json&#x27;</span><br><span class="line">-d &#x27;&#123;<span class="string">&quot;msgtype&quot;</span> : <span class="type">text</span>&#125;&#x27;</span><br></pre></td></tr></table></figure>


<p>需求 ： </p>
<ul>
<li>日志数据 ： hdfs 上 linux user_click.log</li>
<li>例子： u01,鼠标,ios</li>
</ul>
<figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">u01,</span>鼠标,ios</span><br><span class="line"><span class="built_in">u01,</span>鼠标,ios</span><br><span class="line"><span class="built_in">u01,</span>鼠标,ios</span><br><span class="line"><span class="built_in">u01,</span>鼠标,ios</span><br><span class="line"><span class="built_in">u01,</span>鼠标,ios</span><br><span class="line"><span class="built_in">u02,</span>键盘,android</span><br><span class="line"><span class="built_in">u02,</span>键盘,android</span><br><span class="line"><span class="built_in">u02,</span>键盘,android</span><br><span class="line"><span class="built_in">u02,</span>键盘,android</span><br><span class="line"><span class="built_in">u03,</span>显示器,ios</span><br><span class="line"><span class="built_in">u04,</span>托特包,ios</span><br></pre></td></tr></table></figure>

<ul>
<li>业务数据 ：mysql user_info</li>
</ul>
<figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">u01,</span>子航</span><br><span class="line"><span class="built_in">u02,</span>祖安</span><br><span class="line"><span class="built_in">u03,</span>海哥</span><br><span class="line"><span class="built_in">u04,</span>轩轩</span><br></pre></td></tr></table></figure>

<p>统计：</p>
<p>uid ， name ，sku ， os 每个用户点击商品的次数</p>
<figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> bianhao,shop_name,caozuoxit,<span class="keyword">count</span>(*) <span class="keyword">as</span> cishu <span class="keyword">from</span> user_click1 <span class="keyword">group</span> <span class="keyword">by</span> bianhao,shop_name,caozuoxit;</span><br></pre></td></tr></table></figure>

<p>取出表中重复数据，的次数做个排序</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> shop_name,caozuoxit,<span class="type">name</span>,row_number() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> <span class="type">name</span>) <span class="keyword">as</span> rm <span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> user_click1 <span class="keyword">left join</span> user_info <span class="keyword">on</span> user_click1.bianhao=user_info.bianhao</span><br><span class="line">) <span class="keyword">as</span> king</span><br></pre></td></tr></table></figure>

<p>不重复字段标识为1</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">u01</span>,子航,鼠标,ios <span class="number">1</span></span><br><span class="line"><span class="attribute">u01</span>,子航,鼠标,ios <span class="number">2</span></span><br><span class="line"><span class="attribute">u01</span>,子航,鼠标,ios <span class="number">3</span></span><br><span class="line"><span class="attribute">u04</span>,托特包,ios <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>统计表中不重复的数据，一起做排序，但是对于重复数据它还是对自己排序</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="type">name</span>,caozuoxit,shop_name,row_number() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> cishu) <span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> user_click1 <span class="keyword">left join</span> (</span><br><span class="line"><span class="keyword">select</span> bianhao,count(*) <span class="keyword">as</span> cishu <span class="keyword">from</span> user_click1 <span class="keyword">group</span> <span class="keyword">by</span> bianhao,shop_name,caozuoxit</span><br><span class="line">) <span class="keyword">as</span> count_click <span class="keyword">on</span> count_click.bianhao=user_click1.bianhao</span><br><span class="line"><span class="keyword">left join</span> user_info <span class="keyword">on</span> count_click.bianhao=user_info.bianhao  </span><br><span class="line">) <span class="keyword">as</span> ds;</span><br><span class="line">上述是取巧的方法</span><br><span class="line">下面是正经的方法</span><br><span class="line"><span class="keyword">select</span> count_clickbianhao,<span class="type">name</span>,caozuoxit,shop_name,row_number() <span class="keyword">over</span>(<span class="keyword">order</span> <span class="keyword">by</span> cishu) <span class="keyword">as</span> rm <span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> user_click1 <span class="keyword">left join</span> (</span><br><span class="line"><span class="keyword">select</span> bianhao <span class="keyword">as</span> count_clickbianhao,count(*) <span class="keyword">as</span> cishu <span class="keyword">from</span> user_click1 <span class="keyword">group</span> <span class="keyword">by</span> bianhao,shop_name,caozuoxit</span><br><span class="line">) <span class="keyword">as</span> count_click <span class="keyword">on</span> count_click.count_clickbianhao=user_click1.bianhao </span><br><span class="line"><span class="keyword">left join</span> user_info <span class="keyword">on</span> count_click.count_clickbianhao=user_info.bianhao  </span><br><span class="line">) <span class="keyword">as</span> jj <span class="keyword">where</span> cishu = <span class="number">1</span> </span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> count_clickbianhao,<span class="type">name</span>,caozuoxit,shop_name,row_number() <span class="keyword">over</span>(<span class="keyword">partition</span> <span class="keyword">by</span> (<span class="type">name</span>,caozuoxit,shop_name,cishu)) <span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> user_click1 <span class="keyword">left join</span> (</span><br><span class="line"><span class="keyword">select</span> bianhao <span class="keyword">as</span> count_clickbianhao,count(*) <span class="keyword">as</span> cishu <span class="keyword">from</span> user_click1 <span class="keyword">group</span> <span class="keyword">by</span> bianhao,shop_name,caozuoxit</span><br><span class="line">) <span class="keyword">as</span> count_click <span class="keyword">on</span> count_click.count_clickbianhao=user_click1.bianhao </span><br><span class="line"><span class="keyword">left join</span> user_info <span class="keyword">on</span> count_click.count_clickbianhao=user_info.bianhao  </span><br><span class="line">) <span class="keyword">as</span> j <span class="keyword">where</span> cishu != <span class="number">1</span>;</span><br></pre></td></tr></table></figure>

<p>整个流程使用xxl进行调度</p>
<p>最后结果导入到mysql</p>
<p>数据导入mysql保证幂等性</p>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zihang.fun/2022/12/07/docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="liu zihang">
      <meta itemprop="description" content="只有努力不会辜负你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="枫叶冢">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/12/07/docker/" class="post-title-link" itemprop="url">docker</a>
        </h2>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-12-07 08:23:07" itemprop="dateCreated datePublished" datetime="2022-12-07T08:23:07+08:00">2022-12-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-12-11 13:39:59" itemprop="dateModified" datetime="2022-12-11T13:39:59+08:00">2022-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9D%82%E8%B4%A7%E6%8A%80%E6%9C%AF%E6%A0%88/" itemprop="url" rel="index"><span itemprop="name">杂货技术栈</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>7.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>7 分钟</span>
            </span>

        </div>
      </header>

    
    
    

   

    <div class="post-body" itemprop="articleBody">

      
          <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这个是关于docker的简单介绍以及使用</p>
<p>本来这个我其实不打算写的因为网上关于docker的教程很多，而且都比较全，我目前所学的全部都是基于菜鸟教程的</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>首先我们要明白，什么是docker</p>
<p>docker就是相当于一个箱子，其里面有它自己的生态圈</p>
<p>各种环境依赖是直接现成的那样，和之前java打包成exe文件后面绑定依赖是一样的</p>
<h1 id="为什么现在docker会会很火"><a href="#为什么现在docker会会很火" class="headerlink" title="为什么现在docker会会很火"></a>为什么现在docker会会很火</h1><p>因为docker不需要我们配置复杂的环境变量，只要我们通过网络下载一个包含这个功能的linux或者unbanto镜像就行</p>
<p>特别方便，不过方便的同时也会带来隐患，比如，不知道原生安装的话，我们如何详细的知道这个组件的功能？</p>
<h2 id="docker的安装"><a href="#docker的安装" class="headerlink" title="docker的安装"></a>docker的安装</h2><p>docker支持多种操作系统的安装，以下我只简单介绍关于linux和云服务器的安装方法</p>
<h3 id="linux"><a href="#linux" class="headerlink" title="linux"></a>linux</h3><p>使用官方命令安装</p>
<p><code>curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</code></p>
<p>也可以用国内的daocloud安装</p>
<p><code>curl -sSL https://get.daocloud.io/docker | sh</code></p>
<p>当执行安装命令出现以下情况报错的时候</p>
<figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># Executing docker install script, commit: 4f282167c425347a931ccfd95cc91fab041d414f</span><br><span class="line">+ sh -c &#x27;yum install -y -q yum-utils&#x27;</span><br><span class="line"><span class="keyword">error: </span>rpmdb: BDB0113 Thread/process 16675/139942115395648 failed: BDB1507 Thread died in Berkeley DB library</span><br><span class="line"><span class="keyword">error: </span>db5 error(<span class="string">-30973</span>) from dbenv-&gt;failchk: BDB0087 DB_RUNRECOVERY: Fatal error, run database recovery</span><br><span class="line"><span class="keyword">error: </span>cannot open Packages index using db5 -  (<span class="string">-30973</span>)</span><br><span class="line"><span class="keyword">error: </span>cannot open Packages database in /var/lib/rpm</span><br><span class="line">CRITICAL:yum.main:</span><br><span class="line"></span><br><span class="line"><span class="keyword">Error: </span>rpmdb open failed</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>执行 <code>mv /var/lib/rpm/__db.00* /tmp/&amp;&amp;yum clean all</code></p>
<p>再执行安装命令就可以了</p>
<p>这样在有网的机器上就安装完成了，是不是很简单 ，</p>
<p>接下来我们要说手动安装的情况</p>
<p>首先要卸载旧版本</p>
<p>较旧的 Docker 版本称为 docker 或 docker-engine 。如果已安装这些程序，请卸载它们以及相关的依赖项。</p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum remove docker <span class="string">\</span></span><br><span class="line">                  docker-client <span class="string">\</span></span><br><span class="line">                  docker-client-latest <span class="string">\</span></span><br><span class="line">                  docker-common <span class="string">\</span></span><br><span class="line">                  docker-latest <span class="string">\</span></span><br><span class="line">                  docker-latest-logrotate <span class="string">\</span></span><br><span class="line">                  docker-logrotate <span class="string">\</span></span><br><span class="line">                  docker-engine</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。</p>
<p>安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-<span class="class"><span class="keyword">data</span> \</span></span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure>

<p>使用以下命令来设置稳定的仓库。</p>
<p>官方地址源</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:<span class="regexp">//</span>download.docker.com<span class="regexp">/linux/</span>centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>阿里云地址源</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    http:<span class="regexp">//mi</span>rrors.aliyun.com<span class="regexp">/docker-ce/</span>linux<span class="regexp">/centos/</span>docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>清华大学的</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/docker-ce/</span>linux<span class="regexp">/centos/</span>docker-ce.repo</span><br></pre></td></tr></table></figure>

<p>在国内还是建议阿里和清华大学的</p>
<p>安装最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p>
<p><code>$ sudo yum install docker-ce docker-ce-cli containerd.io docker-compose-plugin</code></p>
<p>如果提示您接受 GPG 密钥，请选是。</p>
<p>Docker 安装完默认未启动。并且已经创建好 docker 用户组，但该用户组下没有用户。</p>
<p><strong>要安装特定版本的 Docker Engine-Community，请在存储库中列出可用版本，然后选择并安装：</strong></p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ yum <span class="keyword">list</span> docker-<span class="keyword">ce</span> --showduplicates | <span class="keyword">sort</span> -r</span><br><span class="line"></span><br><span class="line">docker-<span class="keyword">ce</span>.x86_64  <span class="number">3</span>:<span class="number">18.09</span>.<span class="number">1</span>-<span class="number">3</span>.el7                     docker-<span class="keyword">ce</span>-stable</span><br><span class="line">docker-<span class="keyword">ce</span>.x86_64  <span class="number">3</span>:<span class="number">18.09</span>.<span class="number">0</span>-<span class="number">3</span>.el7                     docker-<span class="keyword">ce</span>-stable</span><br><span class="line">docker-<span class="keyword">ce</span>.x86_64  <span class="number">18.06</span>.<span class="number">1</span>.<span class="keyword">ce</span>-<span class="number">3</span>.el7                    docker-<span class="keyword">ce</span>-stable</span><br><span class="line">docker-<span class="keyword">ce</span>.x86_64  <span class="number">18.06</span>.<span class="number">0</span>.<span class="keyword">ce</span>-<span class="number">3</span>.el7                    docker-<span class="keyword">ce</span>-stable</span><br></pre></td></tr></table></figure>

<p>通过其完整的软件包名称安装特定版本，该软件包名称是软件包名称（docker-ce）加上版本字符串（第二列），从第一个冒号（:）一直到第一个连字符，并用连字符（-）分隔。例如：docker-ce-18.09.1。</p>
<p><code>$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io</code></p>
<p>然后启动docker</p>
<p><code>$ sudo systemctl start docker</code></p>
<p>然后运行hello world镜像查看是不是我们成功安装了这个docker</p>
<p><code>$ sudo docker run hello-world</code></p>
<h3 id="卸载docker"><a href="#卸载docker" class="headerlink" title="卸载docker"></a>卸载docker</h3><p>先删除安装包</p>
<p><code>yum remove docker-ce </code></p>
<p>然后删除镜像文件等</p>
<p><code>rm -rf /var/lib/docker</code></p>
<p>云服务器和上面一样</p>
<h1 id="docker-命令"><a href="#docker-命令" class="headerlink" title="docker 命令"></a>docker 命令</h1><p>docker命令的种类不多但是其中的分支较多</p>
<p>docker run : 原本的意义是创建一个docker容器，并运行它</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">-<span class="selector-tag">a</span> stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项；</span><br><span class="line"></span><br><span class="line">-d: 后台运行容器，并返回容器ID；</span><br><span class="line"></span><br><span class="line">-<span class="selector-tag">i</span>: 以交互模式运行容器，通常与 -t 同时使用；</span><br><span class="line"></span><br><span class="line">-P: 随机端口映射，容器内部端口随机映射到主机的端口</span><br><span class="line"></span><br><span class="line">-<span class="selector-tag">p</span>: 指定端口映射，格式为：主机(宿主)端口:容器端口</span><br><span class="line"></span><br><span class="line">-t: 为容器重新分配一个伪输入终端，通常与 -<span class="selector-tag">i</span> 同时使用；</span><br><span class="line"></span><br><span class="line"><span class="attr">--name</span>=<span class="string">&quot;nginx-lb&quot;</span>: 为容器指定一个名称；</span><br><span class="line"></span><br><span class="line"><span class="attr">--dns</span> <span class="number">8.8</span>.<span class="number">8.8</span>: 指定容器使用的DNS服务器，默认和宿主一致；</span><br><span class="line"></span><br><span class="line"><span class="attr">--dns-search</span> example<span class="selector-class">.com</span>: 指定容器DNS搜索域名，默认和宿主一致；</span><br><span class="line"></span><br><span class="line">-h <span class="string">&quot;mars&quot;</span>: 指定容器的hostname；</span><br><span class="line"></span><br><span class="line">-e username=<span class="string">&quot;ritchie&quot;</span>: 设置环境变量；</span><br><span class="line"></span><br><span class="line"><span class="attr">--env-file</span>=<span class="selector-attr">[]</span>: 从指定文件读入环境变量；</span><br><span class="line"></span><br><span class="line"><span class="attr">--cpuset</span>=<span class="string">&quot;0-2&quot;</span> or <span class="attr">--cpuset</span>=<span class="string">&quot;0,1,2&quot;</span>: 绑定容器到指定CPU运行；</span><br><span class="line"></span><br><span class="line">-m :设置容器使用内存最大值；</span><br><span class="line"></span><br><span class="line"><span class="attr">--net</span>=<span class="string">&quot;bridge&quot;</span>: 指定容器的网络连接类型，支持 bridge/host/<span class="attribute">none</span>/container: 四种类型；</span><br><span class="line"></span><br><span class="line"><span class="attr">--link</span>=<span class="selector-attr">[]</span>: 添加链接到另一个容器；</span><br><span class="line"></span><br><span class="line"><span class="attr">--expose</span>=<span class="selector-attr">[]</span>: 开放一个端口或一组端口；</span><br><span class="line"></span><br><span class="line"><span class="attr">--volume</span> , -v: 绑定一个卷</span><br></pre></td></tr></table></figure>

<p><strong>docker start</strong> :启动一个或多个已经被停止的容器</p>
<p><strong>docker stop</strong> :停止一个运行中的容器</p>
<p><strong>docker restart</strong> :重启容器</p>
<p><strong>docker kill</strong> :杀掉一个运行中的容器。</p>
<ul>
<li><strong>-s :</strong> 向容器发送一个信号</li>
</ul>
<p><strong>docker rm ：</strong> 删除一个或多个容器。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-f :通过 SIGKILL 信号强制删除一个运行中的容器。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-l :移除容器间的网络连接，而非容器本身。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-v :删除与容器关联的卷。</span></span><br></pre></td></tr></table></figure>

<ul>
<li>命令可以嵌套使用如下 ：<ul>
<li><code>删除所有已经停止的容器：docker rm $(docker ps -a -q)</code></li>
</ul>
</li>
</ul>
<p><strong>docker pause</strong> :暂停容器中所有的进程。</p>
<p><strong>docker unpause</strong> :恢复容器中所有的进程。</p>
<p><strong>docker create ：</strong> 创建一个新的容器但不启动它 ：其语法和run一样</p>
<p><strong>docker exec ：</strong> 在运行的容器中执行命令</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-d :分离模式: 在后台运行</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-i :即使没有附加也保持STDIN 打开</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-t :分配一个伪终端</span></span><br></pre></td></tr></table></figure>

<p>docker ps : 列出容器</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-a :显示所有的容器，包括未运行的。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-f :根据条件过滤显示的内容。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--format :指定返回值的模板文件。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-l :显示最近创建的容器。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-n :列出最近创建的n个容器。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--no-trunc :不截断输出。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-q :静默模式，只显示容器编号。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-s :显示总的文件大小。</span></span><br></pre></td></tr></table></figure>

<p>输出介绍</p>
<figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">输出详情介绍：</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">CONTAINER ID</span><span class="punctuation">:</span> <span class="string">容器 ID。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">IMAGE</span><span class="punctuation">:</span> <span class="string">使用的镜像。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">COMMAND</span><span class="punctuation">:</span> <span class="string">启动容器时运行的命令。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">CREATED</span><span class="punctuation">:</span> <span class="string">容器的创建时间。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">STATUS</span><span class="punctuation">:</span> <span class="string">容器状态。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">状态有7种：</span></span><br><span class="line"><span class="attribute"></span></span><br><span class="line"><span class="attribute">created（已创建）</span></span><br><span class="line"><span class="attribute">restarting（重启中）</span></span><br><span class="line"><span class="attribute">running（运行中）</span></span><br><span class="line"><span class="attribute">removing（迁移中）</span></span><br><span class="line"><span class="attribute">paused（暂停）</span></span><br><span class="line"><span class="attribute">exited（停止）</span></span><br><span class="line"><span class="attribute">dead（死亡）</span></span><br><span class="line"><span class="attribute">PORTS</span><span class="punctuation">:</span> <span class="string">容器的端口信息和使用的连接类型（tcp\udp）。</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">NAMES</span><span class="punctuation">:</span> <span class="string">自动分配的容器名称。</span></span><br></pre></td></tr></table></figure>

<p><strong>docker inspect :</strong> 获取容器&#x2F;镜像的元数据。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-f :指定返回值的模板文件。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-s :显示总的文件大小。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--type :为指定类型返回JSON。</span></span><br></pre></td></tr></table></figure>

<p><strong>docker top :</strong> 查看容器中运行的进程信息，支持 ps 命令参数。</p>
<p><code>docker top [OPTIONS] CONTAINER [ps OPTIONS]</code></p>
<ul>
<li>查看所有运行容器的进程信息。</li>
<li><code>for i in  </code>docker ps |grep Up|awk ‘{print $1}’<code>;do echo \ &amp;&amp;docker top $i; done</code></li>
</ul>
<p><strong>docker attach :</strong> 连接到正在运行中的容器。</p>
<p>要attach上去的容器必须正在运行，可以同时连接上同一个container来共享屏幕（与screen命令的attach类似）。</p>
<p>docker events : 从服务器获取实时事件</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-f ：根据条件过滤事件；</span><br><span class="line"></span><br><span class="line"><span class="params">--since</span> ：从指定的时间戳后显示所有事件;</span><br><span class="line"></span><br><span class="line"><span class="params">--until</span> ：流水时间显示到指定的时间为止；</span><br><span class="line"></span><br><span class="line">如果指定的时间是到秒级的，需要将时间转成时间戳。如果时间为日期的话，可以直接使用，如<span class="params">--since=</span><span class="string">&quot;2016-07-01&quot;</span>。</span><br></pre></td></tr></table></figure>

<p>docker logs : 获取容器的日志</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">-f : 跟踪日志输出</span><br><span class="line"></span><br><span class="line"><span class="comment">--since :显示某个开始时间的所有日志</span></span><br><span class="line"></span><br><span class="line">-t : 显示时间戳</span><br><span class="line"></span><br><span class="line"><span class="comment">--tail :仅列出最新N条容器日志</span></span><br></pre></td></tr></table></figure>

<p><strong>docker wait :</strong> 阻塞运行直到容器停止，然后打印出它的退出代码</p>
<p><strong>docker export :</strong> 将文件系统作为一个tar归档文件导出到STDOUT。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-o :将输入内容写到文件。</span></span><br></pre></td></tr></table></figure>

<p>docker port 用于列出指定的容器的端口映射，或者查找将 PRIVATE_PORT NAT 到面向公众的端口。</p>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker port <span class="comment">[OPTIONS]</span> <span class="keyword">CONTAINER</span> <span class="comment">[PRIVATE_PORT<span class="comment">[/PROTO]</span>]</span></span><br></pre></td></tr></table></figure>

<p>docker stats : 显示容器资源的使用情况，包括：CPU、内存、网络 I&#x2F;O 等。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">--all</span> , -<span class="selector-tag">a</span> :显示所有的容器，包括未运行的。</span><br><span class="line"></span><br><span class="line"><span class="attr">--format</span> :指定返回值的模板文件。</span><br><span class="line"></span><br><span class="line"><span class="attr">--no-stream</span> :展示当前状态就直接退出了，不再实时更新。</span><br><span class="line"></span><br><span class="line"><span class="attr">--no-trunc</span> :不截断输出。</span><br></pre></td></tr></table></figure>

<p><strong>docker commit :</strong> 从容器创建一个新的镜像。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-a :提交的镜像作者；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-c :使用Dockerfile指令来创建镜像；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-m :提交时的说明文字；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-p :在commit时，将容器暂停。</span></span><br></pre></td></tr></table></figure>

<p><strong>docker cp :</strong> 用于容器与主机之间的数据拷贝。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">-L :保持源目标中的链接</span><br><span class="line">docker <span class="built_in">cp</span> [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-</span><br><span class="line">docker <span class="built_in">cp</span> [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH</span><br><span class="line">例子 ：</span><br><span class="line">实例</span><br><span class="line">将主机/www/runoob目录拷贝到容器96f7f14e99ab的/www目录下。</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /www/runoob 96f7f14e99ab:/www/</span><br><span class="line">将主机/www/runoob目录拷贝到容器96f7f14e99ab中，目录重命名为www。</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span> /www/runoob 96f7f14e99ab:/www</span><br><span class="line">将容器96f7f14e99ab的/www目录拷贝到主机的/tmp目录中。</span><br><span class="line"></span><br><span class="line">docker <span class="built_in">cp</span>  96f7f14e99ab:/www /tmp/</span><br></pre></td></tr></table></figure>

<p>docker diff : 检查容器里文件结构的更改。</p>
<figure class="highlight inform7"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker diff <span class="comment">[OPTIONS]</span> <span class="keyword">CONTAINER</span></span><br></pre></td></tr></table></figure>

<p><strong>docker login :</strong> 登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub</p>
<p><strong>docker logout :</strong> 登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">login</span> [<span class="keyword">OPTIONS</span>] [<span class="keyword">SERVER</span>]</span><br><span class="line">docker logout [<span class="keyword">OPTIONS</span>] [<span class="keyword">SERVER</span>]</span><br><span class="line">-u :登陆的用户名</span><br><span class="line"></span><br><span class="line">-p :登陆的密码</span><br></pre></td></tr></table></figure>

<p>docker pull : 从镜像仓库中拉取或者更新指定镜像</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-<span class="selector-tag">a</span> :拉取所有 tagged 镜像</span><br><span class="line">docker pull <span class="selector-attr">[OPTIONS]</span> NAME<span class="selector-attr">[:TAG|@DIGEST]</span></span><br><span class="line"><span class="attr">--disable-content-trust</span> :忽略镜像的校验,默认开启</span><br></pre></td></tr></table></figure>

<p>docker push : 将本地的镜像上传到镜像仓库,要先登陆到镜像仓库</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--disable-content-trust :忽略镜像的校验,默认开启</span></span><br><span class="line">docker push [<span class="keyword">OPTIONS</span>] <span class="type">NAME</span>[:TAG]</span><br></pre></td></tr></table></figure>

<p><strong>docker search :</strong> 从Docker Hub查找镜像</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">search</span> [<span class="keyword">OPTIONS</span>] TERM</span><br><span class="line"><span class="comment">--automated :只列出 automated build类型的镜像；</span></span><br><span class="line"></span><br><span class="line"><span class="comment">--no-trunc :显示完整的镜像描述；</span></span><br><span class="line"></span><br><span class="line">-f &lt;过滤条件&gt;:列出收藏数不小于指定值的镜像。</span><br></pre></td></tr></table></figure>

<p>docker images : 列出本地镜像。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">docker images <span class="selector-attr">[OPTIONS]</span> <span class="selector-attr">[REPOSITORY[:TAG]</span>]</span><br><span class="line">-<span class="selector-tag">a</span> :列出本地所有的镜像（含中间映像层，默认情况下，过滤掉中间映像层）；</span><br><span class="line"></span><br><span class="line"><span class="attr">--digests</span> :显示镜像的摘要信息；</span><br><span class="line"></span><br><span class="line">-f :显示满足条件的镜像；</span><br><span class="line"></span><br><span class="line"><span class="attr">--format</span> :指定返回值的模板文件；</span><br><span class="line"></span><br><span class="line"><span class="attr">--no-trunc</span> :显示完整的镜像信息；</span><br><span class="line"></span><br><span class="line">-<span class="selector-tag">q</span> :只显示镜像ID。</span><br></pre></td></tr></table></figure>

<p>docker rmi : 删除本地一个或多个镜像。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker rmi <span class="selector-attr">[OPTIONS]</span> IMAGE <span class="selector-attr">[IMAGE...]</span></span><br><span class="line">-f :强制删除；</span><br><span class="line"></span><br><span class="line"><span class="attr">--no-prune</span> :不移除该镜像的过程镜像，默认移除；</span><br></pre></td></tr></table></figure>

<p>docker tag : 标记本地镜像，将其归入某一仓库。</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">tag</span> <span class="title">[OPTIONS</span>] IMAGE[:<span class="keyword">TAG</span>] [REGISTRYHOST/][USERNAME/]NAME[:<span class="keyword">TAG</span>]</span><br></pre></td></tr></table></figure>

<p>docker build 命令用于使用 Dockerfile 创建镜像</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">docker build [OPTIONS] PATH | URL | -</span><br><span class="line"><span class="deletion">--build-arg=[] :设置镜像创建时的变量；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--cpu-shares :设置 cpu 使用权重；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--cpu-period :限制 CPU CFS周期；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--cpu-quota :限制 CPU CFS配额；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--cpuset-cpus :指定使用的CPU id；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--cpuset-mems :指定使用的内存 id；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--disable-content-trust :忽略校验，默认开启；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-f :指定要使用的Dockerfile路径；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--force-rm :设置镜像过程中删除中间容器；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--isolation :使用容器隔离技术；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--label=[] :设置镜像使用的元数据；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-m :设置内存最大值；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--memory-swap :设置Swap的最大值为内存+swap，&quot;-1&quot;表示不限swap；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--no-cache :创建镜像的过程不使用缓存；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--pull :尝试去更新镜像的新版本；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--quiet, -q :安静模式，成功后只输出镜像 ID；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--rm :设置镜像成功后删除中间容器；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--shm-size :设置/dev/shm的大小，默认值是64M；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--ulimit :Ulimit配置。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--squash :将 Dockerfile 中所有的操作压缩为一层。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--tag, -t: 镜像的名字及标签，通常 name:tag 或者 name 格式；可以在一次构建中为一个镜像设置多个标签。</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--network: 默认 default。在构建期间设置RUN指令的网络模式</span></span><br></pre></td></tr></table></figure>

<p>docker history : 查看指定镜像的创建历史。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker history [OPTIONS] IMAGE</span><br><span class="line"><span class="deletion">-H :以可读的格式打印镜像大小和日期，默认为true；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">--no-trunc :显示完整的提交记录；</span></span><br><span class="line"></span><br><span class="line"><span class="deletion">-q :仅列出提交记录ID。</span></span><br></pre></td></tr></table></figure>

<p>docker save : 将指定镜像保存成 tar 归档文件</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker save <span class="selector-attr">[OPTIONS]</span> IMAGE <span class="selector-attr">[IMAGE...]</span></span><br><span class="line">-o :输出到的文件。</span><br></pre></td></tr></table></figure>

<p>docker load : 导入使用 docker save 命令导出的镜像。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker load <span class="selector-attr">[OPTIONS]</span></span><br><span class="line"><span class="attr">--input</span> , -<span class="selector-tag">i</span> : 指定导入的文件，代替 STDIN。</span><br><span class="line"></span><br><span class="line"><span class="attr">--quiet</span> , -<span class="selector-tag">q</span> : 精简输出信息。</span><br></pre></td></tr></table></figure>

<p><strong>docker import :</strong> 从归档文件中创建镜像。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="keyword">import</span> [<span class="keyword">OPTIONS</span>] <span class="keyword">file</span>|URL|- [REPOSITORY[:TAG]]</span><br><span class="line">-c :应用docker 指令创建镜像；</span><br><span class="line"></span><br><span class="line">-m :提交时的说明文字；</span><br></pre></td></tr></table></figure>

<p>docker info : 显示 Docker 系统信息，包括镜像和容器数。</p>
<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">docker</span> <span class="literal">info</span> [OPTIONS]</span><br></pre></td></tr></table></figure>

<p>docker version :显示 Docker 版本信息。</p>
<figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="deletion">-f :指定返回值的模板文件。</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

      
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="liu zihang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">liu zihang</p>
  <div class="site-description" itemprop="description">只有努力不会辜负你</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yourname" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yourname" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      链接网站
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://baidu.com/" title="https:&#x2F;&#x2F;baidu.com" rel="noopener" target="_blank">百度</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://fishc.com.cn/" title="https:&#x2F;&#x2F;fishc.com.cn" rel="noopener" target="_blank">鱼C论坛</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">liu zihang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共114.6k字</span>
</div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/canvas_lines.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  

  


</body>
</html>
